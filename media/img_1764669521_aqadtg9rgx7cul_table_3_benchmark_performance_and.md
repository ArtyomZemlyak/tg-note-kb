# Image Description

**File:** img_1764669521_aqadtg9rgx7cul_table_3_benchmark_performance_and.jpg
**Original:** image.jpg
**Received:** 1764669521

## Extracted Text (OCR)

Table 3 | Benchmark performance and efficiency of reasoning models. For each benchmark, cells show accuracy and output token count (in thousands). The highest accuracy per benchmark is in bold; the second-highest is underlined.

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | GPTI-5 Gemini-3.0 Kimi-K2 DeepSeek-V3.2 | DeepSeek-V3.2 Se SE ee eee ee ЧР ЗЫ ae ee ee ee 3 Ce See gy Re eS se re ee eee es Meee  Benchmark High Pro Thinking Thinking | Speciale   |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| AIME 2025 (asset) 94.6 (13k) 95.0(15k) 94.5 (24k) 93.1 (16k) | 96.0 (23k) HMMT Feb 2025 crassa) 88.3(16k) 97.5(16k) 89.4(31k) 92.5 (19k) | 99.2 (27k) HMMT Nov 2025 г...) 89.2 (20K) 93.3(15k) 89.2 (29k) 90.2 (18k) | 94.4 (25k) IMOAnswerBench (раза) 76.0 (31k) 83.3(18k) 78.6(37k) 78.3 (27k) | 84.5 (45k) LiveCodeBench ‹раззв1сот, 84.5(13k) 90.7(13k) 82.6 (29К) 83.3 (16k) | 88.7 (27k) CodeForces (rating) 2537 (29k) 2708 (22k) - 2386 (42k) | 2701 (77k) СРОА Diamond газе) 85.7(8k) 91.9(8k) 84.5(12k) 82.4(7k) | 85.7 (16k) НГЕ (Passe) 26.3 (15k) 37.7(15k) 23.9(24k) 25.1 (21k) | 30.6 (35k) |                                                                                                                                                                                     |

## Usage Instructions

When referencing this image in markdown:
1. Use relative path based on file location
2. Add descriptive alt text based on OCR content above
3. Add text description BELOW the image for GitHub rendering

Example:
```markdown
![Description based on OCR](../media/img_1764669521_aqadtg9rgx7cul_table_3_benchmark_performance_and.jpg) <!-- TODO: Broken image path -->

**Image shows:** [Describe what the image contains based on OCR]
```
