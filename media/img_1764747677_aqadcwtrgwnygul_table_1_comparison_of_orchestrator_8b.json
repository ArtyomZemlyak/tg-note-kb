{
  "file_id": "AQADCwtrGwnygUl-",
  "timestamp": 1764747677,
  "original_filename": "image.jpg",
  "file_hash": "762c6c82ac91f1ce9c90fcc0072b8350ec5c682746855739cb1cc0f0a18029ee",
  "media_filename": "img_1764747677_aqadcwtrgwnygul_table_1_comparison_of_orchestrator_8b.jpg",
  "ocr_extracted": true,
  "ocr_length": 3931,
  "ocr_structured": {
    "from_cache": false,
    "document_key": "c4e8ba66cd6b20c05f4c0a44e36f47e6",
    "markdown": "Table 1 | Comparison of Orchestrator-8B with baselines (prompt-based LLMs). Llama-Nemotron-49B denotes Llama-3.3-Nemotron-Super-49B-vl. Cost in US cents, Latency in minutes, are averaged between HLE and Frames. More efficiency statistics on 7*-Bench are in Table 16 in Appendix. Basic tools include domain functions, search and code interpreter (54.1). Т The higher the better. | The lower the better. The results of existing SOTA are reported by [23]'.\n\n|                                                             | Tools Model(s) HLE (1) FRAMES (1) 17*-Bench (1) Cost (|) Latency (1)   |\n|-------------------------------------------------------------|------------------------------------------------------------------------|\n| Existing  СРТ-5  35.2                                       |                                                                        |\n| reported 03 24.3 — 68.4                                     |                                                                        |\n| (Jwen3-8B  5  24.2  0.2  0.6                                |                                                                        |\n| Lilama-Nemotron-4d9B  95 6  Од  11                          |                                                                        |\n| Llama-3. 3- тов 3.8 32.4 —* 0.5  а = ee — =— о ee ПС a  1.4 |                                                                        |\n| (Jwen3-235B-A22B  5.2  2.6  -                               |                                                                        |\n| Claude Opus 4.1  11.7  58.2  27.4  8.2                      |                                                                        |\n| 6.2  41                                                     |                                                                        |\n| ()wen3-8B  AT  26.5  40.7  1.3  2.2                         |                                                                        |\n| Llama-Nemotron-19B  6.8  oR о  93 9                         |                                                                        |\n| Basic tools Haar (OB |                                      |                                                                        |\n| (wen3-235B-A22B 14.0 39.5 52.9 12.3 10.2                    |                                                                        |\n| Claude Opus 4.1 19.8 63.5 46.0 76.2 32.0                    |                                                                        |\n| (-PT-5 35 1 TAD УГ 302 19.8                                 |                                                                        |\n| (Jwen3-85 30.6 68.9 72.3 27.6 18.3                          |                                                                        |\n| Llama-Nemotron-49B On 5 579 66.7 95 6 17.1                  |                                                                        |\n| Basic tools, Llama-3.3-70B 19.7 52.4 55.8 19.7 13.4         |                                                                        |\n| Specialized LLMs Qwen3-235B-A22B 32.8 74.2 75.6 29.7 2].2   |                                                                        |\n| Generalist LLMs Claude Opus 4.1 34.6 72.8 76.8 52.0 25.6    |                                                                        |\n| (2177-5  9] 2  БУВ  623  175  136                           |                                                                        |\n| ()rchestrator-3B  37.1  76.3  580.2  9.2  5.2               |                                                                        |\n\n' The HLE results of Existing reported SOTA are based on the full set, while other baselines and ours are only on the text-only subset. + Due to implementation differences, we could not fully reproduce GPT-5's reported result (84.2) and only reached 77.7 in our experiments.\n\nr*\\_Ronch cannot Бе «ое in the absence of tools:",
    "export_format": "markdown"
  },
  "processing_metadata": {
    "docling_mcp": {
      "tool": "convert_document_from_content",
      "server": "docling",
      "transport": "sse"
    },
    "docling": {
      "backend": "mcp",
      "tool": "convert_document_from_content",
      "server": "docling",
      "prefer_markdown_output": true,
      "fallback_plain_text": true,
      "image_ocr_enabled": true,
      "max_file_size_mb": 25,
      "ocr_languages": [
        "eng",
        "rus"
      ]
    }
  }
}