# AgenceBench: Комплексный бенчмарк для оценки агентного интеллекта

## Описание

AgenceBench - это комплексный бенчмарк, предназначенный для оценки способностей агентов искусственного интеллекта. Он тестирует большие языковые модели (LLM) в различных доменах и уровнях сложности, измеряя их способность функционировать как автономные агенты, способные к планированию, выполнению и адаптации в сложных сценариях с несколькими шагами.

## Основные характеристики

- Оценивает способности агентов ИИ в реальных сценариях
- Особое внимание уделяется использованию инструментов и планированию
- Используется для сравнения различных подходов к разработке агентов
- Позволяет измерять прогресс в области агентного ИИ
- Тестирование проводится с R=3 раундами взаимодействия
- Покрывает 10 различных задач в множестве доменов

## Структура бенчмарка

Бенчмарк состоит из 10 различных задач в общей сложности из 49 субзадач:

### Домены задач:
1. **Разработка программного обеспечения**: консольные приложения на C++, системы управления задачами на Java
2. **Разработка игр**: продвинутый ИИ для стратегических игр, таких как Гомоку
3. **Системное программирование**: распределенные системы, устойчивость к отказам, механизмы саморемонта
4. **Научные исследования и анализ**: обнаружение наборов данных, научное моделирование, оценка производительности
5. **Логика знаний**: сложные вопросно-ответные системы на основе фактов в спортивных и финансовых доменах

### Задачи:
- Задача 1: Система чата на C++
- Задача 2: Система управления задачами на Java
- Задача 3: Игра Гомоку Battle
- Задача 4: Автономная система саморемонта
- Задача 5: Анализ набора данных DynToM
- Задача 6: Сравнительное исследование GPT-4o
- Задача 7: Система обнаружения наборов данных
- Задача 8: Открытие функций научной системы
- Задача 9: Анализ игроков НБА
- Задача 10: Анализ компаний S&P 500

## Оценочные метрики

Бенчмарк использует четыре ключевые метрики:

### 1. Первый функциональный успех (FTFC - First-Turn Functional Completeness)
Измеряет реализацию первоначального ответа выполнения

### 2. Коэффициент успеха (SR@R - Success Rate)
Процент запросов, завершенных в пределах R раундов

### 3. Оставшиеся шансы (RC@R - Remaining Chances)
Среднее количество неиспользованных раундов для успешных завершений

### 4. Раунды (R)
Максимальное количество раундов взаимодействия (R=3 в реализации)

## Результаты и лидерборд

На основе оценки с R=3:
- **Первое место**: Claude Sonnet-4 (FTFC: 0.730, RC: 0.752, SR: 0.741)
- **Второе место**: LIMI от GAIR (FTFC: 0.717, RC: 0.742, SR: 0.746) - **Результаты LIMI впечатляющие: 73.5% на AgencyBench**
- **Третье место**: GPT-5 от OpenAI (FTFC: 0.561, RC: 0.594, SR: 0.628)

## Применение в исследовании LIMI

- Использовался для измерения улучшений в производительности агентов
- Показал значительный рост метрик с 45% до 73.5% после дообучения с использованием подхода LIMI
- Демонстрирует 53.7 процентных пункта улучшения по сравнению с моделями, обученными на 10 000 примерах
- Использование в 128 раз меньшего объема данных при достижении превосходных результатов
- Подчеркивает важность оценки агентов в реальных сценариях, а не только в теоретических задачах

## Домены оценки

AgenceBench включает задачи из следующих доменов:

### 1. Vibe Coding
- Задачи программирования и разработки ПО
- Использование различных инструментов разработки
- Решение реальных проблем кодирования
- Совместная разработка программного обеспечения

### 2. Research Workflows
- Научные рабочие процессы
- Использование инструментов для исследований
- Планирование и выполнение исследовательских задач
- Анализ данных и научное моделирование

## Технические особенности

- Использует sii-cli как оценочную структуру
- Содержит файлы спецификаций задач и реализации
- Рабочие области для каждой задачи с файлами реализации
- Официальный сайт: https://agencybench.opensii.ai

## Значение для разработки агентов

- Предоставляет объективную метрику для сравнения различных подходов
- Помогает исследователям понимать реальный прогресс в области агентного ИИ
- Подчеркивает важность способности агентов использовать инструменты для решения задач
- Стандартизирует оценку агентного ИИ в реальных сценариях
- Помогает понимать прогресс в переходе от «думающего ИИ» к «работающему ИИ»

## Связи с другими темами

- [[ai/agents/limi_less_is_more_for_agency.md]] - Исследование LIMI, которое значительно улучшило метрики на AgenceBench
- [[ai/agents/sii_cli_framework.md]] - Фреймворк SII CLI, используемый как оценочная структура для AgenceBench
- [[ai/agents/ai_agent_benchmarks.md]] - Общая информация о бенчмарках для агентов ИИ
- [[ai/agents/tool_usage.md]] - Использование инструментов, важный аспект, оцениваемый AgenceBench
- [[ai/agents/human_in_the_loop_training.md]] - Обучение с участием человека, важный аспект оценки агентов

## Источники

- [Официальный репозиторий AgencyBench](https://github.com/GAIR-NLP/AgencyBench)
- [Официальный сайт](https://agencybench.opensii.ai)
- Описание бенчмарка и подробности статьи в разработке