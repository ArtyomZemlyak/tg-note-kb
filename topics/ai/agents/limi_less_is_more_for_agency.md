# LIMI: Less is More for Agency - Революция в обучении агентов ИИ

## Описание

LIMI (Less is More for Intelligent Agency) представляет радикальный подход к разработке агентов ИИ, бросающий вызов общей парадигме «чем больше данных, тем лучше». Вместо использования огромных объемов данных, LIMI фокусируется на минимальном количестве (всего 78) тщательно отобранных, высококачественных демонстраций сложных совместных рабочих процессов. Эти демонстрации охватывают полный процесс решения задачи — включая рассуждения, использование инструментов и обратную связь от среды — в таких специализированных областях, как разработка ПО и научные исследования.

## Принцип эффективности агентности (Agency Efficiency Principle)

Одним из ключевых вкладов LIMI является формулировка Принципа эффективности агентности: сложная машинная автономия возникает не из-за обилия данных, а благодаря стратегическому отбору демонстраций, которые отражают суть агентного поведения. Это фундаментально меняет дорожную карту перехода от «думающего ИИ» к надёжному «работающему ИИ».

## Основные результаты

- **73.5%** на бенчмарке AgencyBench, что на **53.7 процентных пункта** лучше, чем у бейзлайна, обученного на 10 000 примерах
- Использование в **128 раз меньше данных** при достижении превосходных результатов
- Повышение эффективности агентов с помощью тщательно курируемых обучающих траекторий
- Демонстрация важности качества данных для разработки способных агентов ИИ
- Стабильные преимущества в задачах на обобщение (инструменты, программирование, научные вычисления)

## Домены исследования

Исследование охватывает два знаний-емких домена, требующих полного спектра агентных способностей:

### 1. Vibe Coding (совместная разработка ПО)
- Реальные запросы из практики программирования
- Синтетические запросы, систематически синтезированные из пул-реквестов на GitHub с помощью GPT-5
- Задачи, связанные с кодированием и разработкой программного обеспечения
- Аутентичные, многоэтапные задачи разработки, богатые контекстом

### 2. Research Workflows (научные исследования)
- Научные рабочие процессы
- Задачи, связанные с исследовательской деятельностью
- Использование инструментов и планирование в научной среде
- Комплексные исследовательские задачи с итерациями и адаптацией

## Методология стратегической курации данных

### Подход к отбору данных
- Вместо накопления данных авторы стратегически отбирают минимальный набор из 78 высококачественных обучающих примеров
- Примеры сосредоточены в двух наукоёмких областях: совместная разработка ПО и научные исследования
- Запросы берутся из реальных профессиональных сценариев и систематически синтезируются из пул-реквестов на GitHub с помощью GPT-5

### Систематический сбор траекторий
- Для каждого из 78 запросов команда собрала полную, успешную последовательность взаимодействий, или «траекторию»
- Траектория Tᵢ — это формальная последовательность действий {aᵢ,₁, ..., aᵢ,ₙᵢ}, которая охватывает весь цикл решения задачи:
  - Рассуждения модели (mᵢ,ⱼ): Анализ, планирование и процесс принятия решений агентом
  - Вызов инструментов моделью (tᵢ,ⱼ): Структурированное обращение к внешним инструментам
  - Наблюдение за средой (oᵢ,ⱼ): Обратная связь от выполнения инструментов и от людей-коллабораторов
- Поскольку записывается весь рабочий процесс до успешного завершения, включая итерации доработки, исправления ошибок и стратегической адаптации, итоговый датасет получается невероятно плотным
- Средняя длина траектории составляет внушительные 42.4 тыс. токенов, благодаря чему каждый из 78 примеров несёт богатый обучающий сигнал

## Интеграция с SII CLI

- Каждая траектория собирается в процессе сотрудничества между экспертами (аспирантами) и GPT-5 в специализированной, богатой инструментами среде под названием SII CLI
- SII CLI обеспечивает среду для совместной работы между человеком и ИИ в сложных сценариях программирования и исследований

## Подход к дообучению (Fine-tuning)

- Использовался файнтюнинг GLM-4.5 (355B) и меньшей модели GLM-4.5-Air (106B)
- Фокус на использовании инструментов и полных траекториях выполнения задач
- Ограниченное количество обучающих примеров (всего 78 примеров, при этом в 128 раз меньше, чем у альтернативных подходов)

## Ключевые инсайты

1. **Качество важнее количества**: Небольшое количество высококачественных примеров (78) может превзойти большие, но менее качественные наборы данных (10 000 примеров) на 53.7 процентных пункта
2. **Стратегическая курация данных**: Важно не просто собирать данные, а тщательно отбирать и аннотировать их, отражая суть агентного поведения
3. **Использование инструментов**: Успешные агенты требуют обучающих примеров, демонстрирующих эффективное использование инструментов в контексте полного рабочего процесса
4. **Длинные траектории**: Длинные и подробные траектории решений (до 42.4k токенов в среднем) могут значительно улучшить способности агента
5. **Внутренние способности улучшаются**: Даже в условиях отсутствия инструментов LIMI превосходит все бейзлайны, демонстрируя улучшение фундаментальных способностей к рассуждению и планированию

## Обобщающая способность и внутреннее улучшение

- LIMI показывает стабильные преимущества в наборе задач на обобщение, включая использование инструментов, кодинг и научные вычисления
- Абляция без доступа к инструментам SII CLI: LIMI превосходит все бейзлайны, включая собственную базовую модель GLM-4.5 (50.0% против 48.7%)
- Это демонстрирует, что методология обучения действительно улучшает фундаментальные способности к рассуждению и планированию, а не только владение инструментами
- При возвращении инструментов производительность усиливается, показывая синергию между внутренними способностями и взаимодействием со средой

## Значение и влияние

Значимость этой работы трудно переоценить. Она предлагает ясный, эмпирически подтверждённый путь к созданию более способных и надёжных ИИ-агентов устойчивым и ресурсоэффективным способом. Смещая фокус с количества данных на их качество, парадигма LIMI делает разработку высокопроизводительных специализированных агентов более доступной, ускоряя переход индустрии к «работающему ИИ».

## Ограничения

- Успех методологии продемонстрирован в двух конкретных, хотя и широких, областях
- Применимость к принципиально иным агентным сценариям, таким как робототехника или управление физическими объектами в реальном времени, остаётся открытым вопросом
- Процесс отбора данных экспертами, хоть и очень эффективен, трудоёмок и может не так легко масштабироваться, как автоматизированные пайплайны данных
- Зависимость от конкретной проприетарной среды выполнения (SII CLI) также является препятствием для полной воспроизводимости результатов сообществом

## Связи с другими темами

- [[ai/agents/tool_usage.md]] - Использование инструментов в агентных системах, ключевой аспект подхода LIMI
- [[ai/agents/sii_cli_framework.md]] - Среда выполнения SII CLI, в которой собирались траектории для LIMI
- [[ai/llm/data_quality.md]] - Качество данных для крупных языковых моделей, фундаментальный аспект LIMI
- [[ai/agents/ai_agent_benchmarks.md]] - Бенчмарки для оценки агентов ИИ, включая AgencyBench
- [[ai/agents/fine_tuning_approaches.md]] - Подходы к дообучению агентов ИИ, включая методы, используемые в LIMI
- [[ai/agents/human_in_the_loop_training.md]] - Обучение с участием человека, использованное в сборе качественных траекторий
- [[ai/agents/agencebench.md]] - Бенчмарк AgencyBench, на котором были достигнуты впечатляющие результаты

## Применение на практике

LIMI представляет собой важный сдвиг в парадигме разработки агентов ИИ, подчеркивая, что:

- Меньше, но качественнее данных может привести к лучшим результатам
- Сфокусированность на домене (программирование и исследования) дает значительные преимущества
- Ручная аннотация и курация могут быть более эффективными, чем автоматическое масштабирование
- Длинные и подробные траектории решения задач критически важны для обучения агентов
- Фокус индустрии должен сместиться с вычислительной «грубой силы» на интеллектуальное мастерство инженерии высококачественных данных

## Источники

- [Статья LIMI: Less is More for Agency](https://arxiv.org/abs/2509.17567) - Оригинальная статья о LIMI
- [Ревью статьи](https://arxiviq.substack.com/p/limi-less-is-more-for-agency) - Подробный анализ статьи
- [Код](https://github.com/GAIR-NLP/SII-CLI) - Репозиторий с кодом SII CLI
- [Бенчмарк](https://github.com/GAIR-NLP/AgencyBench) - Репозиторий с AgencyBench