# ToolOrchestra: Фреймворк для оркестрации моделей и инструментов

## Краткое описание
ToolOrchestra - это фреймворк, разработанный NVIDIA для обучения легковесных языковых моделей (8B параметров) выступать в роли умных маршрутизаторов для зоопарка инструментов и мощных моделей-экспертов. С помощью алгоритма GRPO и массивного синтетического датасета ToolScale, полученный оркестратор учится балансировать точность решения с ценой вычислений и предпочтениями пользователя.

## Основная информация

### Контекст и проблема
Текущий подход к агентам часто страдает синдромом "God Model": одна фронтир-модель (условная GPT-5 или Claude Opus) пытается делать всё сама — от креатива до исполнения кода. Она часто использует свои внутренние веса даже тогда, когда внешний инструмент справился бы быстрее и дешевле. Главная проблема здесь — предвзятость самовозвеличивания (self-enhancement bias). Когда большую модель просят выбрать инструмент, она с нарциссическим упорством выбирает саму себя или свои вариации, игнорируя сложность задачи. В пилотном эксперименте GPT-5 выбирала GPT-5-mini или себя почти в 98% случаев, игнорируя более выгодные альтернативы. В итоге получаем систему точную, но экономически разорительную.

### Решение: ToolOrchestra
ToolOrchestra предлагает радикально новый подход, разделяющий "планировщика" и "исполнителя". Вместо того чтобы полагаться на одну мощную модель, система использует легковесную модель-оркестратор (8B параметров), которая умело распределяет задачи по наиболее подходящим инструментам и специализированным моделям. Основные компоненты:

- **Оркестратор (8B модель)**: Небольшая модель (на базе Qwen3-8B), действующая как умный маршрутизатор
- **Зоопарк инструментов**: Коллекция специализированных моделей и внешних инструментов
- **Вектор предпочтений**: Механизм, позволяющий балансировать между точностью, вычислительными затратами и другими критериями

### Архитектура и работа
В отличие от традиционного подхода, где задача формулируется как бинарный результат (правильно/неправильно), ToolOrchestra использует вектор предпочтений P = [p_outcome, p_compute, p_latency, ...]. Этот вектор явно кодирует компромиссы между различными целями. Оркестратор максимизирует составную награду R(τ), которая считается как скалярное произведение метрик траектории и вектора предпочтений. Вопрос смещается с "правдив ли ответ?" на "правдив ли ответ, по карману ли он нам и получен ли разрешённым способом?".

Пример: для запроса "Каково число Алона-Тарси для графа K_1000,1000?" традиционная GPT-5 начнёт "думать" внутри себя или писать скрипт с нуля, сжигая дорогие токены. В ToolOrchestra 8B-модель анализирует промт, понимает, что своих знаний мало, но задача чисто математическая. Она находит спец-модель, например, Qwen2.5-Math-72B, и генерирует вызов, передаёт параметры, получает результат. При этом она постоянно взвешивает текущий кост относительно вектора P.

### Результаты
На бенчмарке Humanity's Last Exam (HLE), устойчивом к гуглению, Orchestrator-8B выбивает 37.1%, обходя монолитную GPT-5 (35.1%), при этом стоимость инференса падает в разы. На бенчмарке τ²-Bench Оркестратор вызывает дорогую GPT-5 лишь в ~40% случаев, сгружая рутину на спец-модели или Python.

## Новые концепции и термины

- **"God Model" curse**: Ситуация, когда большая модель пытается решить всё сама, вместо использования более эффективных инструментов
- **Оркестратор**: Легковесная модель, управляющая использованием других инструментов и моделей
- **Вектор предпочтений**: Многомерный вектор, определяющий важность различных критериев (точность, вычислительные затраты, задержка и т.д.)
- **Самовозвеличивание (self-enhancement bias)**: Предвзятость, при которой крупные модели предпочитают использовать себя вместо внешних инструментов

## Примеры применения
- Решение сложных математических задач с использованием специализированных моделей
- Решение задач с балансировкой между точностью и стоимостью вычислений
- Системы, где важны приватность или ограничения по использованию API

## Связи с другими темами
- [[multi_model_orchestrators.md]] - Общие принципы оркестрации нескольких моделей
- [[../llm/tools/metatool_framework.md]] - Современный подход к обучению LLM освоению инструментов
- [[../llm/mixture_of_experts_architecture.md]] - Архитектура, где используется маршрутизация между экспертами

## Источники
1. Su, Hongjin, Diao, Shizhe, Lu, Ximing, et al. "ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration" (2025). arXiv:2511.21689
2. NVIDIA Research. "ToolOrchestra: Efficient Model and Tool Orchestration" [https://research.nvidia.com/labs/lpr/ToolOrchestra/](https://research.nvidia.com/labs/lpr/ToolOrchestra/)
3. "Humanity's Last Exam: A Comprehensive Benchmark" (2025)
4. "τ²-Bench: A Benchmark for Tool Orchestration" (2025)

## Медиа

![Overview of Orchestrator](../../../media/img_1764747677_aqadcqtrgwnygul_figure_2_overview_of_orchestrator.jpg)

**Рисунок 2:** Обзор оркестратора. Для задачи оркестратор чередует рассуждение и вызовы инструментов в несколько итераций для её решения. Оркестратор взаимодействует с разнообразным набором инструментов, включая базовые инструменты (поиск в Интернете, функции такие как get_flight_status и др.), специализированные LLM (модели кодирования, математические модели и др.) и генералистские LLM (GPT-5, Claude Opus 4.1 и др.). При обучении в рамках ToolOrchestra, оркестратор совместно оптимизируется по результативности, эффективности и предпочтениям через обучение с подкреплением.

![ToolOrchestra shows consistently strong performance](../../../media/img_1764747677_aqaddqtrgwnygul_figure_1_toolorchestra_shows_consistentl.jpg)

**Рисунок 1:** ToolOrchestra демонстрирует стабильно высокую производительность на HLE, FRAMES и τ²-Bench с превосходной эффективностью по стоимости.

![Comparison of Orchestrator-8B with baselines](../../../media/img_1764747677_aqadcwtrgwnygul_table_1_comparison_of_orchestrator_8b.jpg)

**Таблица 1:** Сравнение Orchestrator-8B с базовыми моделями (LLM с подсказками). Llama-Nemotron-49B обозначает Llama-3.3-Nemotron-Super-49B-v1. Стоимость в центах США, латентность в минутах, усредненные между HLE и Frames. Дополнительная статистика эффективности на τ²-Bench представлена в Таблице 16 в Приложении. Базовые инструменты включают доменные функции, поиск и интерпретатор кода.

![Tool-calling preferences exhibited by different models](../../../media/img_1764747677_aqadcatrgwnygul9_figure_3_tool_calling_preferences_exhibi.jpg)

**Рисунок 3:** Предпочтения в вызовах инструментов, проявляемые различными моделями. GPT-5 склонна вызывать GPT-5-mini большую часть времени, в то время как Qwen3-8B в значительной степени полагается на GPT-5.