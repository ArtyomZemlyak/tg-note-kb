# Результаты трека GigaMemory в AI Journey Contest 2025

## Общая информация о конкурсе

GigaMemory - это трек соревнования AI Journey Contest 2025, направленный на создание механизма долговременной памяти для LLM (Large Language Models). Конкурс был организован командой SberAI RnD для B2C решений и проходил до 30 октября 2025 года. Более 90 команд успешно представили свои решения, что сделало этот трек самым популярным среди всех направлений конкурса.

Цель трека - создать автономный модуль памяти, который:
- Извлекает факты о конкретном собеседнике из диалогов (привычки, предпочтения, роли, навыки, события)
- Сохраняет их в произвольном формате данных и типе
- Применяет память во время генерации ответа на основе вопросов пользователя

## Технические требования

- Решение должно работать с диалогами, охватывающими недели и месяцы взаимодействия пользователя - более 100 000 токенов
- Использование фиксированного Docker-образа с предустановленными библиотеками и моделью GigaChat Lite (без доступа к интернету)
- Максимальный размер решения: 5 ГБ, ограничение диска: 10 ГБ
- Максимальное время выполнения: 8 часов (7 для генерации, 1 для оценки)
- Аппаратное обеспечение: 243GB RAM, 16 CPU cores, 1 GPU Tesla A100 (80GB)

## Категории вопросов

Оценка решения проводилась по четырем категориям вопросов:
1. **Fact Equal Session** - ответы внутри одной сессии
2. **Info Consolidation** - требует объединения информации из нескольких сессий
3. **Info Updating** - данные о пользователе изменяются с течением времени
4. **No Info** - вопросы без ответов в диалоге

## Результаты конкурса

### 1-е место: ammarali32&WalaaSO

**Использованные модели:** Qwen3-8B-AWQ и GigaChat-Light-20b

**Подход:**
- Фокус на классификации релевантности и верификации финального ответа
- Хранили всю историю диалогов в памяти, фильтровали релевантные сообщения с помощью GigaChat
- Использовали Qwen для логических рассуждений и GigaChat для коррекции финального ответа
- Решение было основано на адаптации традиционного RAG-подхода с дополнительной верификацией

### 2-е место: Denisiuskley

**Использованные модели:** Qwen-4B и GigaChat

**Подход:**
- Сложный пайплайн с многоуровневым отбором релевантности
- Реализовали агентную систему, а не традиционный RAG
- Использовали затухание по времени для весов сообщений
- Применили Qwen-4B для быстрой фильтрации и GigaChat для финального ответа
- Инновационный подход к управлению временными приоритетами в долгосрочной памяти

### 3-е место: WealthLab

**Использованные модели:** bge-m3 эмбеддер

**Подход:**
- Классический RAG-подход с использованием энкодера bge-m3
- Векторный поиск по релевантным фрагментам диалога
- Иерархическая чанковка (фрагменты по 256 и 32 токена)
- Использовали косинусное сходство для определения релевантности
- Стандартный, но эффективно реализованный подход к извлечению информации

### 4-е место: OPIA

**Использованные модели:** FRIDA эмбеддинги и bge-reranker-v2-m3

**Подход:**
- RAG с векторным поиском, использующий эмбеддинги FRIDA
- Кросс-реранжер (bge-reranker-v2-m3) для повышения точности
- Многоступенчатая агрегация ответов для улучшения точности
- Использовали несколько системных промптов с агрегацией ответов
- Сосредоточились на улучшении точности за счет пост-обработки

## Общие выводы

Конкуренция продемонстрировала разнообразие подходов к реализации долгосрочной памяти для LLM:
- Победители использовали более сложные и инновационные подходы, чем простое накопление контекста
- Среди призеров были представлены как классические RAG-подходы, так и агентные архитектуры
- Успешные решения уделяли особое внимание фильтрации релевантной информации и верификации ответов
- Качество памяти определялось не только точностью извлечения, но и способностью к обновлению информации
- Команды активно использовали комбинации различных моделей (Qwen, GigaChat) для решения разных подзадач

## Метрика оценки

Оценка проводилась с использованием метрики точности с подходом "LLM как судья" - ответы считались корректными, если они семантически соответствовали эталону. Окончательные результаты рассчитывались на тестовом наборе, валидационный и тестовый наборы были примерно равны по размеру.

## Значение результатов

Результаты конкурса GigaMemory показали, что существует множество подходов к созданию долгосрочной персональной памяти для LLM, и что инновации в этой области активно развиваются. Победившие решения демонстрируют, что можно достичь высокой точности при работе с действительно длинными последовательностями (более 100 000 токенов), что открывает перспективы для создания более персонализированных и контекстно-зависимых ИИ-ассистентов.

## Связанные темы

- [[./gigamemory_track.md]] - описание трека GigaMemory
- [[../aij_contest_2025.md]] - основной файл о конкурсе AI Journey 2025
- [[../../llm/memory/gigamemory_architecture.md]] - архитектура GigaMemory
- [[../../llm/models/gigachat_overview.md]] - модель GigaChat, использованная в конкурсе
- [[../../rag/index.md]] - подходы RAG, использованные в решениях участников

## Источники

1. [Результаты конкурса GigaMemory - AI Journey Contest 2025](https://habr.com/ru/companies/sberbank/articles/974310/) - Основная статья, описывающая результаты конкурса GigaMemory, включая подходы победителей и технические детали