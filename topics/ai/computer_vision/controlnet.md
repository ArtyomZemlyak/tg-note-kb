# ControlNet в генерации изображений

```metadata
category: computer_vision
subcategory: image_generation
tags: controlnet, image-generation, computer-vision, conditional-generation, stable-diffusion
```

## Определение

ControlNet - это мощная нейронная сеть, которая позволяет добавлять дополнительные условия к моделям генерации изображений, таким как Stable Diffusion или Z-Image Turbo. Это позволяет пользователям получать точный контроль над процессом генерации, используя визуальные подсказки в дополнение к текстовым запросам.

## Архитектура

ControlNet архитектура основана на добавлении дополнительных "управляющих" потоков к существующим диффузионным моделям без необходимости перетренировки основной модели. Контрольные условия могут включать:

- Карты краев (Canny)
- Карты глубины (Depth)
- Карты нормалей (Normal Maps)
- Позы человека (Pose)
- Линейные сегменты (MLSD)
- Эскизы и наброски (Scribble/Sketch)

## Типы ControlNet

### Canny ControlNet
Использует карты краев Canny для сохранения общей структуры изображения. Эффективен для генерации изображений с сохранением архитектурных линий и общего макета.

### HED (Holistically-Nested Edge Detection) ControlNet
Глубокое обнаружение краев, обеспечивающее более детализированные и точные контуры по сравнению с Canny.

### Depth ControlNet
Использует карты глубины для сохранения пространственной структуры сцены, что особенно полезно для сохранения перспективы и расстояний в генерируемом изображении.

### Pose ControlNet
Обнаруживает позы человека и позволяет генерировать изображения с заданными позами, что особенно полезно для генерации людей и персонажей.

### MLSD (Multi-scale Line Segment Detection) ControlNet
Обнаруживает линейные сегменты на разных масштабах, эффективно сохраняя геометрическую структуру архитектурных и технических сцен.

## Применение

ControlNet позволяет:
- Сохранять структуру при генерации изображений по текстовому запросу
- Контролировать позы, глубину и линии в генерируемых изображениях
- Создавать изображения с точным контролем над пространственными аспектами
- Редактировать изображения с сохранением исходной структуры
- Интегрировать визуальные и текстовые подсказки для лучшего результата

## Примеры использования

- Генерация архитектурных визуализаций с сохранением линий и углов
- Создание изображений с заданными позами людей
- Сохранение перспективы при изменении сцены
- Структурное редактирование изображений
- Генерация изображений с контролируемыми краями и деталями

## Интеграция с моделями

ControlNet может быть интегрирован с различными диффузионными моделями:
- Stable Diffusion (оригинальная интеграция)
- Z-Image Turbo (новая интеграция от Alibaba)
- Другие диффузионные модели

## Связи с другими темами

- [[z_image_turbo_controlnet.md]] - Интеграция ControlNet с Z-Image Turbo
- [[image_generation.md]] - Общая информация о генерации изображений
- [[z_image_turbo.md]] - Ускоренная модель генерации от Alibaba
- [[diffusion_models.md]] - Диффузионные модели для генерации изображений

## Источники

1. [Hugging Face Diffusers: ControlNet Documentation](https://huggingface.co/docs/diffusers/using-diffusers/controlnet) - Официальная документация ControlNet
2. [Stable Diffusion Art: Complete Guide to ControlNet](https://stable-diffusion-art.com/controlnet/) - Руководство по ControlNet
3. [ML Conference: ControlNet Image Generation](https://mlconference.ai/generative-ai-content/controlnet-image-generation/) - Обзор ControlNet
4. [Iterate.AI: ControlNet Glossary](https://www.iterate.ai/ai-glossary/what-is-controlnet) - Определение и объяснение ControlNet