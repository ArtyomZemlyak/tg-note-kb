# PixelDiT: Pixel Diffusion Transformers для генерации изображений

## Краткое описание

PixelDiT (Pixel Diffusion Transformers) - это трансформерная диффузионная модель, которая напрямую выполняет денойзинг в пиксельном пространстве, отказываясь от латентной диффузии с использованием VAE. Модель состоит из двухуровневого каскада: патч-уровневой сети, обрабатывающей патчи, и пиксель-уровневой сети, работающей непосредственно с пикселями.

[[../../../../../media/img_1765027380_aqadpq1rg80gmel_5a0c32a13125b7fd38a2d97a99a72d90.jpg]]

**Изображение демонстрирует:** архитектуру PixelDiT, показывающую двухуровневую структуру с патч-уровневой и пиксель-уровневой сетями.

## Основная информация

### Введение

В последние годы в диффузионных моделях наблюдается тенденция к отказу от латентной диффузии с использованием VAE в пользу генерации напрямую в пиксельном пространстве. PixelDiT представляет собой решение, которое якобы обеспечивает лучшее качество по сравнению с предыдущими подходами, особенно в детализированной (кристальной) генерации [^1].

### Архитектура

PixelDiT использует двухуровневый каскад:

1. **Патч-уровневая сеть** - трансформер, обрабатывающий патчи (в основном 16x16 пикселей) как токены. Принимает на вход либо метку класса, либо текст [^2].

2. **Пиксель-уровневая сеть** - более примечательная часть архитектуры, использует пиксель-уровневую модуляцию (умножение на скаляр и сдвиг) на основе выхода патч-уровневой сети. Чтобы параметры модуляции были специфичны для каждого пикселя, линейный слой разворачивает карту признаков патчей в p x p (где p - размер патча) [^3].

### Технические особенности

- Для вычислительной эффективности полное внимание между всеми пикселями заменяется группировкой токенов в патчи (p x p), затем снова разворачивается в исходную последовательность перед вычислением внимания [^4].
- Пиксель-уровневая сеть обычно делается неглубокой и неширокой (2-4 слоя) с размерностью скрытого пространства 16, что делает вычисления доступными даже для высокоразмерных изображений [^5].
- Для обучения используют REPA с признаками DINOv2 для улучшения метрик и сходимости [^6].

### Эксперименты и результаты

- Обучают как class-condition, так и text-2-image модели [^7].
- Модель показывает хорошие FID-метрики, превосходя предыдущие подходы пиксельной диффузии, но уступая немного SOTA латентным подходам [^8].
- В абляционном анализе показывают, что простое обучение DiT на патчах работает плохо, внимание без сжатия токенов становится вычислительно затратным, а пиксельная модуляция помогает [^9].
- Уменьшение размера патчей не сильно улучшает качество, особенно для больших моделей, при этом кратно увеличивая вычислительную стоимость, поэтому патчи 16x16 выбирают как оптимальные [^10].
- В текст-в-изображение задаче обучают MMDiT-модель с энкодером Gemma-2 размером 1.3B параметров, которая показывает довольно неплохие метрики [^11].

## Новые концепции и термины

- **Пиксель-уровневая модуляция** - техника модуляции (умножение на скаляр и сдвиг) на основе выхода патч-уровневой сети, специфичная для каждого пикселя
- **Двухуровневый каскад** - архитектура, состоящая из патч-уровневой и пиксель-уровневой сетей
- **Отказ от латентной диффузии** - подход, при котором модель работает напрямую в пиксельном пространстве, без сжатия через VAE
- **REPA** - метод, используемый вместе с признаками DINOv2 для улучшения метрик и сходимости

## Примеры применения

- Класс-условная генерация изображений
- Текст-в-изображение генерация
- Высококачественная генерация детализированных изображений
- Генерация изображений без использования VAE для сжатия

## Сравнение с другими моделями

PixelDiT сравнивается с:
- Классическими диффузионными трансформерами (DiT), работающими на патчах
- VAE-базированными моделями (например, FLUX, Wan, Qwen-Image), которые обладают хорошим качеством реконструкции в латентном пространстве
- Пиксельными диффузионными моделями предыдущих подходов

## Связи с другими темами

[[../diffusion_transformer.md]] - Общая архитектура диффузионных трансформеров, на которой основан PixelDiT
[[../../llm/diffusion_models.md]] - Общие принципы диффузионных моделей
[[../image_generation.md]] - Область применения диффузионных моделей
[[../variational_autoencoders.md]] - VAE, которые PixelDiT обходит, отказываясь от латентной диффузии
[[../jit_diffusion_models.md]] - Just Image Transformer, разновидность DiT для прямой обработки в пиксельном пространстве, схожий с подходом PixelDiT
[[../diffusion_pixel_space.md]] - Подход к диффузионным моделям в пиксельном пространстве через x0-prediction, связан с PixelDiT подходом

## Источники

[^1]: "PixelDiT: Pixel Diffusion Transformers for Image Generation" - Основная научная статья, описывающая архитектуру модели, которая работает напрямую в пиксельном пространстве, отказываясь от латентной диффузии с VAE
[^2]: Статья о PixelDiT - патч-уровневая сеть как трансформер, обрабатывающий патчи как токены
[^3]: Статья о PixelDiT - пиксель-уровневая модуляция на основе выхода патч-уровневой сети
[^4]: Статья о PixelDiT - группировка токенов для вычислительной эффективности
[^5]: Статья о PixelDiT - пиксель-уровневая сеть с небольшой глубиной и размерностью
[^6]: Статья о PixelDiT - использование REPA и DINOv2 признаков
[^7]: Статья о PixelDiT - обучение class-condition и text-2-image моделей
[^8]: Статья о PixelDiT - результаты по FID метрике
[^9]: Статья о PixelDiT - абляционный анализ и преимущества пиксельной модуляции
[^10]: Статья о PixelDiT - оптимальный размер патчей 16x16
[^11]: Статья о PixelDiT - MMDiT модель с Gemma-2 энкодером