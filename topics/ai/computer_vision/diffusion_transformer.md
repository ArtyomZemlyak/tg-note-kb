# Diffusion Transformer (DiT)

## Общее описание

Diffusion Transformer (DiT) - это архитектура, которая применяет трансформеры для реализации диффузионных моделей. В отличие от традиционных подходов, использующих ResNet или U-Net в качестве backbone, DiT использует архитектуру трансформера для моделирования сложных зависимостей в данных на каждом шаге диффузионного процесса.

## Архитектурные особенности

### Основные компоненты
- **Transformer blocks**: состоят из слоев мульти-головного внимания и MLP
- **Timestep embedding**: специальное представление текущего шага времени в диффузионном процессе
- **Conditional information integration**: методы интеграции дополнительной информации (например, классов или текстовых описаний)
- **Patch-based processing**: изображения разбиваются на патчи, как в стандартном ViT

### Пространственная обработка
- ДиТ может работать как в латентном пространстве (как в Latent DiT), так и в пиксельном пространстве
- В латентном подходе изображения сначала сжимаются через автоэнкодер, затем обрабатываются трансформером
- В пиксельном подходе (как в JiT - Just Image Transformer) обработка происходит напрямую в пиксельном пространстве

## Сравнение с другими архитектурами

| Архитектура | Преимущества | Ограничения |
|-------------|--------------|-------------|
| U-Net | Хорошая пространственная локализация | Ограничения в моделировании глобальных зависимостей |
| ResNet | Простота и эффективность | Ограниченные возможности внимания |
| DiT | Моделирование глобальных зависимостей | Высокая вычислительная сложность |
| JiT | Прямая обработка в пиксельном пространстве | Еще выше вычислительная сложность |

## Вариации DiT

### Latent DiT
- Использует автоэнкодер для сжатия в латентное пространство
- Более вычислительно эффективен
- Популярен в таких моделях как Stable Diffusion

### Pixel DiT (JiT - Just Image Transformer)
- Работает непосредственно в пиксельном пространстве
- Не требует вспомогательного автоэнкодера
- Согласно статье "Back to Basics: Let Denoising Generative Models Denoise", может быть более эффективным с x0-prediction по сравнению с ε-prediction или v-prediction

## Применение

- Генерация изображений высокого качества
- Видео-генерация (например, Kandinsky Video 5)
- Мультимодальная генерация
- Сpeech-to-text (в ASR системах, как в Drax)
- Текст-в-изображение модели нового поколения (например, Seedream v4.5)

## Преимущества DiT

- **Глобальное внимание**: способность моделировать зависимости между всеми пикселями/патчами
- **Масштабируемость**: качество улучшается с увеличением размера модели
- **Унификация**: та же архитектура, что и в других доменах (NLP, etc.)

## Ограничения

- **Высокая вычислительная сложность**: особенно для обработки больших изображений
- **Память**: квадратичная зависимость потребления памяти от размера изображения
- **Требует больших данных**: лучше работает при обучении на больших датасетах

## Связь с другими темами

- [[vision_transformer.md]] - основы Vision Transformer, на которых основан DiT
- [[diffusion_models.md|Диффузионные модели]] - теоретические основы диффузионных моделей
- [[jit_diffusion_models.md|Just Image Transformer в диффузионных моделях]] - разновидность DiT, работающая в пиксельном пространстве
- [[image_generation.md|Генерация изображений]] - области применения DiT
- [[z_image_turbo_controlnet.md]] - Пример мульти-условного ControlNet для Z-Image Turbo, использующего диффузионные трансформеры
- [[kandinsky_video_5.md]] - пример применения DiT в видео-генерации
- [[../../ai_contests/neurips_2025.md]] - Награды NeurIPS 2025, включающие исследования динамики обучения диффузионных моделей

## Источники

1. [Scalable Diffusion Models with Transformers](https://arxiv.org/abs/2212.09748) - оригинальная статья о DiT (Diffusion Transformers)
2. [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720) - сравнение различных подходов предсказания в DiT и JiT