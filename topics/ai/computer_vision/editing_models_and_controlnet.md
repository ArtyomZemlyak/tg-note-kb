# Редактирующие модели и ControlNet (Editing Models and ControlNet)

```metadata
category: computer_vision
subcategory: image_generation
tags: editing-models, controlnet, image-editing, conditional-generation
```

## Определение

Редактирующие модели - это тип моделей генерации изображений, которые позволяют вносить изменения в существующие изображения или создавать новые изображения на основе референсов. Часто редактирующие модели сами по себе представляют собой ControlNet-модели.

## Принцип работы

### Использование референсов
Редактирующие модели могут использовать различные типы референсов для генерации:
- Карты глубины (depth maps)
- Canny края (Canny edges)
- Скелетные структуры позы (pose skeletons)
- Другие условные изображения

Модель (условно названная "Nanabana" в источнике) может принимать на вход глубину или canny и использовать их как референс, чтобы сгенерировать подобное изображение.

### Позы и скелетные референсы
- Для поз более сложные подходы требуются
- В идеале давать модели 3D-болван как референс, тогда она лучше понимает позу
- Модель может сохранять позу с изображения, но полностью трансформировать персонажа в другой лук

### Использование OpenPose
Использование скелета от OpenPose позволяет настроить модель (условно "Банану") на воспроизведение заданной позы. Хотя результат может потребовать настройки параметров, модель справляется с задачей.

## Применение

### Основные применения редактирующих моделей:
- Редактирование существующих изображений
- Генерация изображений на основе структурных референсов
- Сохранение позы при смене стиля персонажа
- Использование 3D-скелетов для более точного контроля позы

## Особенности

### Сравнение подходов:
- 2D скелеты (например, от OpenPose) просты в использовании, но менее точны
- 3D-модели обеспечивают лучшее понимание пространственной структуры
- Использование референсов позволяет точно контролировать генерацию

## Связи с другими темами

- [[controlnet.md]] - ControlNet и его применение в генерации изображений
- [[pose_estimation_in_image_generation.md]] - Оценка позы в генерации изображений
- [[z_image_turbo_controlnet.md]] - Интеграция ControlNet с Z-Image Turbo
- [[image_generation.md]] - Общая информация о генерации изображений
- [[diffusion_models.md]] - Диффузионные модели для генерации изображений

## Изображения

![Пример редактирующей модели с использованием референса](../../../media/img_1764687829_aqaddqxrgx3veel_image.jpg)

**Изображение показывает:** Пример использования редактирующей модели с референсным изображением для генерации.

![Сравнение результатов с разными типами референсов](../../../media/img_1764687829_aqaddgxrgx3veel_7b7c5dc8d2111b5e2dafff58cbda4d8b.jpg)

**Изображение показывает:** Сравнение результатов генерации с использованием разных типов референсов (глубина, canny и т.д.).

![Трансформация персонажа при сохранении позы](../../../media/img_1764687829_aqaddwxrgx3veel_image_image.jpg)

**Изображение показывает:** Пример трансформации персонажа в другой лук при сохранении исходной позы с использованием редактирующей модели.

## Источники

1. Входящая информация от пользователя о редактирующих моделях и их использовании
2. [Hugging Face Diffusers: ControlNet Documentation](https://huggingface.co/docs/diffusers/using-diffusers/controlnet) - Официальная документация ControlNet
3. [ControlNet: A Complete Guide](https://stable-diffusion-art.com/controlnet/) - Полное руководство по ControlNet