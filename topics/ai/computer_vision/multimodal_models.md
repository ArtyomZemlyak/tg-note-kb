# Мультимодальные модели (CLIP, SigLIP)

## Общие понятия

Мультимодальные модели - это тип нейронных сетей, которые могут обрабатывать и соединять информацию из разных режимов или типов данных (например, изображения и текст одновременно). Они позволяют находить сходства между разными типами данных.

## CLIP (Contrastive Language-Image Pre-training)

CLIP - это мультимодельная архитектура, разработанная OpenAI, которая обучается на парах изображение-текст.

### Архитектура CLIP
- Общий энкодер для изображений и текста
- Обучение на большом наборе пар изображение-описание
- Контрастивное обучение для выравнивания представлений

### Применение CLIP
- Нулевая классификация изображений (zero-shot image classification)
- Изображения по текстовому запросу
- Поиск изображений по текстовому описанию
- Оценка сходства изображений и текста

## SigLIP (Sigmoid Loss for Language Image Pre-training)

SigLIP - это улучшенная версия CLIP, разработанная Google, которая использует сигмоидную функцию потерь вместо softmax.

### Отличия SigLIP от CLIP
- Использует сигмоидную функцию потерь вместо softmax
- Позволяет использовать отрицательные примеры независимо для каждого положительного примера
- Лучшая производительность на задачах сопоставления изображений и текста
- Обучение на отдельных парах изображение-текст, а не на батчах

### Архитектура SigLIP
- Общий энкодер изображений (часто Vision Transformer)
- Общий энкодер текста (обычно Transformer)
- Объединение через скалярное произведение

### Преимущества SigLIP
- Более эффективное использование данных
- Лучшее качество на задачах нулевой классификации
- Возможность обучения на несбалансированных датасетах

## Применение в поиске по фото

### В системе Wildberries
- SigLIP-эмбеддинги используются для преобразования изображений в векторы
- Эти векторы используются для поиска похожих товаров в векторной базе данных
- Позволяет находить товары по визуальному сходству

### Процесс преобразования
1. Изображение проходит через энкодер изображений SigLIP
2. Получается вектор в многомерном пространстве
3. Вектор отправляется в Qdrant для поиска ближайших соседей
4. Найденные товары возвращаются пользователю

## Сравнение CLIP и SigLIP

| Особенность | CLIP | SigLIP |
|-------------|------|--------|
| Функция потерь | Softmax | Sigmoid |
| Обработка отрицательных примеров | В батче | Индивидуально |
| Эффективность | Хорошая | Лучше |
| Требования к данным | Балансировка | Гибче |
| Качество сопоставления | Высокое | Высокое/лучше |

## Другие мультимодальные модели

### ALIGN (A Large-scale ImaGe and Noisy-text embedding)
- Ранняя работа в мультимодальных представлениях
- Использует огромные датасеты с шумными описаниями

### ALBEF (Align before Fuse)
- Сначала выравнивает изображения и текст
- Затем объединяет информацию для задач более высокого уровня

### Ming (от inclusionAI)
- Семейство мультимодальных моделей с архитектурой Sparse Mixture-of-Experts
- Поддержка ввода (изображения, текст, видео, аудио) и вывода (изображения, текст, аудио) в различных модальностях
- Достижение рекордных результатов в распознавании речи и диалектов
- Использование парадигмы генеративной сегментации как редактирования

### Seedream v4.5 (от ByteDance)
- Современная модель генерации изображений с высоким качеством текста и типографики
- Объединяет генерацию и редактирование изображений в единой архитектуре
- Особенности: сохранение материалов и деталей, интеллектуальная типографика, реалистичная генерация персонажей, когерентность при многократной ссылке
- Поддержка генерации до 4K разрешения
- Интеграция различных модальностей для улучшения качества генерации

### X-Fusion
- Фреймворк, добавляющий новую модальность (генерацию изображений) в замороженные LLM
- Использует двухбашенную архитектуру: одна башня заморожена для текста, другая дообучается для визуальных данных
- Интегрирует диффузионные и токенные подходы для мультимодальной генерации

## Фреймворки для мультимодальных моделей

### LMMs Engine
- Единый движок для обучения мультимодальных моделей
- Поддерживает 19+ архитектур, включая Qwen3-VL, Qwen2.5-Omni, LLaVA-OneVision и другие
- Простая, гибкая и мощная архитектура для обучения моделей, понимающих текст, изображения, аудио и видео
- Включает оптимизации производительности: FSDP2, Flash Attention, Liger kernels и другие

## Future направления

- Лучшая интеграция с LLM
- Улучшение качества на различных языках
- Расширение на другие модальности (аудио, видео)
- Более эффективные архитектуры для ресурсоограниченных устройств
- Парадигма генеративной сегментации как редактирования (Generative Segmentation-as-Editing) для более точного контроля

## Связи с другими темами

- [[ming.md|Ming]] - Современная мультимодальная модель с семейством архитектур
- [[ming_flash_omni_preview.md|Ming Flash Omni Preview]] - Флагманская модель с архитектурой Sparse MoE
- [[x_fusion.md|X-Fusion]] - Фреймворк для добавления визуальной генерации в замороженные LLM
- [[dual_tower_architecture.md|Двухбашенная архитектура]] - Архитектурный подход, используемый в X-Fusion
- [[diffusion_llm_integration.md|Интеграция диффузионных моделей с LLM]] - Способы объединения диффузионных моделей и LLM
- [[image_generation/seedream_v4_5.md|Seedream v4.5]] - Современная модель генерации изображений от ByteDance с улучшенной типографикой и возможностями редактирования
- [[ai/computer_vision/visual_search/wildberries_photo_search.md]] - Использование SigLIP в поиске по фото
- [[../ocr/object_detection_yolo_ocr.md]] - Комбинация визуальных и текстовых данных
- [[ai/llm/foundation_models.md]] - Базовые модели для мультимодальных приложений
- [[ai/computer_vision/vector_search.md]] - Использование эмбеддингов для поиска
- [[ai/machine_learning/machine_learning.md]] - Общие понятия о машинном обучении и нейронных сетях
- [[ai/llm/data_quality.md]] - Использование LLM для генерации тегов (как в Wildberries)
- [[canvas_to_image.md]] - Подход к мультимодальному контролю в генерации изображений через холст