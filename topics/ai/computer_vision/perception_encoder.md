# Perception Encoder: Лучшие визуальные эмбеддинги не на выходе сети

![Perception Encoder: The best visual embeddings are not at the output of the network](../../../media/img_1765199234_aqad9xjrgwzjkul_the_mission_mbeddings_are_not.jpg) <!-- TODO: Broken image path -->

**Изображение:** Основная концепция Perception Encoder - эмбеддинги не на выходе сети

## Обзор

Perception Encoder (PE) - это семейство передовых визуальных энкодеров от Meta AI для задач понимания изображений и видео. Основная идея модели заключается в том, что лучшие визуальные эмбеддинги находятся не в последнем слое сети, а в промежуточных слоях, что противоречит традиционному подходу.

## Ключевая идея

Традиционные визуальные энкодеры извлекают эмбеддинги из последнего слоя трансформера, но Perception Encoder показывает, что промежуточные слои содержат более богатую и полезную информацию для downstream-задач. Это открытие стало результатом анализа attention maps, где были обнаружены глобальные токены на определённых слоях.

## Архитектура и обучение

![Perception Encoder Architecture](../../../media/img_1765199234_aqad9hjrgwzjkul_image_perception_encoder.jpg) <!-- TODO: Broken image path -->

**Изображение:** Архитектура Perception Encoder

### Двухступенчатый процесс обучения

Perception Encoder обучается в два этапа с использованием contrastive loss:

1. **Обучение на парах "изображение-текст"**: Используется CLIP-бейзлайн как отправная точка, добавляются улучшения и сравниваются по качеству и устойчивости.

2. **Обучение на парах "видео-текст"**: Используется модель как кадровый энкодер для видео.

### PE_core

Первая версия модели достигла SOTA в задачах zero-shot retrieval и классификации. Однако при тестировании на downstream-задачах (детекция, трекинг, предсказание глубин) производительность оказалась ниже ожидаемой.

## Проблема downstream-задач

При тестировании модели как энкодера на различных downstream-задачах (детекция, трекинг, предсказание глубин) производительность оказалась ниже ожидаемой. Анализ attention maps показал появление глобальных токенов на определённом слое, что дало ключ к решению проблемы.

## График качества по слоям

![Intermediate layers that are very good at language modeling](../../../media/img_1765199234_aqadrjrgwzjkul_image_mediate_layers_that.jpg) <!-- TODO: Broken image path -->

**Изображение:** Промежуточные слои, которые показывают хорошие результаты в задачах

Построив график зависимости качества от номера слоя для разных downstream-задач и моделей, исследователи обнаружили, что качество возрастает к эмбеддингам средних слоёв, а к последним слоям - резко падает. Это позволило определить оптимальный слой для извлечения эмбеддингов.

## PE_spatial

![Perception Encoder: Spatial Analysis](../../../media/img_1765199234_aqadhjrgwzjkul_perception_encoder_spatial_analysis_imag.jpg) <!-- TODO: Broken image path -->

**Изображение:** Пространственный анализ Perception Encoder

Для решения проблемы были использованы два метода после основного обучения:

1. **Сохранение глобальной информации**: Проведён fine-tuning на 41-м слое (который показывает близкие к лучшим значениям по всем задачам) с минимизацией косинусного расстояния между ним и последним слоем.

2. **Сохранение локальной информации**: Добавлен fine-tuning на MSE попарного косинусного расстояния между эмбеддингами последнего слоя (H×W×1024 -> HW×HW) и попарного косинусного расстояния между логитами SAM для 1024 точек из равномерной сетки исходного изображения. Этот подход позволяет использовать пространственную информацию из SAM (Segment Anything Model) для улучшения локальных признаков, что особенно важно для spatial downstream задач.

Эта версия модели была названа PE_spatial и показала SOTA результаты по многим downstream-задачам.

## Сравнение с DinoV3

![One of those layers, layer 32](../../../media/img_1765199234_aqadxjrgwzjkul_image_one_of.jpg) <!-- TODO: Broken image path -->

**Изображение:** Один из слоев (например, 32-й слой), который показывает хорошие результаты

Хотя вышедший позже DinoV3 достиг более высоких результатов, подход Perception Encoder остаётся интересным и значимым для понимания оптимального извлечения визуальных эмбеддингов. Важно отметить, что Meta признана экстремистской организацией, а Facebook и Instagram запрещены на территории РФ, что может повлиять на доступность и восприятие исследований от Meta AI.

## Применение

![Being a CLIP model](../../../media/img_1765199234_aqadbjrgwzjkul_image_being_a_clip.jpg) <!-- TODO: Broken image path -->

**Изображение:** CLIP-модель как основа для Perception Encoder

![But if we apply both teachers at once](../../../media/img_1765199234_aqadbjrgwzjkul_image_d_but_if.jpg) <!-- TODO: Broken image path -->

**Изображение:** Сравнение методов выравнивания признаков для downstream spatial задач

Perception Encoder демонстрирует важность выбора слоя для извлечения эмбеддингов в визуальных моделях и влияет на проектирование современных архитектур компьютерного зрения.

## Связи с другими темами

- [[multimodal_models.md]] - Perception Encoder является мультимодельной архитектурой, как и CLIP
- [[sam_3_segment_anything_model.md]] - PE используется как визуальный энкодер, как и SAM
- [[embedders.md]] - Perception Encoder как улучшенный подход к созданию визуальных эмбеддингов

## Источники

1. "Perception Encoder: The best visual embeddings are not at the output of the network" - Исследовательская работа от Meta AI, представленная на NeurIPS, описывающая основную концепцию и архитектуру Perception Encoder
2. CV Time - Разбор статьи Perception Encoder от Vladislav Fahrtdinov на конференции NeurIPS в Мехико