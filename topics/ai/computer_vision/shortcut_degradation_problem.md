# Проблема деградации шорткатов (Shortcut Degradation) в глубоких сетях

## Общее описание

Проблема деградации шорткатов (shortcut degradation) - это фундаментальная проблема в глубоких нейронных сетях, где сигнал тонет в шуме при увеличении глубины сети. Эта проблема препятствует эффективному масштабированию сверхглубоких сетей (сотни слоёв) и ограничивает их производительность.

## Технические детали проблемы

### Математическая формулировка

В стандартной резидуальной сети репрезентация на слое l - это сумма входа и накопленных остатков: z_l = z_0 + Σ(r_i). При увеличении глубины дисперсия накопленных остаточных членов начинает доминировать над исходным входным сигналом z_0.

Математически это описывается коэффициентом γ_l = σ_0 / σ_l, где σ - стандартное отклонение. В экстремально глубоких моделях (например, 482-слойный DeiT) этот коэффициент стремительно падает к нулю уже в начале обучения. Когда γ_l ≈ 0, градиент затухает, и модель не может прокинуть информацию от глубоких слоёв обратно ко входу.

![Иллюстрация проблемы деградации шорткатов](../../../media/img_1764253717_aqadiq1rgr9qul_figure_2_the_shortcut_ratio_7.jpg)

**Описание:** На изображении показано соотношение сигнала к шуму в зависимости от глубины сети, демонстрирующее, как коэффициент γ_l стремится к нулю с увеличением глубины, что указывает на деградацию шорткатов.

### Сравнение с другими проблемами

- **Ваннинг градиентов (Vanishing Gradients)**: старая проблема, решенная в ResNet с помощью резидуальных соединений
- **Деградация шорткатов**: современная проблема в сверхглубоких сетях, когда даже ResNet не помогает

## Влияние на производительность

### Плато производительности
- После ~100 слоёв производительность традиционных архитектур выходит на плато или падает
- Это не связано с оверфиттингом, а с фундаментальными барьерами оптимизации

### Ограниченный компромисс
- Ограниченный вычислительный бюджет заставляет выбирать между глубиной (D) и шириной (C) модели
- Ёмкость модели растёт как O(C²D), поэтому урезание ширины ради глубины часто приводит к потере мощности

## Существующие архитектуры и проблема деградации

### ResNet
- Использует резидуальные соединения, которые помогают решить проблему ваннинг градиентов
- Однако в сверхглубоких вариантах (500+ слоёв) сталкивается с проблемой деградации шорткатов

### Vision Transformers (DeiT, ViT)
- Также подвержены проблеме деградации шорткатов при увеличении глубины
- Проблема проявляется в виде потери эффективности при масштабировании

### Swin Transformers
- Иерархические трансформеры также сталкиваются с ограничениями глубины
- Деградация шорткатов мешает достижению потенциала "по-настоящему глубоких" сетей

## Решения и подходы

### Step by Step Networks (StepsNet)
- Новая архитектура, которая решает проблему деградации шорткатов
- Использует каскадную схему "шаг за шагом", где входные данные расщепляются и проходят через разное количество блоков
- Позволяет сохранить "чистые" пути для сигнала в глубину

### Другие подходы
- Улучшенные инициализации весов
- Новые нормализации (BatchNorm, LayerNorm, GroupNorm)
- Регуляризация и специальные архитектурные решения

## Значение для масштабируемости

Проблема деградации шорткатов является ключевым барьером на пути к созданию более глубоких эффективных архитектур. Её решение позволяет:

- Разблокировать потенциал "по-настоящему глубоких" сетей
- Достичь лучшего баланса между глубиной и шириной
- Повысить эффективность обучения и выразительную мощность

## Связи с другими темами

- [[stepsnet_architecture.md]] - архитектура, предложенная для решения проблемы деградации шорткатов
- [[residual_networks.md]] - основы резидуальных соединений, подверженных деградации
- [[vision_transformer.md]] - примеры применения трансформеров, сталкивающихся с проблемой
- [[deep_network_scaling.md]] - общая проблема масштабирования глубоких сетей
- [[gradient_flow_optimization.md]] - оптимизация потока градиентов в глубоких сетях

## Источники

1. [Step by Step Network](https://arxiv.org/abs/2511.14329) - статья Dongchen Han и др., где подробно описана и проанализирована проблема деградации шорткатов и предложено решение в виде архитектуры StepsNet, arXiv:2511.14329, ноябрь 2025.
2. [ArXivIQ Review: Step by Step Network](https://arxiviq.substack.com/p/step-by-step-network) - обзор статьи с анализом проблемы деградации шорткатов и её решения.
3. [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - оригинальная статья о ResNet, где впервые были представлены резидуальные соединения для решения проблемы ваннинг градиентов.