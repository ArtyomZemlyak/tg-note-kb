# Vision Transformer (ViT)

## Общее описание

Vision Transformer (ViT) - это архитектура трансформеров, адаптированная для задач компьютерного зрения. В отличие от традиционных сверточных нейронных сетей (CNN), ViT разбивает изображения на фиксированные патчи и обрабатывает их как последовательность, аналогично обработке токенов в NLP задачах.

## Архитектура

### Патчеризация изображений
- Изображение разбивается на непересекающиеся патчи фиксированного размера (например, 16x16 пикселей)
- Каждый патч линейно проецируется в скрытое пространство
- Добавляются позиционные эмбеддинги для сохранения пространственной информации

### Обработка трансформером
- Последовательность патч-эмбеддингов подается в стандартный трансформер
- Используются многоголовое внимание (multi-head attention) и MLP блоки
- В конце добавляется специальный [CLS] токен для задач классификации

## Применение в диффузионных моделях

Vision Transformer нашел применение в диффузионных моделях, где он используется как backbone для обработки зашумленных изображений на каждом шаге диффузионного процесса. В частности:

- **DiT (Diffusion Transformer)** - адаптация ViT для диффузионных моделей
- **JiT (Just Image Transformer)** - разновидность ViT, используемая в статье "Back to Basics: Let Denoising Generative Models Denoise" для прямой работы в пиксельном пространстве

## Преимущества и ограничения

### Преимущества
- Масштабируемость: ViT демонстрирует лучшее качество с увеличением размера модели и данных
- Простота архитектуры: отсутствие специфических для изображений компонентов
- Унификация: та же архитектура, что и в NLP, позволяет легче переносить методы между доменами

### Ограничения
- Требует большого количества данных для обучения
- Хуже работает на небольших датасетах по сравнению с CNN
- Меньшая индуктивная смещенность к пространственной локальности по сравнению с CNN

## Вариации и улучшения

- **DeiT (Data-efficient ViT)** - улучшенная версия с учителем знаний для обучения на меньших наборах данных
- **Swin Transformer** - иерархический ViT с перекрывающимися патчами и смещенным вниманием
- **EfficientViT** - оптимизированные версии для ресурсоограниченных сред

## Связь с другими темами

- [[jit_diffusion_models.md|Just Image Transformer в диффузионных моделях]] - применение ViT-архитектуры в диффузионных моделях
- [[diffusion_models.md|Диффузионные модели]] - контекст применения Vision Transformer
- [[transformer_architecture.md|Архитектура трансформеров]] - основы архитектуры трансформеров
- [[image_generation.md|Генерация изображений]] - области применения ViT
- [[diffusion_pixel_space.md|Диффузионные модели в пиксельном пространстве]] - применение ViT-архитектуры в пиксельном пространстве

## Источники

1. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) - оригинальная статья о Vision Transformer от Google Research
2. [Diffusion Models for Vision: A Survey](https://arxiv.org/abs/2211.15906) - обзор применения диффузионных моделей в задачах зрения