# Поиск по фото от Wildberries

## Описание

Функция поиска по фото от Wildberries - это технология, позволяющая находить товары по загруженным фотографиям. Пользователь может сделать снимок интересующего его товара, загрузить его в приложение и получить соответствующие товары из ассортимента Wildberries.

## Архитектура системы

### Общая схема для пользователя:
1. Заскринить интересующий товар
2. Загрузить фото в приложение
3. Выделить нужный объект на фото
4. Получить поисканные товары

### Техническая реализация (под капотом):
1. **YOLO** - детектирует и вырезает объекты из изображения
2. **OCR** - снимает артикулы и текст с изображения
3. **SigLIP-эмбеддинги** - преобразуют изображение в векторное представление
4. **Qdrant (HNSW)** - векторный поиск для нахождения похожих товаров
5. **Предварительно вычисленные эмбеддинги товаров** - товары хранятся в виде векторов заранее

## Подробная архитектура

### Компоненты системы:
- **Image Retrieval pipeline** - основной пайплайн получения изображений
- **Text tag selection subsystem** - подсистема выбора текстовых тегов
- **Text refinement component** - компонент уточнения текста

### Обработка изображения:
1. Пользователь загружает изображение
2. Две основные цепочки обнаружения обрабатывают изображение:
   - Основное обнаружение объектов: YOLO-модель, покрывающая ~90% категорий на маркетплейсе
   - E2E OCR для определения номера артикула
3. Пользователь выбирает предложенный кроп → обрабатывается через общую модель эмбеддинга (SigLIP 2)
4. Три основные цепочки от модели эмбеддинга:
   - Image Retrieval (основной сценарий поиска)
   - Векторный индекс тегов
   - Модель уточнения текста

### Извлечение признаков:
- Feature Extractor Backbone → Image Retrieval model → Qdrant векторный индекс
- HNSW поиск в построенном индексе для получения кандидатов
- Обогащение характеристиками продукта (цена, количество отзывов, рейтинг)
- Ранжирование с бустингом → онлайн логистическое пере-ранжирование → финальный вывод

## Подходы к обучению

### Матрешечное обучение представлений (MRL - Matryoshka Representation Learning)
- Подход для сжатия векторного пространства
- Входной вектор размера N → векторы от 512 до 64
- Независимый расчет InfoNCE Loss для каждого вектора
- Среднее значение принимается как итоговая функция потерь при обучении
- Преимущества: ускорение сходимости модели, сильное сжатие векторного пространства, ранжирование признаков
- Позволяет нарезать 512-вектор на любую размерность (большая часть оффлайн, меньшая онлайн)
- Обеспечивает >3% улучшение на всех ключевых оффлайн метриках без дополнительных данных
- Использование в продакшене: 512 оффлайн, 128 онлайн

### Архитектура Attention Head
- Self-Attention Token Reducer + Attention Pooling
- Снижение размерности, нормализация с multi-head attention
- Вывод: 512-мерный вектор
- Содержит UnLearnable Token: недоступный для обучения параметр, инициализированный как средняя матрица параметров датасета Query-параметров с Multi-Head Attention
- Обеспечивает стабильность против коллапса внимания
- Выступает в роли семантического якоря, улучшая финальное качество

## Векторная база данных

### Qdrant как основная векторная индексация:
- Используется как первичный векторный индекс (хранит векторы всех товаров на маркетплейсе)
- Тестировались альтернативы: Redis, Milvus, Weaviate, другие open-source векторные базы данных
- Qdrant показал лучшие результаты по обработке нагрузки
- Поддерживает максимальные запросы в секунду с минимальной задержкой
- Встроенная возможность для перестройки индекса в реальном времени (держит БД всегда актуальной)

### Производственная конфигурация:
- Квантованные векторы: 256 fp16
- Время отклика сервиса: ~250мс в среднем (от загрузки изображения до ответа пользователю)
- Размер индекса: 400 миллионов продуктов
- Оффлайн векторизация всех продуктов
- Обновления БД: ~5 раз в день

## Обработка тегов

### Подходы к генерации тегов:
1. **LLM-based**: Использование названия продукта, описания карточки через Gemma-3 (требуется пост-обработка из-за рекламы/шума)
2. **VLM-based**: Обработка изображений через Qwen 2.5, API-перевод, локальная LLM пост-обработка
3. **Третий подход**, похожий на VLM-based

### Проблемы с тегами:
- Эмоциональные описания
- Семантическая несогласованность
- Опечатки
- Смешивание языков

### Оффлайн обработка:
- ~1М оффлайн тегов различной длины и содержания
- Настройка задачи TagRetrieval
- Более мощные вычислительные ресурсы для оффлайн препроцессинга, генерации, текстовой обработки
- Сильное оффлайн кодирование с проприетарной моделью

### Тренировка:
- Датасет изображений карточек продуктов + предсгенерированных текстовых тегов
- Обработка через соответствующие эмбеддеры
- MLP-голова для проекции пространства LLM/BERT в пространство SigLIP 2 (выравнивание текстов к изображениям, а не наоборот)
- Во время инференса: прямое использование вывода SigLIP2 для поиска тегов (все теги в том же CLIP-пространстве, что и изображения)

### Трюк с обучением линейной модели:
- Замкнутое решение с использованием математической формулы
- Экономичный подход к накоплению пакетов в памяти
- Техника ортогональной инициализации (4x улучшение скорости сходимости, +2-3% метрики)
- Ортогональная инициализация Q-матрицы случайным образом для первого слоя
- Инициализация транспонированной Q-матрицы того же для второго слоя

## Обучение и данные

### Создание датасета (WB 200M):
- Галерея фотографий из карточек товаров продавцов
- Фотографии пользователей из обзоров
- Формирование релевантных пар для задачи ImageRetrieval
- Этапы обработки данных:
  1. Очистка дубликатов с использованием CLIP-подобных моделей (SigLIP 2)
  2. Фильтрация шума и выбросов с использованием CLIP-подобных моделей
  3. Финальная команда разметки для проверки "является ли объект на фото A тем же, что и на фото B"
  4. Аугментация основного обнаружения объектов во время обучения

### Выбор модели - SigLIP 2:
- Выбрана после обширного бенчмаркинга над DFN, BLIP3
- Лучшие результаты по оффлайн метрикам: Precision, F1, mAP
- Архитектура обучения: замороженный SigLIP 2 → Attention head → MRL с InfoNCE Loss

## Текстовое уточнение

### Данные для тренировки триплетов:
- "Изображение + текст + изображение" триплеты (изображение-якорь, текст-изменение, целевое изображение)
- Также генерируются через VLM (два изображения → "описать различия")
- Данные текстовых триплетов: текстовые эмбеддеры SigLIP2 из заголовков карточек
- Три эмбеддинга: текстовый якорь, цель, изменение эмбеддинга

## Онлайн метрики и тестирование

### Результаты A/B тестирования:
- Тестирование модели Attention head с 128 и 256-мерными векторами
- Существенное улучшение по сравнению с текущей продакшен-моделью по всем ключевым бизнес-метрикам
- Активные внутренние A/B тесты для других обсуждаемых моделей

## Особенности реализации

### OCR по объектам
Одной из уникальных особенностей является возможность распознавания текста на объектах. Это позволяет находить несколько вещей на одном фото одновременно, что является редкой возможностью в других системах поиска по фото.

### Мультимодальная логика
Поиск работает не только с изображениями. Фотографии обогащаются тегами, которые заранее сгенерированы с помощью LLM (Large Language Model) на основе описаний товаров и визуальных признаков.

### Оффлайн vs Онлайн стратегия:
- Тяжелые вычисления выполняются оффлайн (векторизация, генерация тегов)
- Онлайн инференс с ресурсной эффективностью
- Предварительно вычисленные эмбеддинги для всех продуктов в консистентном пространстве

### Стратегия повторного использования моделей:
- Нет необходимости пересчитывать всю базу данных
- Все эмбеддинги в одном пространстве модели несмотря на разные входы
- Повторное использование SigLIP2 эмбеддингов с головами модификации текста

### Эффективность
- Система не использует простой CLIP, а применяет более сложную архитектуру
- Предварительное вычисление эмбеддингов товаров позволяет ускорить поиск
- Использование HNSW (Hierarchical Navigable Small World) для эффективного поиска ближайших соседей в векторном пространстве

## Применение технологии

Технология особенно полезна в случаях:
- Поиск товаров из социальных сетей (например, из рилсов)
- Поиск товаров, увиденных в реальной жизни (например, в магазине или кафе)
- Быстрый поиск аналогов товаров по визуальному сходству

## Связи с другими темами

- [[../ocr/object_detection_yolo_ocr.md]] - Обнаружение объектов и OCR технологии
- [[ai/computer_vision/multimodal_models.md]] - Мультимодальные модели (SigLIP, CLIP)
- [[ai/computer_vision/vector_search.md]] - Векторный поиск и базы данных
- [[../machine_learning/reasoning_models/matryoshka_representation_learning.md]] - Подробное описание MRL