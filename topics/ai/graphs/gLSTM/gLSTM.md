# gLSTM: архитектура Graph Neural Networks для борьбы с over-squashing

## Описание

gLSTM (Graph Long Short-Term Memory) - это новая архитектура графовых нейронных сетей (GNN), вдохновленная xLSTM (расширенной архитектурой LSTM), которая решает проблему "over-squashing" за счет увеличения емкости хранения узла. Архитектура была предложена Хью Блейни, Альваро Арройо, Сяовэнь Донг и Майклом М. Бронштейном в статье "gLSTM: Mitigating Over-Squashing by Increasing Storage Capacity".

## Проблема over-squashing

Over-squashing - это фундаментальная проблема в глубоких графовых нейронных сетях, при которой информация из экспоненциально растущего рецептивного поля узла сжимается в вектор фиксированного размера, создавая узкое место. Ранее проблема понималась как проблема чувствительности, но статья выделяет два режима сбоя:

1. **Over-squashing чувствительности**: низкая чувствительность, когда выход узла перестает реагировать на изменения в удаленных узлах
2. **Over-squashing емкости**: насыщение представления узла фиксированного размера, которому просто не хватает места для хранения всей необходимой информации из его окрестности

## Архитектурное решение

gLSTM расширяет стандартный механизм передачи сообщений в GNN. Вместо одного лишь векторного скрытого состояния (h) каждый узел в gLSTM также поддерживает матричное скрытое состояние (C), которое функционирует как ассоциативная память.

### Механизм обновления

Механизм обновления работает в три четких шага:

1. **Хранение (программирование памяти)**: предыдущие векторные состояния узла и его соседей проецируются в векторы ключа (k) и значения (v). Затем матрица памяти C обновляется по правилу внешнего произведения с forget-gate, сохраняя новые пары ключ-значение и выборочно удерживая прошлую информацию.

2. **Извлечение**: из предыдущих скрытых состояний генерируется вектор запроса (q). Этот запрос используется для извлечения релевантной информации из матрицы памяти C через матричное умножение, а результат нормализуется для получения кандидатного скрытого состояния.

3. **Гейтинг и выход**: кандидатное состояние проходит через финальные выходные ворота для получения нового векторного скрытого состояния слоя, h^(l). Этот продуманный механизм гейтинга контролирует итоговый поток информации.

## Связанные архитектуры

gLSTM часто используется в паре с K-hop агрегацией - схемой передачи сообщений, в которой узел на слое l агрегирует информацию от соседей, находящихся ровно в l "прыжках" от него. Такая структура создает сильный индуктивный сдвиг для задачи извлечения.

## Применение и результаты

gLSTM продемонстрировал передовые результаты на нескольких задачах предсказания свойств графа на больших расстояниях (Graph Property Prediction, GPP), таких как Diameter и Eccentricity, и показал хорошие результаты на бенчмарке Long Range Graph Benchmark (LRGB).

## Преимущества

- Значительно увеличенная емкость хранения по сравнению с традиционными GNN
- Эффективная борьба с over-squashing за счет увеличения внутренней памяти узла
- Поддержка избирательной чувствительности (способности различать релевантные и нерелевантные узлы)

## Ограничения

- Более высокие вычислительные требования по сравнению со стандартными MPNN
- Высокая производительность сильно зависит от использования K-hop агрегации
- Пока не достигает эффективности аналогов из области моделирования последовательностей

## Связь с другими темами

- [[over_squashing.md]] - Подробнее о проблеме over-squashing в GNN
- [[neighbor_associative_recall.md]] - Задача NAR для оценки емкости хранения
- [[xLSTM_inspiration.md]] - Архитектура xLSTM, вдохновившая gLSTM
- [[long_range_dependencies.md]] - Дальнодействующие зависимости, которые gLSTM эффективно обрабатывает