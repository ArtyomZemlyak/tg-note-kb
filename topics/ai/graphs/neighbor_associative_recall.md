# Neighbor Associative Recall (NAR) - задача для оценки емкости хранения

## Описание

Neighbor Associative Recall (NAR) - это новая синтетическая задача, специально разработанная для измерения ограничения емкости хранения в графовых нейронных сетях (GNN). Задача предложена в статье "gLSTM: Mitigating Over-Squashing by Increasing Storage Capacity" для изоляции и оценки проблемы over-squashing емкости.

## Цель задачи

В отличие от предыдущих бенчмарков, таких как Tree-NeighborsMatch, которые проверяют GNN в глубоких режимах, где проблемы емкости и чувствительности переплетены, задача NAR работает всего с двумя слоями передачи сообщений, что позволяет изолировать проблему емкости от проблемы чувствительности.

## Описание задачи

Задача NAR проста, но элегантна в своей сути:

1. Центральный узел соединен с переменным числом узлов-«соседей», каждый из которых хранит уникальную пару ключ-значение
2. Отдельный узел-«запрос» предоставляет один из ключей
3. Цель центрального узла - извлечь правильное значение, связанное с этим ключом
4. С увеличением числа соседей задача напрямую нагружает емкость хранения центрального узла, не внося при этом мешающих эффектов глубины, таких как затухание градиентов или сильное падение чувствительности

## Значение задачи

### Изоляция проблемы емкости
- Позволяет оценить способность GNN хранить информацию без эффектов, связанных с глубиной
- Помогает различать over-squashing чувствительности и over-squashing емкости

### Оценка архитектур
- Задача NAR позволяет сравнивать разные архитектуры GNN по их способности к хранению информации
- gLSTM показывает значительное преимущество перед стандартными GCN на задаче NAR

## Результаты экспериментов

Эксперименты с gLSTM на задаче NAR показали:

- gLSTM сохраняет идеальную точность до тех пор, пока число соседей не сравняется с размерностью его памяти, после чего демонстрирует «плавное насыщение»
- В отличие от этого, даже большая модель GCN резко перестает справляться, как только число соседей превышает всего восемь
- Эксперименты подтверждают эмпирическое разделение двух режимов over-squashing: производительность GCN на задаче NAR падает из-за насыщения емкости, но её общая чувствительность (измеренная по полной норме Якобиана) остаётся высокой

## Связь с другими темами

- [[gLSTM/gLSTM.md]] - Архитектура, показавшая высокие результаты на задаче NAR
- [[over_squashing.md]] - Проблема, которую оценивает задача NAR
- [[graph_property_prediction.md]] - Задачи предсказания свойств графа, где также важна способность к хранению информации