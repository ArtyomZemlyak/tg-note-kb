# Planned Diffusion

## Описание

Planned Diffusion - это новый гибридный фреймворк для генерации текста, который объединяет сильные стороны авторегрессионных (AR) и диффузионных моделей в единой архитектуре. Метод решает фундаментальную проблему компромисса между скоростью генерации и качеством вывода в больших языковых моделях (LLM).

## Принцип работы

Planned Diffusion работает путём разделения генерации текста на два отдельных этапа, выполняемых одной унифицированной моделью:

### 1. Авторегрессионное планирование

- Процесс начинается с последовательного, авторегрессионного этапа
- Модель генерирует высокоуровневый план выполнения, состоящий из структурных управляющих тегов
- План очерчивает семантическую структуру ответа и разбивает задачу на условно независимые подзадачи
- Например, на просьбу дать определение северного сияния модель может сгенерировать план вида `<topic="definition" len=30><topic="description" len=30>`

### 2. Параллельная диффузия

- План преобразуется в каркас из маск-токенов
- Содержимое для всех определённых фрагментов генерируется одновременно с помощью дискретного диффузионного процесса
- Каждый запланированный фрагмент текста параллельно очищается от шума (denoising)
- Это резко сокращает количество последовательных прогонов модели, необходимых для генерации полного ответа

## Подробности метода

### Сравнение подходов

- **Авторегрессия** в стандартной постановке предсказывает следующий токен на основе предыдущих
- **Маскированная диффузия** предсказывает вероятность маскированного токена стать конкретным токеном из словаря при условии окружающих токенов
- **Авторегрессия** предсказывает по токену за раз
- **Диффузия** может предсказывать сразу несколько токенов, но для лучшего качества требуется несколько прогонов через модель

### Процесс генерации Planned Diffusion

1. Сначала авторегрессионно генерируется некий контекст и черновик для дальнейшей генерации. Предполагается, что есть несколько ветвей рассуждения, которые можно генерировать независимо, и для каждой из авторегрессия предсказывает сколько токенов надо расшумить
2. Затем диффузия, имея контекст и заданное количество маскированных токенов, генерирует ветвь рассуждения
3. Затем происходит синхронизация и генерируется заключение

### Структурные теги

- Контекст размечается специальными `<topic>...</topic>` тегами
- Асинхронные параллельные блоки обозначаются `<async>...</async>` тегами
- Точка синхронизации обозначается `<sync>` тегом

### Варианты архитектуры

Рассматривают два случая:
- **PD** (Planned Diffusion): когда токены в параллельных ветвях не смотрят друг на друга
- **PD-DA** (Planned Diffusion with Dense Attention): когда токены в параллельных ветвях смотрят друг на друга

### Обучение

- В последовательности в нужном формате (с разметкой) зашумляют до некоторого уровня ветви рассуждения
- Модель учится одновременно на авторегрессионный и диффузионный лосс (то есть предсказывать правильно план и рассуждения)
- На инференсе при авторегрессионой генерации можно использовать сгенерированный ранее KV-кэш, но для текущего шага диффузии из-за full attention все токены в ветви рассуждения генерируются по новой
- При декодировании диффузией используют энтропийный порядок - декодируются первыми те токены, где модель более уверенна

## Формальная вероятностная факторизация

Гибридный процесс основан на следующей вероятностной факторизации:
Pₚᴅ(z, x|c) = Pₐᵣ(z|c) ⋅ Pᴅ(x|z, c)

Где:
- z - план
- x - содержимое текста
- c - контекст

Важно, что вероятность диффузии Pᴅ далее факторизуется по независимым фрагментам x⁽ᵏ⁾, что позволяет вести параллельную генерацию:
Pᴅ(x|z, c) = ∏_{k=1}^{b(z)} Pᴅ(x⁽ᵏ⁾|z, c)

## Ключевая архитектурная инновация

Механизм, позволяющий одной модели плавно переключаться между последовательным планированием и параллельной генерацией, кроется в её кастомной маске attentiona:

- **На этапе планирования**: модель использует стандартную каузальную маску, где каждый токен может обращать внимание только на предыдущие - отличительная черта авторегрессионных моделей
- **На этапе диффузии**: маска трансформируется - внутри каждого независимого фрагмента токены используют двунаправленное внимание, что позволяет им видеть все остальные токены в том же фрагменте
- При этом сами фрагменты маскируются друг от друга, обеспечивая условную независимость, необходимую для параллельной генерации

## Преимущества

- **Решение компромисса скорость-качество**: Значительно сокращает последовательный критический путь, достигая ускорения от 1.27x до 1.81x по сравнению со стандартной AR-генерацией при минимальном снижении качества
- **Единая архитектура**: Избегает сложностей систем с несколькими моделями (например, спекулятивного декодирования)
- **Динамическое планирование**: Рассматривает генерацию текста как задачу динамического параллельного планирования, похожую на человеческий процесс работы над объемными задачами
- **Настраиваемый инференс**: Обеспечивает тонкий контроль над компромиссом между скоростью и качеством с помощью простых runtime-параметров (например, "step ratio" и "confidence threshold")
- **Лучшая масштабируемость**: Качество модели продолжает расти с увеличением числа эпох обучения, в отличие от AR-бейзлайнов, которые выходят на плато

## Ограничения

- **Фактическое ускорение меньше теоретического**: Разрыв объясняется более тяжёлыми вычислениями на каждом шаге и меньшим переиспользованием KV-кэша на этапе диффузии
- **Компромисс с качеством**: Для достижения максимального ускорения приходится немного жертвовать качеством по сравнению с лучшим AR-бейзлайном
- **Сложность KV-кэширования**: Двунаправленное внимание на этапе диффузии не позволяет кэшировать представления токенов до завершения всего фрагмента
- **Необходимость структурированных тегов**: Качество зависит от правильного использования тегов `<topic>` и `<sync>`, потеря тега `<topic>` сильно ухудшает качество

## Экспериментальные результаты

### Настройка экспериментов

- Метод валидировали путем дообучения Dream-7B-Base, которую сначала учили на авторегрессию, а затем на диффузию
- Разметку для обучения собирали с помощью Gemini, переформатируя примеры из Slim Orca в требуемый вид (план + ветви рассуждения). Неудачные примеры выбрасывали
- В качестве бейзлайнов брали просто авторегрессию, текстовую диффузию, и ускоренную диффузию Fast-dLLM
- Качество оценивали на AlpacaEval с LLM-as-a-judge, следуя стандартному протоколу

### Гиперпараметры обучения

- Для авторегрессии оптимальны 2 эпохи
- Для диффузионных постановок полезно учить подольше - 16 эпох

### Результаты

- Относительно сильного авторегрессионного бейзлайна, который набрал 50.0% побед с контролем длины (length-controlled win rate, LCWR), стандартная модель Planned Diffusion (PD) достигла 44.6% LCWR при ускорении в 1.81 раза
- Вариант Planned Diffusion with Dense Attention (PD-DA) достиг 49.2% LCWR (падение всего на 0.8 процентных пункта), сохранив при этом ускорение в 1.27 раза
- Planned диффузия по качеству не сильно уступает авторегрессии, но при этом работает быстрее
- В среднем удается добиться в 2.3 раза меньшего числа forward пассов по сравнению с AR
- Конечное ускорение несколько меньше - 1.8x для независимых потоков, и 1.3x при dense-attention
- PD-DA несколько лучше по качеству, чем просто PD, но и медленнее (нельзя пропустить вычисления attention-а в некоторых блоках)
- При пропуске тега `<topic>` качество просаживается сильно, но от потери тега `<sync>` не сильно страдает и получается к тому же еще быстрее
- Если подавать на инференсе диффузии меньше или больше токенов, чем "спланировала" авторегрессия, оптимальное качество достигается когда их столько же. Но если важна скорость - можно подавать более короткие цепочки маскированных токенов с умеренной просадкой

## Связи с другими темами

- [[diffusion_llm_architectures.md]] - Общие принципы диффузионных LLM, на которых основан Planned Diffusion
- [[../non_autoregressive_models.md]] - Невавторегрессивные модели, часть более широкого класса подходов
- [[../inference_optimization/index.md]] - Оптимизация инференса, включая гибридные архитектуры
- [[../llm_architectures_comparison.md]] - Сравнение различных архитектур LLM, включая гибридные подходы
- [[../autoregressive_models.md]] - Авторегрессионные модели, одна из составляющих Planned Diffusion
- [[../speed_always_wins_survey.md]] - Обзор методов ускорения генерации в LLM