# Gated DeltaNet

## Описание

Gated DeltaNet - это архитектура рекуррентной нейронной сети, построенная на основе Delta Rule, которая использует механизм гейтирования для управления потоком информации. Модель представлена в работе "Gated Delta Rule" и служит основой для Kimi Delta Attention (KDA), улучшенной версии, в которой реализован более эффективный механизм гейтирования.

## Технические детали

### Основа: Delta Rule

- Delta Rule рассматривает обновление рекуррентного состояния как онлайн-градиентный спуск для задачи восстановления
- Обновление рекуррентного состояния происходит через операции градиентного типа
- Используется для точного моделирования последовательностей и управления памятью

### Механизм гейтирования

- Использует гейты для управления информационным потоком в рекуррентной сети
- В оригинальной версии используется грубый гейт забывания для всей головы внимания
- Механизм позволяет избирательно забывать информацию в зависимости от новых поступающих данных

### Рекуррентное состояние

- Поддерживает фиксированный размер рекуррентного состояния
- Обновление состояния происходит на основе новой пары ключ-значение
- Состояние используется для вычисления внимания в последующих шагах

## Сравнение с другими архитектурами

### Отличия от KDA (Kimi Delta Attention)

- KDA улучшает Gated DeltaNet, вводя мелкозернистый диагонализированный гейт `Diag(α_t)`
- В Gated DeltaNet используется более грубый гейт забывания для всей головы внимания
- KDA обеспечивает гораздо более точное управление RNN-памятью модели фиксированного размера за счёт поканального механизма

### Отличия от Mamba2

- Gated DeltaNet базируется на Delta Rule и онлайн-градиентном спуске
- Mamba2 использует другие подходы к обновлению состояния
- KDA показывает лучшую сходимость на синтетических задачах извлечения информации и отслеживания состояния по сравнению с Gated DeltaNet и Mamba2

## Значение и применение

- Предшественник Kimi Delta Attention
- Демонстрирует потенциал Delta Rule для задач, требующих интенсивного запоминания и извлечения информации
- Показывает важность точного управления рекуррентной памятью в задачах последовательности

## Ограничения

- Более грубый механизм гейтирования по сравнению с улучшенными версиями
- Может быть менее эффективным в задачах, требующих точного поканального управления памятью
- Общие структуры Diagonal-Plus-Low-Rank (DPLR) сложно распараллелить и требуют больших вычислений (ограничение, которое решается в KDA)

## Связи с другими темами

- [[kimi_delta_attention.md|Kimi Delta Attention]] - улучшенная версия Gated DeltaNet с мелкозернистым гейтированием
- [[kimi_linear.md|Kimi Linear]] - архитектура, использующая KDA как улучшенную версию Gated DeltaNet
- [[state_space_models.md|Модели в пространстве состояний]] - более широкий класс моделей, к которому относится Gated DeltaNet
- [[mamba_architecture.md|Mamba]] - альтернативный подход к линейному моделированию последовательностей