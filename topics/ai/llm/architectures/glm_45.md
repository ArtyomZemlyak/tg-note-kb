# GLM-4.5

## Описание

GLM-4.5 - крупный релиз 2025 года, представляющий собой гибрид инструкций и рассуждений, аналогичный Qwen3, но дополнительно оптимизированный для вызова функций (function calling) и контекста в стиле агентов (agent-style contexts). Флагманская модель с 355 миллиардами параметров превосходит Claude 4 Opus в среднем по 12 бенчмаркам.

## Ключевые архитектурные особенности

### Плотные слои перед MoE

GLM-4.5 принимает структурный выбор, впервые представленный в DeepSeek V3: 3 плотных слоя предшествуют блокам смеси экспертов. Это улучшает стабильность сходимости и общую производительность в больших системах MoE, гарантируя, что модель формирует стабильные низкоуровневые представления до начала принятия решений о маршрутизации экспертов.

### Общий эксперт

В отличие от Qwen3, GLM-4.5 использует общего эксперта, аналогично DeepSeek-V3, что помогает стабилизировать обучение и обработку общих паттернов.

### Внимание смещений

GLM-4.5 также сохраняет механизм смещения внимания (attention bias), использованный в GPT-2 и gpt-oss, что не характерно для большинства современных моделей.

## Архитектурные решения

- **Плотные слои перед MoE**: Улучшение стабильности в больших MoE системах
- **Общий эксперт**: Стабилизация обучения и обработка общих паттернов
- **Гибрид инструкций и рассуждений**: Оптимизация для функций и агентских контекстов
- **Внимание смещений**: Сохранение традиционного подхода GPT-2

## Версии модели

- **GLM-4.5**: Флагманская модель с 355 миллиардами параметров
- **GLM-4.5-Air**: Более компактная версия с 106 миллиардами параметров

## Сравнение с Qwen3

- Использует плотные слои перед MoE (в отличие от Qwen3)
- Использует общего эксперта (в отличие от Qwen3)
- Обе модели имеют MoE архитектуру, но с разными подходами к стабильности

## Развитие в линейке GLM

GLM-4.5 стала важным этапом в развитии линейки GLM, устанавливая базу для последующих мультимодальных разработок. Следующим значительным шагом в этой линейке стала серия GLM-4.6V, которая принесла нативные возможности вызова функций и продвинутое визуальное понимание.

## Производительность

- Превосходит Claude 4 Opus в среднем по 12 бенчмаркам
- Немного уступает o3 от OpenAI и Grok 4 от xAI
- Хорошо оптимизирована для вызова функций и агентских сценариев

## Контекст в области LLM

GLM-4.5 интересна сочетанием инновационных и традиционных подходов. Она возвращает плотные слои перед MoE, как был в DeepSeek V3, что показывает признание важности стабильности в ранних этапах обработки. Также сохранение attention bias показывает, что некоторые традиционные элементы архитектуры могут быть полезны даже в современных MoE моделях.

## Связи с другими темами

- [[../models/multimodal/glm_46v.md|GLM-4.6V]] - Развитие линейки GLM с нативными возможностями вызова функций
- [[deepseek_v3.md|DeepSeek V3]] - Источник подхода с плотными слоями перед MoE
- [[qwen3.md|Qwen3]] - Сравнение с альтернативной MoE архитектурой
- [[../techniques/mixture_of_experts.md|MoE]] - Подробное объяснение смеси экспертов
- [[../techniques/attention_bias.md|Attention Bias]] - Подробное объяснение смещения внимания