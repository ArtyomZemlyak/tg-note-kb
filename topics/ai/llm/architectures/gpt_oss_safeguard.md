# GPT-OSS-Safeguard

## Описание

GPT-OSS-Safeguard (gpt-oss-safeguard-120b и gpt-oss-safeguard-20b) - это новые модели от OpenAI, основанные на архитектуре gpt-oss и специально обученные для задач классификации текста на предмет безопасности. Эти модели представляют собой важное развитие в области контент-модерации с использованием ИИ.

## Ключевые особенности

### Гибкая политика безопасности
- Правила фильтрации не зашиты в модель жестко, а определяются пользователем на этапе инференса
- Возможность задавать любые политики безопасности в зависимости от конкретных требований
- Единая модель может адаптироваться под разные сценарии использования

### Назначение
- Специально обучены для задач классификации текста на предмет безопасности
- Предназначены для модерации контента
- Используются для оценки безопасности запросов и ответов моделей

### Производительность
- Демонстрируют отличные результаты при условии четких и непротиворечивых инструкций
- Способны обрабатывать сложные пограничные случаи при продуманной политике безопасности

## Архитектурные особенности

### Основа
- Построены на базе gpt-oss архитектуры
- Используют ту же широкую архитектуру с бОльшим упором на ширину, чем на глубину
- Наследуют преимущества gpt-oss (2880 размерность эмбеддингов, внимание со скользящим окном и т.д.)

### Специализация
- Адаптированы для задач классификации, а не генерации текста
- Оптимизированы для выявления потенциально опасного или нежелательного контента
- Поддерживают динамическое определение критериев безопасности

## Применение

### Гибкая модерация
- Возможность настройки разных политик для разных пользовательских групп (несовершеннолетние, бизнес-клиенты, etc.)
- Нет необходимости обучать несколько разных классификаторов
- Одна модель с разными инструкциями подстраивается под различные требования

### Внутреннее использование
- Уже частично используются в стартапах для оценки безопасности запросов и ответов моделей
- Применяются для обеспечения соответствия различных политик безопасности

## Преимущества

1. **Гибкость**: возможность перенастройки политики безопасности без переобучения модели
2. **Эффективность**: одна модель может выполнять функции нескольких специализированных классификаторов
3. **Точность**: работают отлично при четких и последовательных политиках безопасности
4. **Масштабируемость**: подходят для решения широкого спектра задач модерации контента

## Сравнение с GPT-OSS

- **GPT-OSS**: универсальные модели для генерации текста
- **GPT-OSS-Safeguard**: специализированные модели для классификации безопасности
- Обе используют одинаковую архитектурную основу, но с разной задачей обучения
- GPT-OSS-Safeguard оптимизированы для задач фильтрации и модерации

## Связи с другими темами

- [[gpt_oss.md|GPT-OSS]] - базовая архитектура, на которой основаны safeguard-модели
- [[../llm_alignment.md|Выравнивание LLM]] - вопросы безопасности и соответствия ценностям
- [[../prompt_engineering.md|Инженерия промптов]] - важность четких и непротиворечивых инструкций
- [[../../security/overview.md|Безопасность ИИ]] - широкий контекст безопасности ИИ-систем
- [[../../security/model_poisoning.md]] - связь с вопросами безопасности моделей
- [[../applications/content_moderation.md]] - применение в системах модерации контента