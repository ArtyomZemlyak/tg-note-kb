# Mamba-3: Улучшенная архитектура State Space Model

## Общее описание

Mamba-3 — это архитектурное развитие семейства моделей пространства состояний (State Space Models, SSM), представленное в статье "Mamba-3: Improved Sequence Modeling Using State Space Principles" (подана на ICLR 2026). Архитектура объединяет три ключевых технических улучшения: схему трапецеидальной дискретизации (вместо метода Эйлера), формулировку Multi-Input Multi-Output (MIMO) для повышения арифметической интенсивности вычислений и теоретическое обоснование, связывающее комплекснозначные SSM с Data-Dependent Rotary Embeddings (RoPE).

Mamba-3 решает две основные слабости эффективных линейных моделей: неспособность решать задачи на отслеживание состояния (state-tracking), такие как проверка чётности или арифметика, и плохую утилизацию железа (memory-bound) во время декодинга. Возвращая выразительность комплексной динамики без вычислительных накладных расходов, Mamba-3 задаёт новый фронт Парето эффективности инференса, обгоняя Mamba-2 и сильные бейзлайны трансформеров на стандартных бенчмарках.

## История и развитие

Mamba-3 является продолжением развития архитектуры Mamba, начавшегося с оригинальной статьи "Mamba: Linear-Time Sequence Modeling with Selective State Spaces" (2023), за которой последовала Mamba-2. В отличие от Mamba-2, которая успешно интегрировала SSM с матричными ускорителями через так называемую "SSD" дуальность (State Space Duality), Mamba-3 возвращается к более выразительной динамике, восстанавливая способность модели к вращательным преобразованиям, критическим для задач отслеживания состояния.

## Технические особенности

### 1. Трапецеидальная дискретизация

В отличие от метода Эйлера, использованного в Mamba-2, Mamba-3 применяет Обобщённое правило трапеций для дискретизации непрерывного сигнала. Математически это повышает точность дискретизации с приближения первого порядка до второго порядка.

В Mamba-2 обновление состояния для одного токена x_t предполагало, что вход остаётся постоянным в течение временного шага Δ_t. Mamba-3 изменяет подход, вводя зависимость от предыдущего шага, фактически создавая свёртку размера 2. Рекуррентность принимает вид:

```
h_t = α_t * h_{t-1} + β_t * B_{t-1} * x_{t-1} + γ_t * B_t * x_t
```

Где коэффициенты β_t и γ_t выводятся из зависимой от данных выпуклой комбинации концов интервала, создавая "структурированную маску", действующую как локальная свёртка.

### 2. Multi-Input Multi-Output (MIMO) формулировка

Одним из прагматичных вкладов Mamba-3 является переход к формулировке Multi-Input Multi-Output для решения проблемы бутылочного горлышка пропускной способности памяти.

В стандартной Single-Input Single-Output (SISO) SSM (как Mamba-2) обновление состояния представляет собой внешнее произведение:
```
h_t ← α * h_{t-1} + b_t ⊗ x_t
```
Эта операция имеет арифметическую интенсивность около 2.5 FLOPs/byte, что радикально ниже возможностей современных GPU (H100 поддерживает ~300 FLOPs/byte).

Mamba-3 решает это через расширение ранга. Вместо векторов:
- Вход проецируется в матрицу X_t размерности p × r
- Состояние H_t размерности n × p вычисляется через матричное умножение

Рекуррентность трансформируется в матричное умножение:
```
H_t ← α_t * H_{t-1} + B_t * X_t^T
```

Увеличивая ранг r, модель выполняет больше вычислений на каждый загруженный байт памяти. Критически важно, что рост FLOPs переводит операцию в режим compute-bound без увеличения размера рекуррентного состояния H_t, что позволяет достичь более высокой утилизации железа и ускорения реального времени декодинга.

### 3. Комплексная динамика через RoPE

Ключевым инсайтом Mamba-3 является теоретическое доказательство: дискретизированная комплексная SSM математически эквивалентна вещественной SSM, оснащённой Data-Dependent Rotary Positional Embeddings (RoPE), применяемыми к проекциям входа и выхода.

В предыдущих итерациях, таких как Mamba-2, матрица A была ограничена вещественной диагональной матрицей (или скаляром), что упрощало вычисления, но лишило модель способности представлять вращательную динамику. Теоретический анализ показывает, что вещественные собственные значения не могут представлять колебательную или вращательную механику, необходимую для задач с периодичностью (например, определение чётности суммы).

Вместо явного хранения комплексных чисел, Mamba-3 применяет матрицы вращения R_t к проекциям B и C, восстанавливая способность к вращению, необходимую для трекинга состояния, без вычислительных накладных расходов комплексной арифметики.

## Архитектурные компоненты

### Mamba-3 Block

Каждый Mamba-3 блок включает:

1. **Normalization Layer**: Слой нормализации (например, RMSNorm)
2. **MIMO Projection**: Преобразование входа в матричную форму высокого ранга
3. **Trapezoidal Discretization**: Обновление состояния с использованием обобщённого правила трапеций
4. **RoPE Integration**: Применение вращательных эмбеддингов к проекциям
5. **Activation Function**: Активация (обычно GELU)
6. **Residual Connection**: Остаточное соединение для стабилизации обучения

### Селективные механизмы

Как и в предыдущих версиях Mamba, Mamba-3 сохраняет селективные механизмы, которые позволяют модели:

- **Выбирать релевантную информацию**: Модель адаптивно решает, какая информация из входной последовательности должна быть сохранена в скрытом состоянии
- **Фильтровать нерелевантные данные**: Нерелевантная информация игнорируется
- **Адаптироваться к контексту**: Параметры модели зависят от текущего контекста

## Решение проблем предыдущих версий

### Проблема отслеживания состояния

Mamba-2 показывала катастрофические результаты (~0.90%) на задаче "Parity" (определение, чётна ли сумма битов), подтверждая теоретическое ограничение вещественных состояний. Mamba-3 достигает 100% точности на этой задаче благодаря восстановленной вращательной динамике через RoPE.

### Проблема утилизации железа

Mamba-3 решает проблему memory-bound вычислений во время декодинга через формулировку MIMO, которая увеличивает арифметическую интенсивность без увеличения рекуррентного состояния.

## Сравнение с предыдущими версиями

| Характеристика | Mamba-1 | Mamba-2 | Mamba-3 |
|----------------|---------|---------|---------|
| Дискретизация | ZOH/Euler | Euler | Трапецеидальная |
| Тип состояния | Вещественное | Вещественное | Комплексное (через RoPE) |
| Формулировка | SISO | SISO | MIMO |
| Арифметическая интенсивность | Низкая | Низкая | Высокая |
| Способность к вращению | Нет | Нет | Да |
| Сложность вычислений | O(N) | O(N) | O(N) |
| Эффективность инференса | Высокая | Высокая | Очень высокая |

## Экспериментальные результаты

![Результаты языкового моделирования](../../../../media/img_1763823137_aqadhwtrgwrcel_table_1_downstream_language_modeling_eva.jpg)

**Описание:** Таблица 1 из статьи Mamba-3, демонстрирующая сравнение производительности Mamba-3 с Mamba-2 и другими моделями на задачах языкового моделирования. Показывает превосходство Mamba-3 на разных масштабах параметров (от 180M до 1.5B).

### Языковое моделирование

На датасете FineWeb-Edu Mamba-3 последовательно обходит Mamba-2 и Gated DeltaNet на разных масштабах (от 180M до 1.5B параметров), демонстрируя улучшенное качество при сохранении вычислительной эффективности.

![Сравнение Mamba-2 и Mamba-3](../../../../media/img_1763823137_aqadhgtrgwrcel_figure_4_contrasting_mamba_2_and_mamba_3.jpg)

**Описание:** Рисунок 4 из статьи, контрастирующий архитектурные различия между Mamba-2 и Mamba-3, особенно в контексте вращательной динамики и использования RoPE.

### Синтетические задачи

На задаче "Parity" Mamba-3 достигает 100% точности, в то время как Mamba-2 показывает катастрофически низкий результат (~0.90%), подтверждая восстановленную способность к отслеживанию состояния.

![Абляции ключевых компонентов](../../../../media/img_1763823137_aqadiatrgwrcel_table_4_left_ablations_on_core.jpg)

**Описание:** Таблица 4 из статьи, показывающая абляционные эксперименты для ключевых компонентов Mamba-3, демонстрирующая вклад каждого из трёх нововведений (трапецеидальная дискретизация, MIMO, комплексная динамика через RoPE) в общую производительность.

## Ограничения

Хотя Mamba-3 значительно улучшает ситуацию со слабостью линейных моделей в "отслеживании состояний", она всё ещё сталкивается с фундаментальным ограничением фиксированной ёмкости состояния в задачах извлечения информации (retrieval). Модели сложно извлекать информацию из полуструктурированных или неструктурированных данных по сравнению с моделями на основе внимания, которые могут пересматривать всю историю через KV-кэш. Сжатие контекста в состояние h_t остаётся сжатием с потерями, независимо от того, насколько выразительной становится динамика переходов.

## Значение для области

Mamba-3 представляет собой зрелую доработку парадигмы линейного моделирования последовательностей. Выйдя за рамки простых эвристик Mamba-2 и обосновав архитектуру строгим численным анализом (трапецеидальная дискретизация) и теорией управления (комплексная динамика через RoPE), авторы создали модель, которая одновременно и умнее, и эффективнее по железу. Для практиков формулировка MIMO предлагает конкретный план по максимизации утилизации GPU во время инференса, делая Mamba-3 привлекательной альтернативой трансформерам для развёртывания в условиях ограниченных ресурсов.

## Связи с другими темами

- [[mamba_architecture.md]] - Оригинальная архитектура Mamba, предшественник Mamba-3
- [[state_space_models.md]] - Более общая категория State Space Models, к которой относится Mamba-3
- [[linear_sequence_modeling.md]] - Контекст линейного моделирования последовательностей
- [[rope_rotary_embeddings.md]] - Вращательные позиционные эмбеддинги, используемые в Mamba-3
- [[speed_always_wins_survey.md]] - Обзор "Speed Always Wins", включающий SSM как важную категорию

## Источники

1. [Mamba-3: Improved Sequence Modeling Using State Space Principles](https://openreview.net/forum?id=HwCvaJOiCj) - основная статья, описывающая архитектуру Mamba-3 (подана на ICLR 2026)
2. [Mamba-3 Review](https://arxiviq.substack.com/p/mamba-3-improved-sequence-modeling) - ревью статьи о Mamba-3
3. [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752) - оригинальная статья о Mamba
4. [Mamba-2: Improved selective state space models](https://arxiv.org/abs/2408.09834) - статья о промежуточной версии Mamba-2