# Gemma 3

## Описание

Gemma 3 - серия открытых моделей от Google, выделяющихся хорошей производительностью при относительно небольшом размере. Модель 27B особенно примечательна, и, по мнению некоторых, недооценена по сравнению с конкурентами.

## Ключевые архитектурные особенности

### Внимание со скользящим окном (Sliding Window Attention)

Gemma 3 использует внимание со скользящим окном для значительного снижения требований к памяти в KV-кеше. Соотношение между глобальным (обычным) и локальным (скользящим) вниманием составляет 5:1, то есть только 1 слой полного внимания на каждые 5 слоев локального внимания со скользящим окном. Размер скользящего окна составляет 1024 токена.

### Уникальное размещение нормализации

Gemma 3 использует RMSNorm как в пре-нормализации, так и в пост-нормализации вокруг модуля Grouped-Query Attention, что обеспечивает "лучшее из обоих миров".

## Архитектурные решения

- **Внимание со скользящим окном**: Значительно снижает использование памяти при минимальном влиянии на производительность
- **Удвоенная нормализация**: Использование RMSNorm как до, так и после модулей внимания и прямого распространения
- **Grouped-Query Attention**: В сочетании со скользящим окном
- **Оптимизация для эффективности**: Смещение фокуса в сторону более эффективных локализованных вычислений

## Версия Gemma 3n (оптимизированная для устройств)

Через некоторое время была выпущена Gemma 3n - оптимизированная версия для запуска на мобильных устройствах:
- **Per-Layer Embedding (PLE)**: Позволяет хранить в памяти GPU только подмножество параметров модели
- **MatFormer**: Концепция, позволяющая разделить общую архитектуру на более мелкие, независимо используемые модели

## Сравнение с другими моделями

- В отличие от Mistral Small 3.1, использует скользящее окно внимания
- В отличие от OLMo 2, использует GQA вместо традиционного многоголового внимания
- В отличие от DeepSeek V3, использует GQA вместо MLA

## Связи с другими темами

- [[../techniques/sliding_window_attention.md|Sliding Window Attention]] - Подробное объяснение внимания со скользящим окном
- [[mistral_small_31.md|Mistral Small 3.1]] - Альтернативный подход без скользящего окна
- [[olmo_2.md|OLMo 2]] - Сравнение размещения нормализации
- [[gemma_2.md|Gemma 2]] - Предшественник с соотношением 1:1 вместо 5:1