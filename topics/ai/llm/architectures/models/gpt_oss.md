# GPT-OSS

## Описание

GPT-OSS (gpt-oss-120b и gpt-oss-20b) - первые модели с открытыми весами от OpenAI после GPT-2 в 2019 году. Эти модели представляют интерес как архитектурные примеры от создателей GPT, внедряя современные подходы в открытых весах.

## Ключевые архитектурные особенности

### Ширина против глубины

GPT-OSS представляет архитектуру, которая шире, чем глубока:
- **Размерность эмбеддингов**: 2880 (в отличие от 2048 в Qwen3)
- **Промежуточная размерность**: 2880 для экспертов (в отличие от 768 в Qwen3)
- **Количество голов внимания**: Вдвое больше, чем в Qwen3

Это создает более "широкую" архитектуру по сравнению с "глубокой" архитектурой Qwen3 (48 блоков трансформера против 24).

### Fewer, но крупные эксперты

В отличие от тенденции к множеству мелких экспертов, GPT-OSS использует:
- 32 эксперта всего (вместо 128 в Qwen3)
- 4 активных эксперта на токен (вместо 8 в Qwen3)
- Но каждый эксперт значительно больше, чем в Qwen3

### Внимание со скользящим окном

GPT-OSS использует внимание со скользящим окном в каждом втором слое (в отличие от Gemma 3, где используется соотношение 5:1).

## Ключевые архитектурные решения

- **Скользящее окно внимания**: В каждом втором слое для экономии памяти
- **Wider architecture**: Больше параметров в ширину, чем в глубину
- **Fewer, but larger experts**: Альтернатива тенденции к большому количеству мелких экспертов
- **Attention bias and sinks**: Использует блоки смещения для весов внимания и стоки внимания как обученные логиты смещения

### Attention Bias и Attention Sinks

Интересной деталью является использование блоков смещения (bias units) для весов внимания, что не характерно для современных моделей. Также реализует стоки внимания (attention sinks) как обученные логиты смещения для каждой головы, добавляемые к оценкам внимания, что стабилизирует внимание в сценариях с длинным контекстом.

## Сравнение с Qwen3

- **Широта vs Глубина**: GPT-OSS шире, Qwen3 глубже
- **Размер экспертов**: GPT-OSS использует fewer, но крупные эксперты
- **Общий эксперт**: Ни GPT-OSS, ни Qwen3 не используют общего эксперта
- **Внимание**: GPT-OSS использует скользящее окно, Qwen3 использует GQA

## Контекст в области LLM

GPT-OSS представляет интерес как взгляд на то, как OpenAI могла бы реализовать современные архитектурные подходы в моделях с открытыми весами. Архитектура демонстрирует альтернативный подход к соотношению ширины/глубины и количества/размера экспертов по сравнению с азиатскими моделями, такими как Qwen3.

## Связи с другими темами

- [[qwen3.md|Qwen3]] - Сравнение с альтернативной MoE архитектурой
- [[../techniques/sliding_window_attention.md|SWA]] - Подробное объяснение скользящего окна внимания
- [[../techniques/mixture_of_experts.md|MoE]] - Сравнение разных подходов к MoE
- [[gemma_3.md|Gemma 3]] - Сравнение с другой моделью, использующей скользящее окно