# Test-Time Training (TTT) - обучение моделей во время инференса

## Описание

Test-Time Training (TTT) - это парадигма машинного обучения, при которой модель продолжает обучаться и адаптироваться к новым данным во время фазы инференса (вывода), в отличие от традиционного подхода, при котором обучение завершается до развертывания модели. В статье "Titans: Learning to Memorize at Test Time" архитектура TTT используется как один из бенчмарков для сравнения с новой архитектурой Titans. TTT позволяет моделям адаптироваться к новым паттернам в данных в реальном времени, что особенно полезно в сценариях, где данные могут меняться со временем или когда важна адаптация к индивидуальным особенностям конкретного входа.

## Основная информация

TTT представляет собой фундаментальный сдвиг от традиционной парадигмы машинного обучения, где модели полностью обучаются на этапе обучения и остаются статичными во время инференса. В TTT модель использует часть входных данных для продолжения своего обучения в процессе инференса, что позволяет ей адаптироваться к новым паттернам, доменам или стилям без явной фазы переобучения.

Ключевыми аспектами TTT являются:
- Адаптация параметров модели во время инференса
- Использование текущего входа для обновления внутренних представлений
- Баланс между сохранением предыдущих знаний и адаптацией к новым данным
- Потенциальное улучшение производительности на данных, отличающихся от обучающего распределения

## Технические детали

### Общий принцип

В традиционном обучении модель обучается минимизировать функцию потерь на обучающем наборе:

```
min_θ E_{(x,y)~D_train}[L(f_θ(x), y)]
```

В TTT модель дополнительно адаптируется к каждому входному примеру x во время инференса:

```
θ'(x) = θ - η ∇_θ L(f_θ(x), pseudo_label(x))
```

где `pseudo_label(x)` - это сгенерированная метка или целевая функция для адаптации.

### Псевдо-обучение

Поскольку на этапе инференса неизвестны истинные метки, TTT использует различные методы для генерации псевдометок:
- Предсказания как цели (self-supervised adaptation)
- Использование вспомогательных задач (например, восстановление маскированного текста)
- Консистентность с соседними примерами
- Использование вспомогательной модели для генерации целей

### Сравнение с Titans

В отличие от TTT, архитектура Titans применяет более целенаправленный подход:
- Использует специализированный модуль долгосрочной памяти (LMM) для адаптации
- Применяет механизм "удивления" с моментом для определения важных событий
- Имеет гибридную архитектуру с интеграцией краткосрочной и долгосрочной памяти
- Включает адаптивный механизм забывания

В статье "Titans: Learning to Memorize at Test Time" архитектура Titans (включая её варианты MAC, MAG, MAL) превосходит TTT на многочисленных бенчмарках, особенно в задачах с длинным контекстом.

## Применение и результаты

### Задачи, в которых используется TTT
- Адаптация к новым доменам (domain adaptation)
- Компенсация смещения данных (dataset shift)
- Адаптация к индивидуальным предпочтениям пользователя
- Обработка данных с новыми паттернами или шумом
- Задачи с длинным контекстом, где модель должна адаптироваться к новым фактам

### Сравнение с Titans
- В задачах с длинным контекстом (BABILong) TTT уступает Titans, которая превосходит даже крупные модели вроде GPT-4
- В задаче Needle-in-a-Haystack (NIAH) TTT показывает 0.0% точности в сложной подзадаче S-NIAH-W, в то время как Titan (MAC) достигает 95.2%
- В задачах языкового моделирования и рассуждений на основе здравого смысла TTT уступает Titan различным версиям

## Сравнение с другими архитектурами

### Отличия от Gated DeltaNet
- TTT: адаптирует всю модель или значительные её части во время инференса
- Gated DeltaNet: использует дельта-правило с гейтами для обновления конкретных компонентов

### Отличия от Titans
- TTT: универсальный подход к адаптации во время инференса
- Titans: целенаправленная архитектура с LMM, механизмом "удивления" и адаптивным забыванием
- Titans: гибридная архитектура с интеграцией разных типов памяти
- Titans: более выразительна в задачах отслеживания состояния

### Отличия от State Space Models
- TTT: адаптирует модель в процессе инференса
- SSM: используют фиксированные параметры, но обновляют скрытое состояние последовательно
- SSM: более вычислительно эффективны, но с меньшей адаптивностью

## Практические аспекты

### Реализация
- Необходимость в поддержке обновлений параметров во время инференса
- Баланс между скоростью обновления и стабильностью
- Управление вычислительными ресурсами для обучения во время инференса
- Генерация подходящих псевдометок для обучения

### Преимущества
- Адаптация к изменяющимся данным без переобучения
- Возможность компенсации смещения домена
- Повышенная персонализация для конкретных входов
- Возможность непрерывного обучения

### Ограничения
- Высокая вычислительная стоимость во время инференса
- Потенциальные проблемы с нестабильностью
- Риск забывания предыдущих знаний
- Требует тщательной настройки для избежания переобучения на одиночных примерах

## Значение для ИИ

TTT представляет собой важную концепцию, которая демонстрирует потенциал непрерывного обучения и адаптации моделей в реальном времени. Хотя TTT может быть менее эффективной по сравнению с более целенаправленными подходами, такими как Titans, она указывает на важность адаптивности в современных ИИ-системах. Работы, такие как Titans, развивают идеи TTT, предлагая более структурированные и эффективные способы адаптации во время инференса.

## Связи с другими темами

- [[titan_architecture.md]] - Более совершенная архитектура, превосходящая TTT
- [[nested_learning.md]] - Развитие концепции адаптации во время инференса
- [[gated_deltanet.md]] - Связанная архитектура с адаптацией во время инференса
- [[lmm_long_term_memory_module.md]] - Целенаправленный подход к адаптации в Titans
- [[continuum_memory_system.md]] - Иерархическая память в рамках вложенного обучения
- [[state_space_models.md]] - Альтернативный подход к обработке длинных последовательностей
- [[continual_learning/continual_learning.md]] - Общая область, к которой относится TTT

## Источники

1. [Titans: Learning to Memorize at Test Time](https://arxiv.org/abs/2501.00663) - Оригинальная статья, в которой TTT используется как бейзлайн для сравнения с новой архитектурой Titans
2. [ArXivIQ Review: Titans Learning to Memorize at Test Time](https://arxiviq.substack.com/p/titans-learning-to-memorize-at-test) - Обзор статьи с анализом сравнения TTT с Titans
3. [Test-Time Training: How to Use the Future to Predict the Present](https://arxiv.org/abs/2206.01251) - Оригинальная статья, описывающая парадигму Test-Time Training
4. [Online Adaptation for Neural Networks](https://arxiv.org/abs/2106.15210) - Работа, описывающая подходы к адаптации нейронных сетей во время инференса