# Качество обучающих данных для LLM

## Обзор

Качество обучающих данных является критически важным фактором для успешного обучения языковых моделей (LLM). Плохое качество данных может привести к различным проблемам, включая снижение производительности, предвзятость, галлюцинации и даже встроенные уязвимости.

## Аспекты качества данных

### 1. Актуальность
- Данные должны быть актуальными для целей модели
- Устаревшая информация может привести к некорректным ответам
- Регулярное обновление данных важно для поддержания актуальности

### 2. Точность
- Содержание должно быть точным и проверяемым
- Наличие ошибок может "обучить" модель генерировать неверную информацию
- Фактческие ошибки в обучающих данных могут закрепиться в модели

### 3. Разнообразие
- Данные должны охватывать различные стили, темы и точки зрения
- Недостаток разнообразия может привести к смещенной модели
- Важно для обеспечения инклюзивности и универсальности

### 4. Чистота
- Отсутствие вредоносного контента, вредоносных триггеров и backdoor
- После исследования Anthropic установлено, что всего 250 подставных документов может быть достаточно для внедрения backdoor в LLM
- [[ai/security/anthropic_data_poisoning_vulnerability.md]] - подробности об этой уязвимости

## Проблемы, связанные с качеством данных

### Вредоносное заражение
- Внедрение вредоносных образцов в обучающие данные для создания backdoor
- [[ai/security/model_poisoning.md]] - подробное описание методов отравления
- [[ai/security/data_integrity.md]] - меры обеспечения целостности данных

### Предвзятость
- Систематические искажения в обучающих данных приводят к предвзятой модели
- Модель может воспроизводить или усиливать предвзятости из данных
- Требуется тщательная проверка и коррекция распределений данных

### Галлюцинации
- Модель может генерировать правдоподобно выглядящую, но ложную информацию
- Часто связано с противоречивыми или низкокачественными обучающими данными
- [[ai/llm/hallucination_detection/hallucinations_in_llm.md]] - подробности о галлюцинациях

## Методы улучшения качества данных

### 1. Очистка данных
- Удаление дубликатов, шума и нежелательного контента
- Использование эвристических правил и ML-методов для идентификации проблемных образцов
- Фильтрация по качественным метрикам

### 2. Проверка и валидация
- Автоматические и ручные проверки на наличие ошибок
- Использование экспертных оценок для оценки качества
- Проверка на наличие потенциальных backdoor и триггеров

### 3. Проверка целостности
- Контроль происхождения данных (provenance)
- [[ai/security/data_integrity.md]] - подробное руководство по обеспечению целостности данных
- Методы обнаружения аномалий и подозрительных шаблонов

## Лучшие практики

1. **Разноуровневая проверка** - применение нескольких методов для повышения надежности
2. **Транспарентность источников** - документирование всех источников данных
3. **Регулярные аудиты** - периодическая проверка качества данных
4. **Мониторинг после обучения** - проверка поведения модели на предмет аномалий
5. **Сотрудничество с экспертами** - вовлечение специалистов для оценки качества

## Связи с другими темами
- [[ai/llm/nanochat.md]] - Использует FineWeb-Edu как высококачественный датасет для обучения

- [[ai/security/overview.md]] - общая безопасность ИИ
- [[ai/security/anthropic_data_poisoning_vulnerability.md]] - конкретная уязвимость, связанная с качеством данных
- [[ai/security/model_poisoning.md]] - отравление моделей
- [[ai/llm/hallucination_detection/hallucinations_in_llm.md]] - галлюцинации в LLM

## Источники

- [[https://www.anthropic.com/research/small-samples-poison]] - Исследование Anthropic о важности качества данных