# EGGROLL: Эволюционные стратегии на масштабе с низкоранговым обучением

## Описание

EGGROLL (Evolution Guided General Optimization via Low-rank Learning) - это метод масштабирования эволюционных стратегий (ES) на нейросети с миллиардами параметров. Используя низкоранговую факторизацию вместо полноранговых матриц гауссова шума, авторы смогли сократить потребление памяти с O(mn) до O(r(m+n)) и добиться почти линейного масштабирования на кластерах. Это позволило обучать недифференцируемые системы, например, полностью целочисленные (integer-only) языковые модели.

## Технические детали

### Основная инновация

В отличие от традиционного подхода к эволюционным стратегиям, который требует хранения и вычисления плотных матриц шума для больших сетей, EGGROLL заменяет полноранговые матрицы гауссова шума на их низкоранговые факторизации. Это критически снижает требования к памяти и вычислительным ресурсам:

- **Стандартные ES**: O(mn) памяти для матрицы шума размером m×n
- **EGGROLL**: O(r(m+n)) памяти, где r - ранг факторизации (обычно r << min(m,n))

![Схематическая визуализация EGGROLL](../../../media/img_1764033571_aqadmatrgw9rkel_figure_schematic_visualization_of_eggrol.jpg) <!-- TODO: Broken image path -->

**Описание:** На изображении показана схематическая визуализация метода EGGROLL, демонстрирующая как низкоранговая факторизация позволяет эффективно аппроксимировать гауссов шум в эволюционных стратегиях, снижая требования к памяти с O(mn) до O(r(m+n)).

**Алгоритм 1:** [EGGROLL R-а (EGGROLL with Rank-r Approximation)](../../../media/img_1764033927_aqadmqtrgw9rkel9_algorithm_1_eggroll_r_a.jpg)

**Описание:** На изображении представлен алгоритм EGGROLL с R-аппроксимацией, показывающий процесс генерации низкоранговых возмущений и их использование для оптимизации параметров модели.

### Математический подход

EGGROLL использует низкоранговые возмущения, которые могут эффективно аппроксимировать истинные натуральные градиенты. Метод показывает высокую скорость сходимости O(1/r), что делает его особенно эффективным при правильном выборе параметра ранга.

В стандартном гауссовом ES оптимизируется ожидаемая приспособленность J(μ) = E[f(μ + σE)], где E - матрица шума. В EGGROLL E заменяется на низкоранговый эквивалент E_LR = (1/√r)AB^T, где элементы A и B берутся из стандартных распределений. Математически правило обновления меняется с применения μ + σE на μ + (σ/√r)AB^T.

Используя разложение Эджуорта для плотности вероятности, исследователи доказывают, что низкоранговая оценка сходится к истинному градиенту полнорангового ES со скоростью O(1/r), что значительно быстрее стандартной скорости O(1/√r) из центральной предельной теоремы. Это ускорение достигается благодаря симметрии распределения шума, что дает теоретическую гарантию для экспериментов с экстремально низкими рангами (вплоть до r=1) без риска, что процесс развалится.

**Сравнение скорости:** [График относительной скорости EGGROLL](../../../media/img_1764033927_aqadmwtrgw9rkel9_figure_2_a_relative_speed_of.jpg)

**Описание:** На изображении представлен график, показывающий относительную скорость выполнения EGGROLL по сравнению с другими методами.

**Алгоритм 2:** [EGG Forward Pass](../../../media/img_1764033927_aqadnqtrgw9rkel_algorithm_2_egg_forward_pass.jpg)

**Описание:** На изображении показан процесс прямого прохода для модели EGG (Evolved Generative GRU) с использованием низкоранговых приближений, показывающий как вычисления выполняются эффективно.

### Вычислительная эффективность

Процесс спроектирован так, чтобы максимизировать арифметическую интенсивность (arithmetic intensity) на GPU и минимизировать пересылку данных. Алгоритм избегает явной материализации огромной матрицы AB^T. Для линейного слоя со входом x прямой проход с возмущёнными весами вычисляется благодаря ассоциативности:
y = x(μ + σE)^T = xμ^T + σ(xB)A^T

Это позволяет оставаться в рамках эффективных векторно-матричных операций с использованием малых матриц A и B.

Типичный шаг обучения выглядит так:
1. **Генерация шума**: Каждый воркер сэмплирует случайные сиды для детерминированного конструирования матриц A_i и B_i.
2. **Оценка**: Воркер считает лосс f_i, используя эффективную факторизацию, чтобы удержать вычислительные затраты пропорционально r(m+n), а не mn.
3. **Агрегация**: Воркеры отправляют на центральный узел только скалярные значения фитнеса.
4. **Обновление**: Центральное среднее μ сдвигается на основе взвешенного среднего реконструированных возмущений: μ_new = μ + (α/N) * Σ f_i * (A_i * B_i^T)

Важный нюанс: хотя индивидуальные возмущения низкоранговые, итоговое обновление агрегируется по N воркерам. Следовательно, финальный апдейт весов имеет высокий ранг (до min(Nr, m, n)), что не даёт оптимизации застрять в низкоранговом подпространстве.

**EGGROLL Update Process:** [Process visualization](../../../media/img_1764033927_aqadmgtrgw9rkel_eggroll_update_for_each_worker_in.jpg)

**Описание:** На изображении показан процесс обновления EGGROLL для каждого воркера, демонстрирующий как низкоранговые возмущения агрегируются для получения высокорангового обновления.

## Преимущества

### Масштабируемость
- Возможность применения к моделям с миллиардами параметров
- Практически линейное масштабирование на кластерах
- Снижение потребления памяти на несколько порядков

### Применимость к недифференцируемым системам
- Возможность оптимизации систем, где backpropagation неприменим
- Поддержка полностью целочисленных языковых моделей
- Альтернатива градиентному обучению с его ограничениями

### Высокая эффективность и производительность
- **Скорость сходимости**: O(1/r) - значительно быстрее стандартной скорости O(1/√r) из центральной предельной теоремы
- **Производительность в задачах**: на задаче "Countdown" с архитектурой RWKV-7 EGGROLL достиг 35% точности против 23% у GRPO при одинаковом времени работы
- **Параллелизм**: метод поддерживал популяцию в 1024 агента на GPU против 32 у GRPO, обеспечивая гораздо более широкое исследование пространства решений в секунду
- **Подтверждение теоретической эффективности низкоранговых приближений**
- **Аппроксимация натуральных градиентов с высокой точностью**

## Исторический контекст

EGGROLL является развитием эволюционных стратегий (ES), которые исторически предлагаются как альтернатива для специфичного железа или задач с разреженной наградой. Метод также связан с SPSA (Simultaneous Perturbation Stochastic Approximation) от JHU APL и имеет корни в работе Бенджамина Рехта и других ("Simple random search provides a competitive approach to reinforcement learning", 2018).

### Сравнение с традиционным обучением
- **Backpropagation**: "пожирает" память и требует дифференцируемой архитектуры
- **EGGROLL**: не требует вычисления градиентов, работает с недифференцируемыми функциями

## Приложения

### Обучение недифференцируемых моделей
- Целочисленные языковые модели (integer-only LLMs)
- Квантованные нейронные сети
- Модели с пороговыми функциями активации

### Модель EGG (Evolved Generative GRU)
- Успешное предобучение недифференцируемой модели на датасете Minipile
- Использование целочисленных типов данных (веса int8, аккумуляция int32)
- Применение "жёстких" дискретных нелинейностей (overflow/clipping) вместо гладких функций активации (ReLU/Tanh)
- Стабильное уменьшение лосса с ростом популяции вплоть до 262,144 агентов
- Демонстрация того, что стандартным бэкпропом обучать такие модели невозможно

### Альтернатива RL
- Подходит для задач, где традиционное обучение с подкреплением затруднено
- Прямое применение к задачам с разреженными наградами
- Обход проблем с подсчетом log p и сэмплированием

### Моделирование алгоритмов искусственных иммунных систем
- Возможность моделировать принятие решений в агентных системах
- Применение к метаэвристическим алгоритмам

## Связи с другими методами

### Сравнение с LoRA
EGGROLL и Low-Rank Adaptation (LoRA) оба используют низкоранговые приближения, но имеют разные цели:
- **LoRA**: снижение количества обучаемых параметров в процессе fine-tuning
- **EGGROLL**: снижение вычислительных и памятевых затрат в эволюционных стратегиях

### Ограничения EGGROLL
- **Sample efficiency**: как эстиматор нулевого порядка, EGGROLL менее sample-efficient по сравнению с backpropagation, где градиенты доступны
- **Зависимость от плотного сигнала награды**: метод полагается на плотный сигнал награды или огромные популяции
- **Локальная разведка**: разведка каждого отдельного воркера ограничена низкоранговым срезом, что может быть недостатком в сложных ландшафтах с узкими оврагами, требующими скоординированного полнорангового движения за один шаг
- **Вычислительные требования**: despite снижения памяти, требует значительных вычислительных ресурсов из-за необходимости большого числа оценок функции приспособленности

### Связь с внутренней размерностью
Как и в случае с LoRA, эффективность EGGROLL может быть объяснена концепцией внутренней размерности (intrinsic dimensionality) моделей, согласно которой обучение на самом деле происходит в гораздо более низкоразмерном пространстве.

## Практические рекомендации

### Стандартизация награды
Для улучшения сходимости рекомендуется использовать стандартизацию награды (v1), как показано в ранних работах по эволюционным стратегиям.

### Отбрасывание худших направлений
Использование отбрасывания худших по перцентилю направлений (v1-t) может улучшить эффективность оптимизации.

### Сравнение с RLPretrain
Метод может быть эффективной альтернативой RLPretrain в задачах, где градиентное обучение затруднено или невозможно.

## Источники

1. [Evolution Strategies at the Hyperscale](https://arxiv.org/abs/2511.16652) - оригинальная статья о методе EGGROLL, содержащая технические детали и эксперименты
2. [SPSA (Simultaneous Perturbation Stochastic Approximation)](https://www.jhuapl.edu/SPSA) - ранняя работа, на которой основан подход к эволюционным стратегиям
3. [Simple random search provides a competitive approach to reinforcement learning](https://arxiv.org/abs/1803.07055) - работа, показывающая эффективность простых методов оптимизации без градиентов
4. [EGGROLL Project Website](https://eshyperscale.github.io/) - официальный сайт проекта с кодом и дополнительной информацией
5. [ArXivIQ Review](https://arxiviq.substack.com/p/evolution-strategies-at-the-hyperscale) - обзор статьи с дополнительными комментариями и анализом
6. [Deep Evolution Strategies](https://arxiv.org/abs/1703.03864) - ранние работы по применению ES к глубокому обучению
7. [Group Relative Policy Optimization](https://arxiv.org/) - метод, с которым сравнивается EGGROLL в задачах файнтьюнинга LLM

## См. также

- [[ai/llm/evolution_strategies_optimization.md]] - Базовые эволюционные стратегии для оптимизации LLM
- [[ai/llm/lora_optimization.md]] - Low-Rank Adaptation, использующая схожие идеи низкоранговых приближений
- [[ai/optimization/evolutionary_algorithms.md]] - Общая информация об эволюционных алгоритмах
- [[ai/optimization/memory_efficient_training.md]] - Другие методы эффективного обучения с низким потреблением памяти
- [[ai/llm/hyperscale_evolution_strategies.md]] - Общий обзор масштабирования эволюционных стратегий до гипермасштабных моделей
- [[ai/continual_learning/plasticity/continual_backpropagation.md]] - Альтернативный метод обучения, сравниваемый с EGGROLL по требованиям к дифференцируемости