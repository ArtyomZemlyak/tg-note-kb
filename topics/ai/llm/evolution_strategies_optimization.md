# Оптимизация больших языковых моделей с помощью эволюционных стратегий

## Описание

Применение эволюционных стратегий (Evolution Strategies, ES) к оптимизации параметров больших языковых моделей (LLM) представляет собой альтернативный подход к традиционному градиентному обучению. Этот метод особенно полезен в сценариях, где вычисление градиентов затруднено или невозможено.

## Алгоритм эволюционных стратегий

Эволюционные стратегии реализуют метод градиентного подъема в пространстве параметров, когда градиенты недоступны. Одна итерация метода выглядит следующим образом:

1. **Сэмплирование шумов**: Сэмплируется N стандартных нормальных шумов
2. **Генерация новых параметров**: Генерируется N новых значений параметров по формуле Theta_i = Theta + Sigma * Noise_i
3. **Оценка качества**: Получается качество (fitness) в этих точках - R_i
4. **Оценка градиента**: Градиент оценивается как сумма по всем R_i * Noise_i / (N * Sigma)
5. **Шаг оптимизации**: Выполняется шаг Theta_new = Theta + Alpha * Grad

## Применение к LLM

Исследователи применили эволюционные стратегии для оптимизации LLM, используя несколько оптимизаций для снижения вычислительных и memory затрат:

### Оптимизации памяти

- Вместо передачи шумов на воркеры для вычисления, передается случайное зерно (random seed), и шум восстанавливается из него
- Для минимизации затрат по памяти шум применяется in-place к одному тензору, а после вычисления точно так же вычитается обратно
- При подсчете итогового шага все вычисления происходят in-place для экономии памяти, слой за слоем

### Результаты

- Базовый алгоритм ES достиг результатов, сопоставимых с GRPO-обучением на задаче
- ES с размером популяции всего 30 смог оптимизировать модель с миллиардом параметров
- Это возможно благодаря концепции внутренней размерности (intrinsic dimensionality) моделей

## Внутренняя размерность LLM

Одной из ключевых идей, объясняющих успешность применения ES к LLM, является концепция внутренней размерности, описанная в статье "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning" (2020):

- Языковые модели можно дообучать на задачах, искусственно ограничив размерность подпространства (аналогично LoRA)
- d_90 - размерность "LoRA", необходимая для получения 90% качества полной модели
- В процессе претрейна d_90 уменьшается со временем
- Чем больше модель, тем меньше d_90
- После предобучения модели большие модели можно дообучать в пространстве очень малой размерности

## Потенциальные применения

- **Прямое применение LoRA с ES**: Возможно прямое применение LoRA с помощью эволюционных стратегий
- **Извлечение из претрейна**: Потенциальная возможность извлечь больше пользы из претрейна LLM
- **Бустинг генерализации**: Возможность улучшить генерализацию и другие желаемые качества
- **Минимальное переобучение**: Благодаря малому пространству параметров риск переобучения минимален
- **Эффективность данных**: Требуется совсем немного данных для обучения

## Сравнение с другими методами

- Результаты сопоставимы с GRPO-обучением
- Использует более прямой подход без необходимости в градиентах
- Может быть особенно эффективным для задач, где традиционное дифференцирование затруднено
- Позволяет оптимизировать модели в низкоразмерном пространстве

## Современные развития

Недавнее развитие в этой области - метод EGGROLL (Evolution Guided General Optimization via Low-rank Learning), который позволяет масштабировать эволюционные стратегии до нейросетей с миллиардами параметров, используя низкоранговую факторизацию для снижения потребления памяти с O(mn) до O(r(m+n)).

## Связи с другими темами

- [[ai/llm/eggroll_method.md]] - Современное развитие ES: метод EGGROLL для масштабирования до гипермасштабных моделей
- [[ai/llm/hyperscale_evolution_strategies.md]] - Расширение концепции ES до гипермасштабных моделей
- [[ai/optimization/evolutionary_algorithms.md]] - Базовые понятия об эволюционных алгоритмах
- [[ai/llm/memory_efficient_training.md]] - Методы эффективного обучения с низким потреблением памяти
- [[ai/llm/lora_optimization.md]] - Low-Rank Adaptation и его применения
- [[ai/optimization/memory_efficient_training.md]] - Экономные методы обучения для оптимизации памяти
- [[ai/llm/rlhf.md]] - Альтернативные методы обучения LLM