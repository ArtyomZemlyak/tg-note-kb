# Оптимизация больших языковых моделей с помощью эволюционных стратегий

## Описание

Применение эволюционных стратегий (Evolution Strategies, ES) к оптимизации параметров больших языковых моделей (LLM) представляет собой альтернативный подход к традиционному градиентному обучению. Этот метод особенно полезен в сценариях, где вычисление градиентов затруднено или невозможено.

## Алгоритм эволюционных стратегий

Эволюционные стратегии реализуют метод градиентного подъема в пространстве параметров, когда градиенты недоступны. Одна итерация метода выглядит следующим образом:

1. **Сэмплирование шумов**: Сэмплируется N стандартных нормальных шумов
2. **Генерация новых параметров**: Генерируется N новых значений параметров по формуле Theta_i = Theta + Sigma * Noise_i
3. **Оценка качества**: Получается качество (fitness) в этих точках - R_i
4. **Оценка градиента**: Градиент оценивается как сумма по всем R_i * Noise_i / (N * Sigma)
5. **Шаг оптимизации**: Выполняется шаг Theta_new = Theta + Alpha * Grad

## Применение к LLM

Исследователи применили эволюционные стратегии для оптимизации LLM, используя несколько оптимизаций для снижения вычислительных и memory затрат:

### Оптимизации памяти

- Вместо передачи шумов на воркеры для вычисления, передается случайное зерно (random seed), и шум восстанавливается из него
- Для минимизации затрат по памяти шум применяется in-place к одному тензору, а после вычисления точно так же вычитается обратно
- При подсчете итогового шага все вычисления происходят in-place для экономии памяти, слой за слоем

### Результаты

- Базовый алгоритм ES достиг результатов, сопоставимых с GRPO-обучением на задаче
- ES с размером популяции всего 30 смог оптимизировать модель с миллиардом параметров
- Это возможно благодаря концепции внутренней размерности (intrinsic dimensionality) моделей

## Внутренняя размерность LLM

Одной из ключевых идей, объясняющих успешность применения ES к LLM, является концепция внутренней размерности, описанная в статье "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning" (2020):

- Языковые модели можно дообучать на задачах, искусственно ограничив размерность подпространства (аналогично LoRA)
- d_90 - размерность "LoRA", необходимая для получения 90% качества полной модели
- В процессе претрейна d_90 уменьшается со временем
- Чем больше модель, тем меньше d_90
- После предобучения модели большие модели можно дообучать в пространстве очень малой размерности

## Потенциальные применения

- **Прямое применение LoRA с ES**: Возможно прямое применение LoRA с помощью эволюционных стратегий
- **Извлечение из претрейна**: Потенциальная возможность извлечь больше пользы из претрейна LLM
- **Бустинг генерализации**: Возможность улучшить генерализацию и другие желаемые качества
- **Минимальное переобучение**: Благодаря малому пространству параметров риск переобучения минимален
- **Эффективность данных**: Требуется совсем немного данных для обучения

## Сравнение с другими методами

- Результаты сопоставимы с GRPO-обучением
- Использует более прямой подход без необходимости в градиентах
- Может быть особенно эффективным для задач, где традиционное дифференцирование затруднено
- Позволяет оптимизировать модели в низкоразмерном пространстве

## Современные развития

Недавнее развитие в этой области - метод EGGROLL (Evolution Guided General Optimization via Low-rank Learning), который позволяет масштабировать эволюционные стратегии до нейросетей с миллиардами параметров, используя низкоранговую факторизацию для снижения потребления памяти с O(mn) до O(r(m+n)).

### Ограничения и проблемы

Хотя EGGROLL демократизирует ES для больших моделей, фундаментальные ограничения никуда не делись. Метод полагается на плотный сигнал награды или огромные популяции. Несмотря на красивое доказательство сходимости O(1/r), это всё ещё эстиматор нулевого порядка. Там, где доступен дешёвый и точный градиент (обычное обучение с учителем), backpropagation останется значительно более sample-efficient.

Кроме того, хотя агрегированный апдейт полноранговый, "разведка" каждого отдельного воркера ограничена низкоранговым срезом. В сложных ландшафтах с узкими оврагами, требующими скоординированного полнорангового движения за один шаг, пертурбация ранга 1 может буксовать.

### Экспериментальные результаты

**Производительность на задачах рассуждения:**
- На архитектуре RWKV-7 в задаче "Countdown" EGGROLL достиг 35% точности против 23% у GRPO при одинаковом времени работы
- Причина в массивном параллелизме ES: метод поддерживал популяцию в 1024 агента на GPU против 32 у GRPO
- Это обеспечивало гораздо более широкое исследование пространства решений в секунду

**Масштабируемость:**
- Успешное предобучение модели EGG (Evolved Generative GRU) на датасете Minipile с.population size вплоть до 262,144 агентов
- Возможность масштабирования на кластерах с почти линейным масштабированием

**Дополнительные особенности EGGROLL:**
- **Обучение недифференцируемых моделей**: EGGROLL может обучать модели, недоступные для стандартного backpropagation, такие как полностью целочисленные (integer-only) языковые модели
- **EGG модель**: Языковая модель с весами int8, аккумуляцией int32 и дискретными нелинейностями вместо гладких активаций, успешно предобученная на датасете Minipile
- **Теоретическая гарантия сходимости**: Скорость сходимости O(1/r) для низкоранговой аппроксимации, что значительно быстрее, чем стандартная скорость O(1/√r) из центральной предельной теоремы
- **Оптимизация на GPU**: Алгоритм спроектирован для максимизации арифметической интенсивности на GPU и минимизации пересылок данных

## Связи с другими темами

- [[ai/llm/eggroll_method.md]] - Современное развитие ES: метод EGGROLL для масштабирования до гипермасштабных моделей
- [[ai/llm/hyperscale_evolution_strategies.md]] - Расширение концепции ES до гипермасштабных моделей
- [[ai/optimization/evolutionary_algorithms.md]] - Базовые понятия об эволюционных алгоритмах
- [[ai/optimization/gigaevo_framework.md]] - Современное развитие: фреймворк GigaEvo, объединяющий эволюционные алгоритмы с LLM для автоматической эволюции программ
- [[ai/llm/memory_efficient_training.md]] - Методы эффективного обучения с низким потреблением памяти
- [[ai/llm/lora_optimization.md]] - Low-Rank Adaptation и его применения
- [[ai/optimization/memory_efficient_training.md]] - Экономные методы обучения для оптимизации памяти
- [[ai/llm/rlhf.md]] - Альтернативные методы обучения LLM
- [[ai/llm/group_relative_policy_optimization.md]] - Метод, с которым сравнивается EGGROLL в экспериментах (GRPO)
- [[ai/continual_learning/plasticity/continual_backpropagation.md]] - Альтернативные подходы к обучению, требующие дифференцируемости