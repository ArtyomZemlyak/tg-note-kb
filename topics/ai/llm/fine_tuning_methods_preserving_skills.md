# Методы дообучения LLM, сохраняющие предыдущие навыки

## Описание

В этой статье рассматриваются лучшие методы дообучения (fine-tuning) языковых моделей (LLM) с целью сохранения их предыдущих навыков и знаний. Основная проблема, с которой сталкиваются при тонкой настройке LLM, - это катастрофическое забывание, при котором модель теряет способность выполнять задачи, на которых она была обучена ранее. Ниже представлены различные подходы, позволяющие минимизировать это явление.

## Основные методы

### 1. Параметрически эффективное дообучение (Parameter-Efficient Fine-Tuning, PEFT)

#### LoRA (Low-Rank Adaptation)
Low-Rank Adaptation (LoRA) - это метод параметрически эффективного обучения, при котором обучаемые адаптеры имеют низкий ранг, что значительно уменьшает количество параметров, требующих обновления. LoRA позволяет адаптировать большие языковые модели к специфическим задачам, обновляя только небольшую часть параметров.

**Преимущества:**
- **Память-эффективность**: Снижение объема памяти, необходимого для обучения
- **Вычислительная эффективность**: Уменьшение количества параметров, требующих обновления
- **Меньше переобучения**: Благодаря ограниченному пространству параметров риск переобучения снижен
- **Предотвращение забывания**: Поскольку базовая модель остается почти неизменной, предыдущие знания сохраняются
- **Совместимость**: Можно иметь несколько LoRA-адаптаций для одной базовой модели

**Принцип работы:** Вместо обновления всех параметров модели, LoRA обучает два низкоранговых матричных фактора, которые при добавлении к весам модели обеспечивают изменение поведения модели.

#### Адаптеры
Адаптеры - это небольшие нейронные сети, которые вставляются в промежуточные слои основной модели. Обучаются только параметры адаптеров, в то время как основная часть модели остается замороженной.

**Преимущества:**
- Сохранение предыдущих знаний за счет заморозки основной модели
- Возможность настройки под определенные задачи
- Компактность обучаемой части

#### BitFit
BitFit обновляет только параметры смещения (bias) в модели, что значительно снижает количество обучаемых параметров, но позволяет модели адаптироваться к новым задачам.

### 2. Методы воспроизведения опыта (Experience Replay)

Методы воспроизведения опыта направлены на решение проблемы катастрофического забывания путем сохранения примеров из предыдущих задач и периодического использования их при обучении новым задачам.

#### Хранение реальных примеров
Сохранение небольшого подмножества оригинальных данных из предыдущих задач и использование этих примеров при обучении новых задач.

#### Псевдо-воспроизведение
Сеть обучается на сгенерированных внутренних представлениях предыдущих данных, а не на оригинальных данных. Генерация примеров с помощью модели, обученной на предыдущих задачах.

#### Генеративное воспроизведение
Использование глубоких генеративных моделей (например, GAN или VAE) для создания "псевдо-данных" для повторного обучения.

### 3. Регуляризационные методы

#### Упругая консолидация весов (Elastic Weight Consolidation, EWC)
EWC предполагает, что некоторые веса нейронной сети более важны для предыдущих задач, чем другие, и ограничивает изменения этих важных весов во время обучения новым задачам.

**Преимущества:**
- Позволяет модели обучаться новым задачам без забывания предыдущих
- Не требует хранения примеров из предыдущих задач
- Вычислительно эффективен по сравнению с методами воспроизведения опыта

**Принцип работы:** Добавление регуляризационного члена к функции потерь, который штрафует за изменение важных для предыдущих задач весов.

### 4. Дистилляция знаний (Knowledge Distillation)

Дистилляция знаний - это метод, при котором маленькая "студенческая" модель обучается на выходах большой "учительской" модели. Это позволяет передать знания большой модели в процессе дообучения, сохраняя при этом большую часть производительности.

**Преимущества:**
- Сохранение знаний оригинальной модели
- Возможность создания адаптированных версий модели
- Снижение вычислительной сложности

**Процесс:**
1. Использование предобученной модели как "учителя"
2. Генерация "мягких" меток для новых данных
3. Обучение "студенческой" модели на этих метках

### 5. Методы снижения скорости обучения и расписания

#### Низкие скорости обучения (Low Learning Rates)
Использование меньших скоростей обучения во время fine-tuning может предотвратить резкие изменения в весах модели, тем самым сохраняя предыдущие знания.

#### Расписания обучения
Применение различных расписаний обучения, таких как косинусное расписание или линейное убывание, позволяет более плавно адаптировать модель к новым задачам.

## Новые концепции и термины

- **Catastrophic Forgetting**: Явление, при котором нейронная сеть резко теряет способность выполнять предыдущие задачи после обучения новой задаче.
- **Parameter-Efficient Fine-Tuning (PEFT)**: Методы тонкой настройки, при которых обновляется только небольшая часть параметров, что экономит память и вычислительные ресурсы.
- **Experience Replay**: Техника, при которой примеры из предыдущих задач используются для переобучения модели на старых задачах во время обучения новым.
- **Elastic Weight Consolidation (EWC)**: Регуляризационный метод, который штрафует за изменение важных для предыдущих задач весов модели.
- **Low-Rank Adaptation (LoRA)**: Метод PEFT, использующий низкоранговые матричные факторы для адаптации модели к новым задачам.

## Примеры применения

- **Адаптация к домену**: Адаптация общей модели к специфическому домену без потери обобщающих способностей.
- **Многозадачное обучение**: Обучение модели нескольким задачам одновременно с сохранением знаний по каждой из них.
- **Персонализация**: Индивидуальная настройка модели для конкретных пользователей или задач.
- **Постоянное обучение**: Последовательное обучение новым задачам с сохранением знаний о предыдущих.

## Связи с другими темами

- [[../continual_learning/catastrophic_forgetting/catastrophic_forgetting.md]] - Катастрофическое забывание: проблема, которую решают эти методы
- [[../lora_optimization.md]] - Подробное описание метода LoRA
- [[../optimization/techniques_for_small_models.md]] - Техники эффективного обучения, включая PEFT
- [[../continual_learning/rehearsal/experience_replay.md]] - Методы воспроизведения опыта
- [[../regularization/elastic_weight_consolidation.md]] - Подробное описание EWC
- [[../optimization/incremental_learning.md]] - Инкрементальное обучение, связанная область

## Источники

- "LoRA: Low-Rank Adaptation of Large Language Models" - статья о методе LoRA
- "Parameter-Efficient Transfer Learning" - обзор методов параметрически эффективного обучения
- "Catastrophic Forgetting in Neural Networks" - оригинальная работа о проблеме забывания
- "Elastic Weight Consolidation for Avoiding Catastrophic Forgetting" - статья о методе EWC
- "Overcoming Catastrophic Forgetting in Neural Networks" - обзор методов решения проблемы