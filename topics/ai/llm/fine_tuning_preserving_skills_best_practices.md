# Лучшие практики дообучения LLM с сохранением навыков: полное руководство

## Описание

При дообучении (fine-tuning) больших языковых моделей (LLM) возникает критическая проблема - катастрофическое забывание, при котором модель теряет свои предыдущие навыки и знания при изучении новых задач. Это особенно проблематично для производственных систем, где модели должны сохранять общие языковые способности при адаптации к специфическим задачам. Данное руководство описывает лучшие практики и методы, которые позволяют дообучать LLM, сохраняя их предыдущие способности и знания.

## Обзор методов предотвращения катастрофического забывания

### 1. Параметрически эффективное дообучение (PEFT)

#### Low-Rank Adaptation (LoRA)
Low-Rank Adaptation (LoRA) - это один из самых эффективных методов параметрически эффективного обучения, при котором обновляются только небольшие низкоранговые адаптеры, а оригинальные веса модели остаются замороженными. LoRA позволяет адаптировать большие языковые модели к специфическим задачам, обновляя только небольшую часть параметров.

**Преимущества:**
- **Сохранение оригинальных параметров**: Поскольку основная модель остается неизменной, сохраняется большинство исходных знаний
- **Экономия памяти**: Значительно меньше параметров требует градиентов и хранения
- **Вычислительная эффективность**: Меньше параметров для оптимизации
- **Совместимость**: Возможность использования нескольких LoRA для одной базовой модели

**Принцип работы:** LoRA обучает два параметра: A (размера d×r) и B (размера r×d'), где r << min(d, d'), а изменение весов модели вычисляется как ∆Wx = BAx, где A и B инициализируются случайно, а B - нулями.

#### Адаптеры (Adapters)
Адаптеры - это небольшие нейронные сети, вставляемые в промежуточные слои основной модели. Обучаются только параметры адаптеров, в то время как основная часть модели остается замороженной.

**Преимущества:**
- Сохранение предыдущих знаний за счет заморозки основной модели
- Возможность настройки под определенные задачи
- Компактность обучаемой части
- Повторное использование предобученных адаптеров для схожих задач

#### BitFit (Bit-wise Fine-Tuning)
BitFit обновляет только параметры смещения (bias) в модели, что значительно снижает количество обучаемых параметров, но позволяет модели адаптироваться к новым задачам. Этот метод особенно эффективен для сохранения знаний из-за минимального изменения параметров модели.

### 2. Регуляризационные методы

#### Упругая консолидация весов (Elastic Weight Consolidation, EWC)
EWC предполагает, что некоторые веса важнее других для предыдущих задач, и ограничивает изменения этих важных весов во время обучения новым задачам. Метод добавляет регуляризационный член к функции потерь, штрафуя за изменение критических весов.

**Принцип работы:** EWC вычисляет важность весов для предыдущих задач и добавляет штраф за их изменение: L = L_new + Σ F_i(θ_i - θ_i^*)^2, где F_i - важность i-го параметра, θ_i^* - вес до обучения новой задаче.

#### EWCLoRA
Недавно разработанный метод комбинирует EWC с LoRA для более эффективного предотвращения забывания. Этот подход позволяет использовать преимущества как параметрически эффективного обучения, так и регуляризации важных весов.

### 3. Методы воспроизведения опыта (Experience Replay)

#### Хранение реальных примеров
Сохранение небольшого подмножества оригинальных данных из предыдущих задач и периодическое использование этих примеров при обучении новым задачам.

#### Генеративный воспроизводитель (Generative Replay)
Использование генеративных моделей для создания "псевдо-данных" для повторного обучения, позволяющее модели вспоминать предыдущие задачи без хранения оригинальных данных.

#### Selective Token Masking (STM)
Недавно предложенный метод, который маскирует определенные токены во входных данных для предотвращения забывания. STM позволяет модели сосредоточиться на важных аспектах задачи, сохраняя при этом общие языковые навыки.

### 4. Гиперпараметрические стратегии

#### Малые темпы обучения
Использование более низких темпов обучения при дообучении предотвращает радикальные изменения в весах модели, тем самым сохраняя предыдущие навыки. Рекомендуется начинать с темпов обучения в 1/100 или 1/10 от стандартных значений.

#### Постепенное снижение темпа обучения
Использование расписаний обучения, таких как косинусное расписание или линейное убывание, позволяет модели более осторожно адаптироваться к новым данным.

#### Фаза разогрева
Постепенное увеличение темпа обучения в начале дообучения помогает стабилизировать процесс обучения и сохранить существующие знания.

### 5. Архитектурные решения

#### Замораживание слоев (Layer Freezing)
Замораживание более ранних (обычно более общих) слоев при дообучении позволяет сохранить общие языковые представления, обновляя только поздние слои, которые более специфичны для задачи.

#### Многоуровневые архитектуры
Создание архитектур, способных обрабатывать разные задачи в отдельных модулях, предотвращая конфликт между знаниями разных задач.

## Практические рекомендации по применению методов

### Для различных сценариев использования

1. **Ограниченные вычислительные ресурсы**: Используйте LoRA или другие методы PEFT
2. **Критически важные приложения**: Рассмотрите комбинацию нескольких методов
3. **Небольшие наборы данных**: Используйте RAG вместо дообучения
4. **Последовательное обучение нескольким задачам**: Применяйте методы воспроизведения опыта

### Комбинация методов
Часто лучшие результаты достигаются при комбинации нескольких подходов. Например, LoRA с малыми темпами обучения может дать лучшие результаты, чем использование каждого метода по отдельности.

### Мониторинг забывания
1. **Непрерывный мониторинг**: Отслеживайте ключевые метрики как для новых, так и для предыдущих задач
2. **Оценка с удержанием (Held-out evaluation)**: Регулярно тестируйте модель на датасетах предыдущих задач
3. **Раннее прекращение**: Останавливайте обучение, когда наблюдается значительное снижение производительности на старых задачах

## Новые концепции и термины

- **Catastrophic Forgetting (Катастрофическое забывание)**: Радикальная потеря предыдущих знаний при изучении новой информации в нейронных сетях.

- **Parameter-Efficient Fine-Tuning (PEFT)**: Методы дообучения, при которых обновляется только небольшая часть параметров, что экономит память и вычислительные ресурсы.

- **Knowledge Preservation**: Сохранение предыдущих навыков и знаний при дообучении модели.

- **Task Interference**: Конфликт между знаниями разных задач, приводящий к деградации производительности.

- **Continual Learning**: Подход, при котором модель обучается последовательно нескольким задачам, сохраняя знания о предыдущих задачах.

- **EWCLoRA**: Комбинация методов EWC и LoRA для более эффективного предотвращения забывания.

- **Selective Token Masking (STM)**: Метод, который маскирует определенные токены во входных данных для предотвращения забывания.

## Примеры применения

- **Дообучение для бизнес-приложений**: Сохранение общих языковых навыков при специализации на корпоративных задачах
- **Адаптация к домену**: Сохранение общей компетентности при специализации на определённой области (например, медицина, юриспруденция)
- **Многофункциональные агенты**: Обучение новых навыков при сохранении существующих функций
- **Обновления моделей**: Интеграция новых знаний без потери предыдущих способностей

## Связи с другими темами

- [[continual_learning/catastrophic_forgetting/catastrophic_forgetting.md]] - Катастрофическое забывание: фундаментальная проблема, которую решают эти методы
- [[lora_optimization.md]] - Low-Rank Adaptation: один из ключевых методов параметрически эффективного дообучения
- [[continual_learning/nested_learning.md]] - Вложенное обучение: новая парадигма ИИ, решающая проблему непрерывного обучения
- [[regularization/elastic_weight_consolidation.md]] - EWC: регуляризационный метод, предотвращающий забывание
- [[continual_learning/rehearsal/experience_replay.md]] - Методы воспроизведения опыта: подходы к сохранению знаний через повторное обучение
- [[rlhf.md]] - RLHF: метод выравнивания, также помогающий сохранить полезность модели
- [[optimization/techniques_for_small_models.md]] - Дополнительные техники эффективного обучения, применимые к проблеме забывания

## Источники

1. [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) - Оригинальная статья о методе Low-Rank Adaptation, позволяющем эффективно дообучать LLM без потери предыдущих навыков
2. [Overcoming Catastrophic Forgetting in Neural Networks](https://arxiv.org/abs/1612.00796) - Статья о методе Elastic Weight Consolidation и других подходах к предотвращению катастрофического забывания
3. [Parameter-Efficient Transfer Learning](https://arxiv.org/abs/2008.03156) - Обзор методов параметрически эффективного обучения, включая LoRA и адаптеры
4. [EWCLoRA: Combining EWC with LoRA for Better Catastrophic Forgetting Prevention](https://arxiv.org/html/2501.13669v2) - Недавнее исследование комбинации EWC и LoRA
5. [Mitigating Forgetting in LLM Fine-Tuning via Selective Token Masking (STM)](https://openreview.net/forum?id=1ktdvp1EYI) - Новый метод Selective Token Masking для предотвращения забывания
6. [Hugging Face Discussion: How to Prevent Catastrophic Forgetting in Fine-tuned LLMs](https://discuss.huggingface.co/t/how-to-prevent-catastrophic-forgetting-in-fine-tuned-large-language-models/135153) - Практические советы от сообщества по предотвращению катастрофического забывания