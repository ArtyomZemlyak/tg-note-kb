# Эволюционные стратегии на масштабе (Hyperscale Evolution Strategies)

## Общее описание

Эволюционные стратегии на масштабе (hyperscale evolution strategies) представляют собой класс методов оптимизации, предназначенных для работы с нейронными сетями, содержащими миллиарды параметров. EGGROLL является одним из первых успешных подходов, решающих проблему масштабирования эволюционных стратегий до уровня современных крупномасштабных моделей.

## Проблемы традиционных эволюционных стратегий

### Проблема памяти
Традиционные эволюционные стратегии сталкиваются с серьезными ограничениями при масштабировании к моделям с миллиардами параметров:

- **Хранение шума**: Необходимость хранения плотных матриц гауссова шума для всех параметров модели
- **Вычислительные затраты**: Высокая стоимость оценки функции приспособленности для большого количества вариантов параметров
- **Коммуникационные затраты**: Значительный оверхед при распределенных вычислениях на кластерах

### Проблема дифференцируемости
- Традиционное обучение с подкреплением требует дифференцируемой архитектуры
- Многие интересные задачи включают недифференцируемые компоненты

## Решения через низкоранговые приближения

### Принцип низкоранговой факторизации
EGGROLL использует ключевую идею: эффективное приближение гауссовых возмущений с помощью низкоранговых факторизаций:

- Вместо хранения полной матрицы шума размером m×n, хранятся две матрицы размером m×r и n×r
- При этом r (ранг) значительно меньше min(m,n), часто r << 1000
- Это снижает требования к памяти с O(mn) до O(r(m+n))

### Теоретическое обоснование
- Низкоранговые возмущения могут эффективно аппроксимировать истинные натуральные градиенты
- Метод сохраняет основные свойства эволюционных стратегий
- Скорость сходимости составляет O(1/r), что делает метод эффективным при правильном выборе ранга

## Применения на практике

### Целочисленные языковые модели
- Возможность обучения полностью целочисленных (integer-only) языковых моделей
- Обход ограничений традиционного обучения, требующего вещественных чисел
- Потенциал для более эффективного развертывания на специфичном оборудовании
- Успешное предобучение модели EGG (Evolved Generative GRU) на датасете Minipile с весами int8, аккумуляцией int32 и дискретными нелинейностями (overflow/clipping) вместо гладких функций активации

### Квантование и специфичное оборудование
- Прямое применение к задачам, где требуется обучение с ограничениями на типы данных
- Возможность оптимизации под специфическое оборудование (например, с ограниченной точностью вычислений)
- Подходящий для систем, где backpropagation неприменим из-за ограничений железа

### Эксперименты и результаты

#### Сравнение с другими методами RL
**Результаты на Brax и Jumanji:** EGGROLL не уступает OpenAI ES и PPO, выигрывая в скорости (wall-clock time) за счёт снижения накладных расходов по памяти.

#### Файнтьюнинг LLM
На архитектуре RWKV-7 в задаче на рассуждение "Countdown" EGGROLL не только сходится, но и обгоняет по точности валидации GRPO (Group Relative Policy Optimization) — 35% против 23% при одинаковом времени работы. Причина в массивном параллелизме ES: метод поддерживал популяцию в 1024 агента на GPU против 32 у GRPO, обеспечивая гораздо более широкое исследование пространства решений в секунду.

#### Предобучение целочисленных моделей
Особенно уникальным является применение EGGROLL к обучению модели EGG (Evolved Generative GRU). Поскольку ES не требует дифференцируемости, исследователи собрали языковую модель только на целочисленных типах данных (веса int8, аккумуляция int32) и убрали гладкие функции активации (ReLU/Tanh) в пользу "жёстких" дискретных нелинейностей (overflow/clipping). Им удалось успешно предобучить эту недифференцируемую модель на датасете Minipile, показав стабильное уменьшение лосса с ростом популяции вплоть до 262,144 агентов. Стандартным бэкпропом сделать это невозможно.

**Сравнение RL:** [График сравнения с Reinforcement Learning](../../../media/img_1764033927_aqadmwtrgw9rkel_figure_4_comparison_of_reinforcement_lea.jpg)

**Описание:** На изображении представлено сравнение производительности EGGROLL с другими методами обучения с подкреплением на различных задачах.

**Сравнение валидации:** [График сравнения валидационной точности](../../../media/img_1764033927_aqadnatrgw9rkel_figure_5_comparison_of_the_validation.jpg)

**Описание:** На изображении показано сравнение валидационной точности различных методов, демонстрирующее превосходство EGGROLL над GRPO в задаче файнтьюнинга LLM.

**Сравнение скорости:** [График относительной скорости EGGROLL](../../../media/img_1764033927_aqadoqtrgw9rkel9_figure_6_relative_speed_of_eggroll.jpg)

**Описание:** На изображении представлен график, показывающий относительную скорость выполнения EGGROLL по сравнению с другими методами.

## Сравнение с другими подходами

### EGGROLL vs. Full-rank ES
- **Память**: O(r(m+n)) vs O(mn) - значительное улучшение для крупных моделей
- **Скорость**: Возможность обучения на кластерах с почти линейным масштабированием
- **Применимость**: Расширение области применения на недифференцируемые системы

### EGGROLL vs. Backpropagation
- **Требования к дифференцируемости**: EGGROLL не требует дифференцируемости, backpropagation - требует
- **Потребление памяти**: EGGROLL значительно более экономичен
- **Применимость**: EGGROLL может работать с более широким классом задач

### EGGROLL vs. LoRA
- **Цель**: EGGROLL - масштабирование эволюционных стратегий, LoRA - параметрически эффективное fine-tuning
- **Механизм**: Оба используют низкоранговые приближения, но в разных контекстах
- **Применение**: EGGROLL - оптимизация в процессе обучения, LoRA - адаптация обученной модели

## Историческая эволюция

### Истоки
- Эволюционные стратегии (Rechenberg, Schwefel, 1960-е годы)
- SPSA (Spall, 1987) - Simultaneous Perturbation Stochastic Approximation
- Современные подходы к эволюционным стратегиям в контексте нейронных сетей (Salimans et al., 2017)

### Развитие до EGGROLL
- Исследования внутренней размерности (intrinsic dimensionality) LLM
- Работы по эффективному применению ES к LLM (как описано в [[ai/llm/evolution_strategies_optimization.md]])
- Прорывной подход EGGROLL к масштабированию через низкоранговые приближения

## Будущие направления

### Теоретические аспекты
- Глубокое понимание связи между низкоранговыми приближениями и естественными градиентами
- Оптимальный выбор ранга r в зависимости от задачи и архитектуры модели

### Практические применения
- Интеграция с системами слияния моделей (model merging)
- Применение в системах искусственных иммунных систем для принятия решений
- Использование в агентных системах для оптимизации стратегий

## Сравнение с другими методами оптимизации

### Отношение к генетическим алгоритмам
- EGGROLL сохраняет идею популяционной оптимизации
- Вместо кроссовера используется низкоранговое возмущение параметров
- Более подходит для непрерывных пространств параметров нейронных сетей

### Отношение к дифференциальной эволюции
- Обе методы относятся к классу эволюционных стратегий
- EGGROLL использует конкретный подход к генерации потомства через низкоранговые возмущения
- Дифференциальная эволюция использует комбинации существующих решений

## Источники

1. [Evolution Strategies at the Hyperscale](https://arxiv.org/abs/2511.16652) - оригинальная статья о методе EGGROLL
2. [SPSA Simultaneous Perturbation Stochastic Approximation](https://www.jhuapl.edu/SPSA) - оригинальная работа по SPSA
3. [Simple random search provides a competitive approach to reinforcement learning](https://arxiv.org/abs/1803.07055) - работа, демонстрирующая эффективность градиент-свободных методов
4. [Deep Evolution Strategies](https://arxiv.org/abs/1703.03864) - ранние работы по применению ES к глубокому обучению

## См. также

- [[ai/llm/eggroll_method.md]] - Подробное описание метода EGGROLL
- [[ai/llm/evolution_strategies_optimization.md]] - Общее применение эволюционных стратегий к LLM
- [[ai/optimization/evolutionary_algorithms.md]] - Общая информация об эволюционных алгоритмах
- [[ai/llm/lora_optimization.md]] - Low-Rank Adaptation, использующий схожие идеи низкоранговых приближений
- [[ai/continual_learning/plasticity/continual_backpropagation.md]] - Метод, сравниваемый с EGGROLL по требованиям к дифференцируемости и подходам к обучению
- [[ai/llm/group_relative_policy_optimization.md]] - Метод, с которым сравнивается EGGROLL в экспериментах (GRPO)