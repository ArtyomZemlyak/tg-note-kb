# Детерминированный инференс в LLM

## Определение

Детерминированный инференс в больших языковых моделях (LLM) - это подход, обеспечивающий воспроизводимость выходных данных модели при одинаковых входных данных и параметрах. То есть, при запуске одной и той же задачи с одинаковыми параметрами, модель будет выдавать одинаковые результаты каждый раз.

## Почему это важно

### Для обучения с подкреплением (RL)
- Обеспечивает стабильные logprobs при разных запусках
- Уменьшает стохастический шум
- Делает тренировку RL более стабильной, воспроизводимой и поддающейся отладке

### Для тестирования и отладки
- Позволяет точно воспроизводить результаты
- Упрощает отладку и идентификацию проблем
- Обеспечивает надежную оценку изменений

### Для продуктового использования
- Повышает надежность систем
- Улучшает пользовательский опыт
- Упрощает логирование и аудит

### Для регулируемых отраслей
- Обеспечивает воспроизводимость результатов для соответствия требованиям
- Упрощает аудит и проверку результатов
- Критично для финансовых и медицинских приложений

## Причины недетерминированности в стандартном инференсе

### Проблема масштабирования
Согласно исследованию IBM ([LLM Output Drift: Cross-Provider Validation & Mitigation for Deterministic AI](https://arxiv.org/abs/2511.07585)), основные источники нестабильности находятся в порядке убывания значимости:

1. **Порядок извлечения документов**: В системах RAG (Retrieval-Augmented Generation) порядок извлечения влияет на контекст и, соответственно, на вывод модели
2. **Процесс выборки токенов**: Даже при температуре 0 могут возникать численные различия в вычислениях
3. **Вариации в реализации**: Различия в GPU-вычислениях, особенно в операциях редукции

### Влияние размера модели
Исследование IBM показало, что **увеличение параметров модели не всегда приводит к более стабильному поведению**:
- Модели 7B и 8B показали **100% стабильность** при температуре 0
- Модель 120B совпадала только в **12.5% случаев** даже при температуре 0
- Поведение зависит от архитектуры и реализации модели

### Размер батча
Основной причиной недетерминированности является изменяющийся размер батча. Разные размеры батча вызывают различное разделение GPU-ядрами операций редукции, что приводит к различным порядкам сложения. Из-за неассоциативности чисел с плавающей запятой ((a + b) + c ≠ a + (b + c)) получаются разные результаты даже при одинаковых входах.

## Технические решения

### Методы, предложенные IBM
- **Фиксация температуры на 0**: Полное отключение случайности при выборе токенов
- **Greedy decoding**: Принудительное использование жадной стратегии выборки
- **Фиксированный seed**: Обеспечение воспроизводимости процессов
- **Строгий порядок извлечения документов**: Использование фиксированного порядка параграфов SEC 10K
- **Проверочные схемы**: Дополнительные схемы проверки для JSON и SQL
- **Числовые допуски**: Числовые ответы считались корректными при отклонении не более 5%

### Batch-invariant операторы
Решение, реализованное в таких системах как SGLang, заключается в использовании batch-invariant операторов, которые обеспечивают одинаковый результат независимо от размера батча.

### Поддержка различных бэкендов
Для детерминированного инференса требуются специальные бэкенды внимания, такие как:
- FlashInfer
- FlashAttention 3 (FA3)
- Triton

## Влияние температуры на стабильность

### При температуре 0.2
Согласно исследованию IBM:
- Задачи с RAG (Retrieval-Augmented Generation) **теряли стабильность**
- SQL-запросы и короткие сводки оставались **стопроцентно одинаковыми**
- Это показывает, что структурированный вывод стабилен по природе, а свободный текст остается чувствительным к любым флуктуациям

## Применение в фреймворках

### SGLang
Один из первых фреймворков, который реализовал детерминированный инференс с поддержкой:
- Chunked prefill
- CUDA графов
- Radix cache
- Нежадной выборки (даже при температуре > 0)

## Структурированный vs. неструктурированный вывод

- **Структурированный вывод** (SQL-запросы, JSON-ответы) показывает **естественную стабильность**
- **Неструктурированный вывод** (свободный текст) остается **чувствительным к любым флуктуациям**
- Это различие важно при выборе подходящей модели для конкретной задачи

## Практические рекомендации

### Для критических систем
- Использовать модели 7B и 8B для всех задач в регулируемых областях
- Устанавливать температуру 0 для детерминированного поведения
- Использовать фиксированный порядок извлечения
- Применять версионированные промпты
- Осуществлять двойную валидацию перед продакшн-запуском

### Для финансовых приложений
- Температура 0 для минимизации вариаций
- Фиксированный порядок извлечения
- Версионированные промпты
- Двойная валидация перед запуском в продакшн

## Связь с другими темами

- [[tools/sglang.md]] - SGLang, один из первых фреймворков с детерминированным инференсом
- [[tools/slime.md]] - SLiME, использует SGLang для RL-тренировки с детерминированным выводом
- [[../../reinforcement_learning/ppo_algorithm.md]] - PPO, алгоритм обучения с подкреплением, который может выиграть от детерминированного инференса
- [[../../reinforcement_learning/deep_rl/deep_rl_algorithms.md]] - Описание DDPG (Deep Deterministic Policy Gradient), где "детерминистичность" также важна, но в другом контексте
- [[../../reinforcement_learning/survey_rl_comprehensive.md]] - Обзор RL с упоминанием детерминистских подходов
- [[research/ibm_determinism_study.md]] - Исследование IBM о детерминизме в LLM
- [[scaling/determinism_scaling.md]] - Влияние размера модели на стабильность вывода
- [[../hallucination_detection/hallucinations_in_llm.md]] - Связь с проблемой галлюцинаций и предсказуемости LLM

## Источники

1. [LLM Output Drift: Cross-Provider Validation & Mitigation for Deterministic AI](https://arxiv.org/abs/2511.07585) - Исследование IBM о детерминизме вывода LLM, опубликованное на arXiv, содержащее результаты экспериментов с различными моделями и подходами к обеспечению стабильности вывода