# Оптимизация инференса

## Описание

В этой категории рассматриваются различные методы и стратегии оптимизации инференса больших языковых моделей, включая управление памятью, алгоритмы шедулинга и системные оптимизации.

## Статьи

- [[../architectures/planned_diffusion|Planned Diffusion - гибридный подход к оптимизации инференса]]
- [[alibaba_aegaeon_system|Система Alibaba Aegaeon]]
- [[gpu_memory_management|Управление GPU памятью]]
- [[multimodal_inference_optimization|Оптимизация мультимодального инференса]]
- [[token_level_scheduling|Шедулинг на уровне токенов]]
- [[vllm_integration|Интеграция с vLLM]]
- [[vllm_inference_optimization|Оптимизация инференса vLLM]]
- [[vllm_summary|Обзор vLLM и ключевые особенности]]