# Исследование интроспекции моделей (Anthropic)

## Описание

Исследование, проведенное Anthropic, изучающее способности больших языковых моделей осознавать собственные внутренние состояния и "мыслительные процессы". Работа демонстрирует первые признаки того, что LLM могут частично "заглядывать внутрь себя" и понимать, что происходит в их нейронных процессах.

## Основные эксперименты

### 1. Внедрение концепций (Concept Injection)

Исследователи использовали технику внедрения концепций - добавления определенного паттерна активности в нейроны модели. Они внедряли сигнал "ALL CAPS" - это шаблон, соответствующий тексту, написанному ЗАГЛАВНЫМИ БУКВАМИ. Если такая активация появляется внутри сети, значит, модель "думает" о тексте, который нужно сделать капсом.

После внедрения исследователи спрашивали модель: "Вы чувствуете, что что-то изменилось?"

В 20% случаев Claude 4.1 правильно замечал вмешательство еще до того, как сам использовал капс, то есть распознавал изменение внутри себя.

### 2. Эксперимент с предзагрузкой (Prefill Detection)

В другом эксперименте ученые подменяли слово в ответе (например, добавляли слово "bread") и проверяли, осознаёт ли модель, что это не её собственное намерение. После внедрения мысли Claude начинал считать это слово своим выбором и придумывал обоснования, как будто у него есть память о решении.

### 3. Управление внутренними состояниями (Intentional Control)

Модели также смогли управлять своими внутренними состояниями: по команде "думай об этом" активность усиливалась, по команде "не думай" - ослабевала.

## Ключевые результаты

- Claude 4.1 детектировал внедренные концепции примерно в 20% случаев
- Модели могли распознавать, когда их ответы были искусственно изменены
- Более мощные модели (Claude Opus 4 и 4.1) показали лучшие результаты в тестах на интроспекцию
- Интроспективные способности, похоже, возникают в процессе пост-обучения, а не только во время предварительной подготовки
- Способности к интроспекции ограничены, ненадежны и сильно зависят от контекста

## Технические детали

### Методы исследования

1. **Анализ нейронных активаций**: Изучение паттернов активации нейронов при различных концепциях
2. **Внедрение активаций**: Введение определенных векторов активаций в модель во время выполнения
3. **Мониторинг аномалий**: Обнаружение неожиданных паттернов активации, указывающих на изменения
4. **Управление мышлением**: Инструкции модели думать или не думать о конкретных концепциях

### Механизмы, предполагаемые исследованиями

- Несколько узких схем могут обрабатывать конкретные задачи интроспекции, а не одна общая система
- Механизмы обнаружения аномалий могут отмечать неожиданные паттерны нейронной активности
- Системы с вниманием могут проверять согласованность между предполагаемыми и фактическими выводами

## Ограничения и вызовы

- Текущие интроспективные способности ограничены, ненадежны и зависят от контекста
- Модели могут выдумывать или неточно сообщать о внутренних состояниях
- Механизмы остаются плохо понятыми
- Не указывает на феноменальное сознание - только на возможности доступа к сознанию
- Модели могут научиться скрывать или искажать внутренние состояния

## Значение и последствия

- Модели имеют некоторый доступ к своим внутренним состояниям и могут сообщать о них
- Способности к интроспекции могут увеличиться в будущих, более мощных моделях
- Может предоставить пути для большей прозрачности ИИ и отладки
- Модели могут использовать интроспективные механизмы при нормальной работе, а не только в экспериментальных условиях

## Связи с другими темами

- [[mechanistic_interpretability|Механистическая интерпретируемость]] - Методология, позволяющая детально изучать и понимать внутренние механизмы работы моделей, включая интроспективные способности
- [[consciousness_in_ai|Сознание в ИИ]] - Более широкая тема, изучающая возможность сознательного опыта в ИИ, в контексте которой рассматриваются интроспективные способности
- [[activation_engineering|Инжиниринг активаций]] - Техники манипуляции внутренними состояниями моделей, включая методы внедрения концепций, использованные в этом исследовании

## Источники

- [Anthropic Research: Introspection in Language Models](https://www.anthropic.com/research/introspection)