# Low-Rank Adaptation (LoRA) для оптимизации LLM

## Описание

Low-Rank Adaptation (LoRA) - это метод параметрически эффективного обучения, при котором обучаемые адаптеры имеют низкий ранг, что значительно уменьшает количество параметров, требующих обновления. LoRA позволяет адаптировать большие языковые модели к специфическим задачам, обновляя только небольшую часть параметров.

## Принцип работы

1. **Идея низкоранговой адаптации**: Вместо обновления всех параметров модели, LoRA обучает два низкоранговых матричных фактора, которые при добавлении к весам модели обеспечивают изменение поведения модели.

2. **Математическое представление**: Для весовой матрицы W, LoRA обучает ∆W = BA, где B и A - низкоранговые матрицы, и rank(∆W) << rank(W).

3. **Эффективность**: Поскольку нужно обучать только параметры матриц A и B, а не всей матрицы W, количество обучаемых параметров значительно уменьшается.

## Связь с внутренней размерностью

LoRA тесно связан с концепцией внутренней размерности (intrinsic dimensionality) LLM:

- Внутренняя размерность объясняет, почему модели с миллиардами параметров можно эффективно дообучать в пространствах гораздо меньшей размерности
- LoRA реализует эту концепцию на практике, ограничивая пространство параметров, в котором происходит обучение
- Малая внутренняя размерность объясняет высокую эффективность LoRA

## Преимущества

- **Память-эффективность**: Снижение объема памяти, необходимого для обучения
- **Вычислительная эффективность**: Уменьшение количества параметров, требующих обновления
- **Меньше переобучения**: Благодаря ограниченному пространству параметров риск переобучения снижен
- **Совместимость**: Можно иметь несколько LoRA-адаптаций для одной базовой модели
- **Качество**: Часто достигается качество, сопоставимое с полным fine-tuning

## Применения

- **Адаптация к домену**: Адаптация общей модели к специфическому домену
- **Индивидуальная настройка**: Персонализация моделей для конкретных пользователей или задач
- **Эксперименты с новыми функциями**: Быстрая проверка новых возможностей без изменения базовой модели
- **Совместное обучение**: Обучение нескольких задач на одной базовой модели
- **Обучение дистиллированных моделей**: Использование специальных адаптеров (например, Z-Image-Turbo Training Adapter) для обучения дистиллированных моделей без разрушения их основных характеристик

## Сравнение с другими методами

- **Полный fine-tuning**: Обновляет все параметры, требует больше ресурсов
- **Адаптеры**: Обучает небольшие вставки в модель, схожая эффективность
- **Prompt-tuning**: Обновляет только обучаемый промпт, LoRA более гибкий
- **P-tuning**: Обновляет только токены промпта, LoRA изменяет параметры модели

## Сравнение с другими методами

- **Полный fine-tuning**: Обновляет все параметры, требует больше ресурсов
- **Адаптеры**: Обучает небольшие вставки в модель, схожая эффективность
- **Prompt-tuning**: Обновляет только обучаемый промпт, LoRA более гибкий
- **P-tuning**: Обновляет только токены промпта, LoRA изменяет параметры модели

## Сравнение с EGGROLL

Оба метода используют низкоранговые приближения, но для разных целей:
- **LoRA**: снижение количества обучаемых параметров в процессе fine-tuning
- **EGGROLL**: снижение вычислительных и памятевых затрат в эволюционных стратегиях

## Связи с другими темами

- [[ai/llm/eggroll_method.md]] - EGGROLL использует схожую концепцию низкоранговой факторизации, но в контексте эволюционных стратегий для гипермасштабных моделей
- [[ai/llm/intrinsic_dimensionality.md]] - Концепция внутренней размерности, объясняющая эффективность LoRA
- [[ai/optimization/memory_efficient_training.md]] - Общие методы память-эффективного обучения
- [[ai/llm/google_data_quality_assessment_methodology.md]] - Методология Google, подтверждающая, что LoRA основано на принципе эффективности небольших наборов высококачественных данных
- [[ai/llm/evolution_strategies_optimization.md]] - Альтернативный подход к оптимизации LLM с использованием эволюционных стратегий
- [[ai/llm/rlhf.md]] - Другие методы адаптации LLM к специфическим задачам
- [[ai/llm/optimization/smol_training_playbook.md]] - Руководство, описывающее LoRA как одну из ключевых техник параметрически эффективного обучения
- [[ai/llm/optimization/techniques_for_small_models.md]] - Детальное описание применения LoRA в обучении небольших моделей
- [[ai/tools/ai_toolkit_by_ostris.md]] - Инструмент AI Toolkit, поддерживающий LoRA обучение для диффузионных моделей, включая Z-Image Turbo
- [[ai/computer_vision/z_image_turbo.md]] - Пример применения LoRA для диффузионной модели изображений Z-Image Turbo