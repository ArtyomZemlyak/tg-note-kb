# The Markovian Thinker: Революция в обучении LLM

## Общее описание

The Markovian Thinker представляет собой новую парадигму для рассуждений в больших языковых моделях (LLM), решая фундаментальную проблему, связанную с ростом вычислительных затрат при обучении с подкреплением (RL) для задач рассуждения. Традиционные методы имеют квадратичную сложность, поскольку размер состояния (промпт + все токены рассуждения) постоянно растет.

## Основная концепция: "Марковское мышление"

- **Проблема**: В традиционном RL для LLM состояние (пространство) продолжает расти по мере генерации токенов рассуждения
- **Решение**: Парадигма "Марковского мышления", где размер состояния ограничен/фиксирован
- **Результат**: Вычислительная стоимость становится линейной, а использование памяти - постоянным

## Метод Delethink

Delethink - это реализация парадигмы "Марковского мышления":

- **Порционная генерация**: Генерация происходит фиксированными блоками
- **Сброс контекста**: На каждой границе контекст сбрасывается до свежего промпта с исходным вопросом плюс короткий перенос
- **Механизм обучения**: Модель учится продвигать прогресс в тексте, становясь "Марковским мыслителем"

### Сравнение с LongCoT:
- **LongCoT**: Продолжает конкатенировать токены, поэтому контекст постоянно растет
- **Delethink**: Поддерживает фиксированный активный контекст при обработке длинного рассуждения

## Преимущества

1. **Вычислительная эффективность**: Линейная стоимость вычислений вместо квадратичной
2. **Оптимизация памяти**: Постоянное использование памяти независимо от длины рассуждения
3. **Масштабируемость**: Может обрабатывать гораздо более длинные цепочки рассуждений (до 128K токенов)
4. **Производительность**: Соответствует или превосходит точность LongCoT-RL с лучшей эффективностью
5. **Продолжающееся улучшение**: При превышении бюджета обучения продолжает улучшаться, в то время как другие модели стагнируют

## Технические детали

### Архитектура:
- Построена поверх кодовых баз **verl** и **SGLang**
- Использует порционную обработку с механизмом сброса контекста
- Фиксированный размер контекста (C) с механизмом переноса (m) и ограничением итераций (I)

### Масштабирование до 96K токенов:
- Успешно масштабирован Delethink до обработки до 96K токенов (и далее до 128K)
- Сохраняет линейное масштабирование вычислений при обработке очень длинных цепочек рассуждений

### Доступные модели:
- `delethink-24k-1.5b`
- `delethink-96k-1.5b`
- `longcot-24k-1.5b`
- `longcot-8k-1.5b`

## Применение

### Анализ GPT-OSS и Qwen3:
- Современные LLM GPT-OSS-120B и Qwen3-30B-A3B показывают сильные признаки "Марковского мышления" без специальной настройки
- Обеспечивает сильную инициализацию для обучения
- Delethink близко отслеживает LongCoT и восстанавливает большую часть его финальной точности
- Доказательства потенциала масштабируемости для будущих приложений

### Результаты оценки:
- Продемонстрирована эффективность на задачах математического рассуждения с использованием наборов данных DeepScaleR и OpenMath
- Успешно воспроизведены эксперименты по обучению с подкреплением с конфигурациями как 24K, так и 96K токенов

## Ключевые выводы

1. **Новая парадигма**: Вводит парадигму "Марковского мышления", где модели учатся продвигать рассуждения, опираясь только на состояния фиксированного размера
2. **Практическая польза**: Простой и эффективный подход - с 8K фиксированным состоянием соответствует или превосходит LongCoT-RL и может рассуждать до 128K токенов
3. **Реальные доказательства**: Ведущие модели (GPT-OSS 120B, Qwen3 30B-A3B) уже показывают сильные признаки "Марковского мышления"
4. **Масштабируемость**: Демонстрирует потенциал для масштабирования до очень длинных цепочек рассуждений с управляемыми вычислительными затратами

## Источники и ссылки

- GitHub: [https://github.com/McGill-NLP/the-markovian-thinker](https://github.com/McGill-NLP/the-markovian-thinker)