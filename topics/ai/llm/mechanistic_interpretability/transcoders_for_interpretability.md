# Транскодеры для интерпретируемости (Transcoders for Interpretability)

## Краткое описание

Транскодеры - это модифицированные разреженные автоэнкодеры, используемые для анализа и интерпретации внутренних представлений трансформеров. Они заменяют стандартные компоненты (например, MLP-модули) в больших языковых моделях, чтобы обеспечить более интерпретируемое представление внутренних вычислений. Транскодеры играют ключевую роль в методах, таких как Circuit-based Reasoning Verification (CRV), где интерпретируемость необходима для анализа причинно-следственных связей в рассуждениях.

## Основная информация

### Основные концепции

1. **Транскодер (Transcoder)**: Вариант разреженного автоэнкодера (SAE), обученный аппроксимировать функцию вход-выход целевого компонента (например, MLP) в интерпретируемом, разреженно активированном базисе.

2. **Разреженные автоэнкодеры (Sparse Autoencoders, SAE)**: Архитектуры, обученные реконструировать вектор активации x ∈ ℝ^d из гораздо более высокомерного, но в основном нулевого, вектора признаков f ∈ ℝ^D, где D >> d.

3. **Интерпретируемые признаки (Interpretable features)**: Элементы разреженного вектора признаков, которые активируются спарсно и соответствуют понятным человеку концепциям.

4. **Топ-K активация (TopK activation)**: Функция активации, которая обеспечивает разреженность, сохраняя только k самых больших активаций признаков.

5. **Функциональная замена (Functional substitute)**: Концепция, согласно которой транскодер действует как истинная функциональная замена оригинального модуля, обучаясь эмулировать вычислительный шаг в интерпретируемом базисе.

### Архитектура и методология

Архитектура транскодеров включает:

1. **Обучение на данных активаций**: Транскодер обучается на большом разнообразном наборе данных активаций, собранных из оригинальной LLM.

2. **Объектив функции**: Комбинация L2-потерь реконструкции с TopK-функцией активации, которая обеспечивает разреженность.

3. **Замена оригинальных модулей**: После обучения MLP-модуль каждого слоя в LLM заменяется соответствующим транскодером.

4. **Интерпретируемость**: Вычислительный проход модели теперь вынужден идти через эти разреженные, интерпретируемые "бутылочные горлышки".

5. **Анализ признаков**: Возможность анализа и манипуляции отдельными интерпретируемыми признаками для понимания и коррекции поведения модели.

### Отличия от существующих подходов

В отличие от:

- **Стандартных активаций**: Которые являются плотными и неинтерпретируемыми
- **Простых проб**: Которые не заменяют внутренние вычисления, а только анализируют их
- **Традиционных SAE**: Которые обучены реконструировать собственный вход (f(x) ≈ x), в отличие от транскодеров, обученных аппроксимировать функцию вход-выход целевого компонента (f(x) ≈ MLP(x))

Транскодеры:
- Обеспечивают функциональную замену оригинальных модулей
- Делают внутренние вычисления интерпретируемыми
- Позволяют целевые интервенции в конкретные признаки

## Новые концепции и термины

- **Функциональная эмуляция (Functional emulation)**: Процесс, при котором транскодер эмулирует вычислительный шаг оригинального модуля в интерпретируемом базисе.
- **Разреженные активации (Sparse activations)**: Представления с большинством нулевых значений, где только небольшое подмножество признаков активировано в любой момент.
- **Интерпретируемое замещение (Interpretable substitute)**: Модель или модуль, который функционально заменяет оригинальный компонент, но делает вычисления более понятными.
- **Признаковый базис (Feature basis)**: Набор интерпретируемых признаков, через которые выражаются внутренние вычисления.
- **Вынужденные вычисления (Forced computations)**: Процесс, при котором вычисления модели вынуждены проходить через разреженные, интерпретируемые представления.

## Примеры применения

- **Анализ рассуждений LLM**: Использование транскодеров для изучения внутренних вычислений в процессе Chain-of-Thought рассуждений
- **Целевые интервенции**: Вмешательство в конкретные признаки для коррекции ошибочного поведения модели
- **Верификация рассуждений**: Использование транскодеров как основы для методов, таких как CRV
- **Интерпретация механизмов ошибок**: Понимание того, какие конкретные признаки приводят к ошибкам

## Связи с другими темами

[[ai/llm/reasoning/circuit_based_reasoning_verification.md]] - Использование транскодеров в методе CRV для верификации рассуждений
[[ai/llm/mechanistic_interpretability.md]] - Общий контекст механистической интерпретируемости
[[ai/llm/reasoning/attribution_graphs_interpretability.md]] - Атрибуционные графы, построенные на основе транскодеров
[[ai/llm/activation_engineering.md]] - Методы инженерии активаций и их интерпретации
[[ai/llm/models/sparse_attention_mechanisms.md]] - Другие методы разреженности в архитектурах LLM

## Ссылки на источники

- Оригинальная работа по Circuit-based Reasoning Verification (CRV)
- Исследования по транскодерам Dunefsky et al. (2025)
- Исследования по разреженным автоэнкодерам Cunningham et al. (2023)
- Работы по механистической интерпретируемости трансформеров