# Мобильные LLM: Развитие компактных языковых моделей для автономной работы

## Краткое описание
Обзор и анализ развития компактных языковых моделей, оптимизированных для работы на устройствах (on-device), включая архитектуру MobileLLM-Pro.

## Основная информация

### MobileLLM-Pro
MobileLLM-Pro - мощная компактная языковая модель (~1 млрд параметров) для работы на устройствах:
- Превосходит Gemma 3 1B и Llama 3.2 1B в задачах рассуждения, знаний и работы с длинным контекстом
- Поддерживает длину контекста до 128 000 токенов
- Использует гибридное внимание (локальное + глобальное в соотношении 3:1, окно 512)
- Обеспечивает низкую задержку и экономию KV-памяти

### Архитектурные особенности
- **Гибридное внимание**: Сочетание локального и глобального внимания для баланса между производительностью и эффективностью
- **Оптимизация KV-кэша**: Экономия памяти при сохранении способности работать с длинным контекстом
- **Компактность**: Малое количество параметров позволяет работать на устройствах с ограниченными ресурсами

### Преимущества on-device моделей
- **Конфиденциальность**: Обработка данных происходит на устройстве без передачи в облако
- **Надежность**: Не зависит от подключения к интернету
- **Задержка**: Быстрый отклик без необходимости взаимодействия с сервером
- **Экономичность**: Меньше затрат на облачные вычисления

## Новые концепции и термины
- **On-device ML** - машинное обучение, выполняемое непосредственно на пользовательских устройствах
- **KV-память** - ключ-значение память, используемая в механизмах внимания трансформеров
- **Гибридное внимание** - комбинация локального и глобального механизмов внимания

## Примеры применения
- Чат-боты, работающие автономно на смартфонах
- Локальный ассистент с высокой степенью приватности
- Приложения, требующие работы в условиях ограниченного подключения к интернету
- IoT-устройства с ИИ-функциями

## Связи с другими темами
- [[ai/llm/models/laser_reinforcement_learning.md]] - Оптимизация моделей для различных задач
- [[ai/machine_learning/machine_learning.md]] - Общие принципы машинного обучения
- [[ai/llm/llm_memory_systems/llm_compression.md]] - Компрессия и оптимизация LLM

## Ссылки на источники
- Исследование MobileLLM-Pro от FacebookResearch
- Документация по оптимизации LLM для мобильных устройств