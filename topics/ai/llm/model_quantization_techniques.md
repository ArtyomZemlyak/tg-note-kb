# Техники квантования моделей

## Общее описание

Квантование моделей - это техника уменьшения точности весов и активаций нейронных сетей с целью уменьшения требований к памяти и ускорения инференса, при сохранении приемлемой точности модели.

## Основные методы квантования

### INT8 и INT4
- Квантование целых чисел с 8 или 4 битами
- Значительное уменьшение требований к памяти
- Ускорение вычислений за счёт целочисленных операций
- Широко используется в производственных системах

### FP8 (Float8)
- 8-битное квантование с плавающей запятой
- Баланс между точностью и эффективностью
- Включает форматы E4M3 и E5M2
- Поддерживается современными GPU (Hopper, Ada Lovelace и др.)

### GPTQ (GPU-aware Post-Training Quantization)
- Метод пост-обучения квантования
- Оптимизирован для GPU-ускорения
- Требует калибровочный датасет
- Позволяет квантовать модели до 4 бит без значительной потери точности

### AWQ (Activation-aware Weight Quantization)
- Учитывает важность активаций при квантовании весов
- Устойчив к "outliers" в весах
- Сохраняет важные веса в полной точности
- Требует калибровочный датасет

### AutoRound
- Автоматизированный метод для INT4 квантования
- Не требует специальных калибровочных данных
- Эффективен для распределённых вычислений
- Оптимизирует квантования с учётом округлений

## Применение в vLLM

vLLM поддерживает несколько методов квантования:
- GPTQ для 4-битного квантования
- AWQ для вес-зависимого квантования
- AutoRound для автоматического квантования
- INT4, INT8 и FP8 квантования

## Применение и выбор метода

- **Для максимальной экономии памяти**: INT4 или GPTQ
- **Для минимальной потери точности**: FP8
- **Для простой реализации**: INT8
- **Для оптимизированного квантования**: AWQ или AutoRound

## Преимущества

- Уменьшение требований к памяти
- Ускорение инференса за счёт целочисленных операций
- Возможность запуска больших моделей на ограниченных устройствах
- Снижение энергопотребления

## Ограничения и вызовы

- Потенциальная потеря точности модели
- Необходимость калибровки для некоторых методов
- Сложность в квантовании специфичных архитектур
- Необходимость поддержки на уровне аппаратуры

## Связи с другими темами

- [[gpu_memory_management.md]] - Влияние квантования на использование GPU-памяти
- [[model_compression.md]] - Другие методы сжатия моделей
- [[vllm_integration.md]] - Поддержка квантования в vLLM
- [[hardware_acceleration.md]] - Аппаратная поддержка квантования
- [[post_training_optimization.md]] - Пост-обучение оптимизации

## Источники

- Исследования по различным методам квантования
- Документация по квантующим библиотекам (GPTQ-for-LLaMa, AutoGPTQ, etc.)
- Публикации о FP8 и современных форматах
- Практики использования квантования в производственных системах