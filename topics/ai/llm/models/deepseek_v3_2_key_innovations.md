# DeepSeek-V3.2: Обзор ключевых инноваций

## Общее описание

DeepSeek-V3.2 представляет собой значительный шаг вперед в архитектуре больших языковых моделей, включающий несколько ключевых инноваций в области эффективности вычислений, архитектуры внимания и стабилизации обучения с подкреплением. Модель достигает баланса между высокой вычислительной эффективностью и превосходной способностью к рассуждению и агентным задачам.

## Ключевые технические инновации

### 1. DeepSeek Sparse Attention (DSA) с top-K селектором

![Архитектура внимания DeepSeek-V3.2 с DSA](../../../../media/img_1764931113_aqadcxbrg1gfkel_figure_2_attention_architecture_of.jpg)

Основное усиление заключается в применении DeepSeek Sparse Attention с top-K селектором, что позволяет:

- **Снижение сложности**: с O(n²) до O(n*<w>), где <w> - средний размер адаптивного окна
- **Lightning Indexer**: легковесная сеть для вычисления индексных оценок
- **Fine-grained token selection**: динамический выбор релевантных токенов для внимания
- **Global и sliding window части**: комбинация глобального и локального внимания с top-K селектором

DSA с top-K селектором усиливает traditional DSA за счет специального механизма "выбора", который определяет, на какие токены должна обращать внимание global часть. Зеленый селектор на рисунках показывает, как он размещается на KV для роутинга, позволяя w (размер окна) уменьшаться от слайда к слайду.

### 2. Усиленная Multi Latent Head Attention (MLA) с top-K селектором в латентах

![Регулярное каузальное самовнимание с маской](../../../../media/img_1764931113_aqadhxbrg1gfkel9_regular_causal_self_attention_mask_deeps.jpg)

Вторая ключевая инновация - усиление MLA, при котором:

- **Сжатие QKV**: тензоры сжимаются в пространство меньшей размерности в X раз
- **RoPE в латентах**: механизм Rotational Positional Embedding применен к сжатым латентным представлениям
- **Top-K селектор в латентах**: выбор наиболее релевантных латентных векторов
- **Дополнительное ускорение**: за счет интеграции DSA с top-K селектором прямо в латентные представления

Вместо старого DSA, в DeepSeek-V3.2 интегрирован DSA с top-K селектором прямов в латенты, что еще больше ускоряет модель.

### 3. Улучшенная стабилизация обучения с подкреплением

#### Unbiased KL Estimate

![Расположение синков внимания в конце](../../../../media/img_1764931113_aqadxjrgwtqkul_sink_location_at_the_end.jpg)

Наиболее важное улучшение в RL касается оценки дивергенции KL в алгоритме GRPO:

- **Проблема**: В оригинальном GRPO KL-регуляризация оценивалась с систематической ошибкой
- **Градиентный взрыв**: Когда токены имели значительно более низкую вероятность под текущей политикой πθ, по сравнению со старой, политикой πold, градиент оригинального лосса назначал непропорционально большие веса
- **Последствия**: шумные градиентные обновления, нестабильная динамика обучения, деградация качества сэмплов
- **Решение**: "Unbiased KL Estimate" - исправление, заключающееся в перевзвешивании KL-члена с тем же самым коэффициентом важности (importance ratio), что и используется для основной функции потерь

#### Дополнительные методы стабилизации

- **Off-Policy Sequence Masking**: маскировка последовательностей, которые отклоняются от исходной модели больше порога
- **Keep Routing**: сохранение маршрутов экспертов при обучении MoE моделей
- **Keep Sampling Mask**: сохранение масок топ-p/топ-k семплирования для согласования пространств действий

## Технические детали архитектуры

### Сравнение с предыдущими версиями

| Характеристика | DeepSeek V3.1 | DeepSeek V3.2 |
|----------------|---------------|---------------|
| Механизм внимания | MLA с GQA | MLA усилена DSA с top-K в латентах |
| Сложность внимания | O(n²) | O(n*<w>) где <w> << n |
| Стабильность RL | Базовый GRPO | GRPO + Unbiased KL Estimate |
| Обработка длинного контекста | Ограничена | Значительно улучшена |

### Детали DSA с top-K селектором

Lightning Indexer вычисляет индексную оценку I_t,s между токеном запроса h_t ∈ R^d и предыдущим токеном h_s ∈ R^d:

I_t,s = Σ_j ReLU(q_I_t,j * k_I_s,j + w_I_t,j)

где H_I - количество indexer голов, q_I_t,j ∈ R^d_I, w_I_t,j ∈ R - производные от токена запроса h_t, k_I_s ∈ R^d_I - производная от предыдущего токена h_s.

Fine-grained token selection retrieves only the key-value entries {c_s} corresponding to the top-k индексные оценки, и attention output u_t вычисляется путем применения attention mechanism между токеном запроса h_t и разреженно выбранными key-value entries {c_s}.

## Влияние на производительность

### Вычислительная эффективность

- **Значительное ускорение** end-to-end в сценариях длинного контекста
- **Снижение использования памяти** для KV-кеширования
- **Более эффективное использование вычислительных ресурсов**
- **Возможность обработки очень длинных последовательностей** за разумное время

### Качество модели

- **Сохранение уровня точности** и производительности
- **Улучшенная масштабируемость** для длинных контекстов
- **Высокая способность к рассуждению** и агентным задачам
- **Достижение уровня топ-систем** при значительно меньших вычислительных затратах

## Применения и результаты

DeepSeek-V3.2 демонстрирует выдающиеся результаты на различных бенчмарках:
- Сравнимый уровень с GPT-5 и превосходство над Gemini 3.0 Pro в математике и коде
- Золотые медали на IMO и IOI 2025
- Превосходство в задачах агентности и рассуждения

## Связи с другими темами

- [[dsa_with_top_k_selector.md]] - подробное описание DSA с top-K селектором
- [[enhanced_mla_with_top_k_selector.md]] - усиленная MLA с top-K селектором в латентах  
- [[unbiased_kl_estimate_in_grpo.md]] - улучшение GRPO с несмещенной оценкой KL-дивергенции
- [[deepseek_sparse_attention.md]] - базовая концепция DSA
- [[multi_head_latent_attention.md]] - основная концепция MLA
- [[group_relative_policy_optimization.md]] - основной алгоритм RL с улучшениями
- [[deepseek_v3_2_speciale.md]] - флагманская версия с этими улучшениями
- [[deepseek_v3_2_reinforcement_learning_agent_training.md]] - применение в RL системах

## Источники

- Технический отчет DeepSeek-V3.2: "DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models"
- Исследования по DSA, MLA и GRPO
- Оригинальные архитектурные диаграммы и визуализации