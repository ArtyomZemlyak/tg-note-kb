# Семейство Emu - мультимодальные модели BAAI

## Общее описание

**Семейство Emu** - это серия мультимодальных моделей, разработанных Beijing Academy of Artificial Intelligence (BAAI), начиная с оригинальной модели Emu, через Emu2, и заканчивая последними версиями Emu3 и Emu3.5. Эти модели представляют собой "Native Multimodal Models", работающие с чередующимися визуально-текстовыми последовательностями.

## История развития

### Оригинальная модель Emu
- Первый шаг в направлении native multimodal моделей
- Основной фокус на интерливинг (interleaving) текста и изображений
- Демонстрировала возможности совместной обработки визуальных и текстовых данных

### Emu2
- Улучшенная архитектура по сравнению с оригинальной моделью
- Повышенная эффективность в задачах генерации и понимания
- Улучшенная работа с длинными последовательностями

### Emu3
- Значительное масштабирование по сравнению с предыдущими версиями
- Больше параметров и больший объем данных для обучения
- Улучшенные архитектурные компоненты для мультимодального понимания

### Emu3.5
- Последняя версия семейства на данный момент
- Представляет собой **world-модель**, работающую с текстовыми и пиксельными потоками
- Введение **DiDA (Discrete Diffusion Adaptation)** подхода для ускорения инференса (примерно 20× быстрее без потери качества)
- Обучена на более чем 10T+ чередующихся vision-language токенах
- Превосходит Nano Banana в задачах генерации, редактирования и интерливинга

## Общие архитектурные принципы

### Unified World Modeling
- Всё семейство Emu следует подходу unified world modeling
- Предсказание следующего состояния совместно для визуального и языкового потоков
- Возможность моделирования и генерации чередующихся визуально-текстовых последовательностей

### Native Multimodal Processing
- Отсутствие необходимости в адаптерах модальностей или специфичных для задач головных модулях
- Прямая обработка и генерация данных в разных модальностях
- Единый токенизационный подход для различных типов данных

## Технологические достижения

### DiDA (Discrete Diffusion Adaptation)
- Внедрено в Emu3.5
- Преобразует последовательное декодирование в параллельное двустороннее "денойзинг"-предсказание
- Значительно ускоряет инференс без потери качества

### Scale и обучение
- Масштаб обучения: 10T+ токенов для Emu3.5
- Использование RL-дообучения для повышения качества рассуждения и генерации
- Обучение на видеоданных с транскриптами для захвата пространственно-временной структуры

## Сравнение моделей

| Модель | Год | Особенности | Основные улучшения |
|--------|-----|-------------|-------------------|
| Emu    | 2023 | Оригинальная архитектура | Интерливинг текста и изображений |
| Emu2   | 2023 | Улучшенная архитектура | Повышенная эффективность |
| Emu3   | 2024 | Масштабированная версия | Больше параметров, улучшенные компоненты |
| Emu3.5 | 2025 | World-модель с DiDA | 20× ускорение инференса, world modeling |

## Применения

### Общие задачи
- Генерация изображений по текстовому описанию
- Редактирование изображений
- Интерливинговые задачи
- Визуально-языковое рассуждение

### Продвинутые задачи (Emu3.5)
- Долгосрочное моделирование визуально-языковых последовательностей
- Пространственно-временно согласованные генерации
- Открытая эмбодиментная манипуляция

## Влияние и значимость

Семейство Emu представляет собой важное направление в развитии native multimodal ИИ-систем, продемонстрировав:
- Возможность эффективной обработки чередующихся визуально-текстовых последовательностей
- Прогресс в масштабировании мультимодальных моделей
- Возможность создания world моделей с мультимодальными возможностями
- Практическое применение подходов, таких как DiDA, для улучшения производительности

## Связи с другими темами

- [[multimodal_models.md|Мультимодальные модели]] - Общие понятия о мультимодальных архитектурах
- [[world_models.md|World модели]] - Концепция world моделей, развитая в Emu3.5
- [[emu3.5.md|Emu3.5]] - Подробная информация о последней версии семейства
- [[diffusion_models.md|Диффузионные модели]] - База для технологии DiDA
- [[ming.md|Ming]] - Альтернативная мультимодальная модель от inclusionAI