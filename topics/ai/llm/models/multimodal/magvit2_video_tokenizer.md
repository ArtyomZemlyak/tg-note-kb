# MAGViT2: Модель видео токенизации

## Описание

MAGViT2 (Masked Generative Video Transformer v2) - это улучшенная версия MAGViT, предназначенная для эффективной токенизации видео. Модель использует lookup-free quantization и архитектурные улучшения для токенизации изображений и видео. Модель была представлена в статье "MAGVIT-v2: Language Model Driven Visual Generation" и используется в архитектуре Loong для токенизации видео данных.

Согласно [оригинальной статье](https://proceedings.iclr.cc/paper_files/paper/2024/file/036912a83bdbb1fd792baf6532f102d8-Paper-Conference.pdf), MAGViT2 предлагает инновационный подход к видео токенизации, который преодолевает ограничения традиционных VQ-методов.

## Архитектура

### Lookup-free quantization

- Основная инновация MAGViT2 заключается в использовании lookup-free quantization
- Вместо традиционного подхода с codebook, каждый канал квантуется отдельно в {-1, 1}
- Это позволяет избежать ограничений по размеру кодбука и повысить эффективность

### Видео токенизация

- MAGViT2 обучается кодировать как изображения, так и видео с помощью одного и того же подхода
- Использует 3D CNN свёрточные операции для обработки временных последовательностей
- Применяет Clustering Vector Quantization для эффективной токенизации

## Преимущества

1. **Отсутствие зависимости от размера кодбука**: Lookup-free квантование не требует хранения больших кодбуков
2. **Единая архитектура**: Одна модель может обрабатывать как изображения, так и видео
3. **Эффективность**: Повышенная вычислительная эффективность по сравнению с традиционными VQ-методами
4. **Качество**: Повышенное качество токенизации по сравнению с предыдущими версиями

## Применение в Loong

- В модели Loong MAGViT2 используется в качестве энкодера для токенизации видео
- Размер токенайзера составляет 246M параметров
- После токенизации видеотокены подаются на вход LLM для генерации

## Основные улучшения по сравнению с MAGViT

- **Улучшенная квантовка**: Lookup-free квантование вместо традиционного Vector Quantization
- **Архитектурные улучшения**: Повышенная эффективность и качество генерации
- **Объединённая обработка**: Возможность обработки как изображений, так и видео в единой архитектуре

## Связи с другими темами

- [[./loong_video_generation.md]] - Модель, использующая MAGViT2
- [[./vqgan_decoder.md]] - Альтернативный подход к токенизации/декодированию
- [[../../generative_models.md]] - Общая информация о генеративных моделях
- [[../../diffusion_models.md]] - Сравнение с диффузионными моделями

## Источники

1. [MAGVIT-v2: Language Model Driven Visual Generation](https://proceedings.iclr.cc/paper_files/paper/2024/file/036912a83bdbb1fd792baf6532f102d8-Paper-Conference.pdf) - Оригинальная статья, описывающая MAGViT2 и его архитектуру
2. [Open-MAGVIT2: An Open-Source Project Toward Democratizing Auto-regressive Visual Generation](https://arxiv.org/html/2409.04410v2) - Открытый проект, реализующий MAGViT2 подход
3. [MAGVIT: Masked Generative Video Transformer](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_MAGVIT_Masked_Generative_Video_Transformer_CVPR_2023_paper.pdf) - Оригинальная статья о MAGViT, предшественнике MAGViT2