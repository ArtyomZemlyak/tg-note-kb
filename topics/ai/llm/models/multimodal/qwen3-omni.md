# Qwen3-Omni

## Описание

Qwen3-Omni - это новая мультимодальная модель от команды Qwen, которая достигает SOTA-результатов или близких к ним сразу на всех типах данных. Качество не ухудшается ни в одном направлении по сравнению с немультимодальными моделями Qwen. Другими словами, Qwen3-Omni показывает качество на тексте не хуже, чем текстовая версия Qwen3 или визуальная Qwen3-VL, при сопоставимых размерах моделей.

## Архитектура

### Thinker-Talker архитектура

Qwen3-Omni использует архитектуру Thinker-Talker:
- **Thinker** - языковая модель, которая умеет принимать на вход данные разных модальностей и выдавать текст
- **Talker** - принимает выходы Thinker и генерирует аудио

Важное отличие от предыдущего Qwen2.5-Omni в том, что теперь Thinker/Talker - это MoE-модели (Mixture of Experts).

### Модальностные энкодеры

- Для изображений используется обновленный энкодер Qwen3-VL (вместо Qwen2.5-VL)
- Для аудио авторы обучили свой энкодер с нуля (вместо дообучения Whisper)
- Разные модальности кодируются за счёт соответствующих энкодеров

### Передача текста в систему

В отличие от предыдущих версий:
- Для изображений и аудио продолжают использовать скрытые состояния (hiddden states) Thinker
- Текст теперь передаётся в виде обычных текстовых эмбеддингов
- Это делает систему гибче: можно использовать разные промпты для Thinker и Talker или добавлять дополнительный контекст (например, через RAG), не ухудшая качество

## Ключевые особенности

### Мультимодальные возможности

- **Текст**: Обработка текстовых данных
- **Изображения**: Визуальное понимание с использованием Qwen3-VL энкодера
- **Аудио**: Распознавание и генерация речи, понимание аудио
- **Видео**: Динамическая обработка видео с гибким соотношением кадров

### Языковая поддержка

- **Текст**: 119 языков
- **Speech-understanding**: 19 языков
- **Speech-generation**: 10 языков

### Длительность обработки

- Модель может обрабатывать очень длинные входы - до 40 минут

## Производительность

- Улучшен ризонинг независимо от модальности входа
- Низкая задержка (latency) - всё работает достаточно быстро
- Достигает SOTA результатов или близких к ним на всех типах данных

## Сравнение с Qwen2.5-Omni

- Использует обновленные энкодеры
- Использует MoE архитектуру для Thinker/Talker (вместо плотных моделей)
- Новый подход к передаче текста (эмбеддинги вместо скрытых состояний)
- Новый аудиоэнкодер, обученный с нуля (вместо дообучения Whisper)
- Более сильный downsampling factor в аудио модальности (8 вместо 4)
- Динамическая подача видео вместо фиксированных двухсекундных блоков
- Улучшенная асинхронность и потоковая обработка

## Применение

[[qwen3-omni-audio-processing.md|Обработка аудио в Qwen3-Omni]] - Подробная информация о возможностях аудиообработки
[[qwen3-omni-video-processing.md|Обработка видео в Qwen3-Omni]] - Подробная информация о видеообработке
[[qwen3-omni-training-methodology.md|Методология обучения Qwen3-Omni]] - Подробная информация о процессе обучения