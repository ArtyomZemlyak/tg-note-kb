# NVIDIA Llama-3 Nemotron Super 49B v1.5: Обзор модели

## Описание

NVIDIA Llama-3.3-Nemotron-Super-49B-v1.5-NVFP4 - это 49-миллиардный языковой резонирующий движок, производный от Llama-3.3-70B-Instruct от Meta, с улучшенными возможностями рассуждения, вызова инструментов и стабильного диалога на длинных контекстах. Модель оптимизирована для реальных агентских нагрузок, таких как RAG (расширенная генерация с извлечением), вызов инструментов и сложные цепочки действий ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4)).

## Архитектура

- **Тип модели**: Плотная decoder-only трансформерная модель
- **Базовая модель**: Производная от Llama-3.3-70B-Instruct от Meta
- **Уникальные особенности архитектуры**:
  - Пропуск внимания: Некоторые блоки полностью пропускают внимание или заменяют его одним линейным слоем
  - Переменная FFN: Различные коэффициенты расширения/сжатия в FFN-слоях между блоками
  - Нестандартные, неповторяющиеся блоки, созданные с помощью нейронного поиска архитектур (Neural Architecture Search, NAS)
- **Поиск архитектуры**: Использует алгоритм нейронного поиска архитектур (Neural Architecture Search, NAS) для оптимизации между точностью и эффективностью
- **Размер модели**: 26B параметров (в отличие от номинальных 49B в названии, это 26B параметров, оптимизированных через NAS)
- **Точность**: NVFP4, BF16, F8_E4M3, U8

## Ключевые особенности

### Длинный контекст
- **Длина контекста**: 128K токенов (131,072 токена), позволяющая обрабатывать большие беседы, документы и планы без нарезки ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

### Возможности рассуждения
- **Рассуждение**: Пост-обучение для задач рассуждения
- **Двухрежимная операция**:
  - Рассуждение ВКЛ (по умолчанию): Для сложного решения проблем
  - Рассуждение ВЫКЛ: Для прямых ответов (управляется через системный промпт `/no_think` для ВЫКЛ)

### Вызов инструментов
- **Возможность вызова инструментов**: С встроенным парсером инструментов
- **Интеграция с vLLM**: Поддержка вызова инструментов с пользовательским парсером ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

### Поддержка нескольких языков
- **Основной язык**: Английский
- **Дополнительные языки**: Немецкий, французский, итальянский, португальский, хинди, испанский и тайский ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

## Применение

### Агентские задачи
Модель оптимизирована для:
- RAG (расширенная генерация с извлечением)
- Вызов инструментов
- Сложные цепочки действий
- Диалоговые сценарии с длинным контекстом ([Введение в модель](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

### Оборудование
- **Оптимизирована для**: Системы GPU NVIDIA (микроархитектуры Ampere и Hopper)
- **Развертывание**: Может работать на одном GPU H200 несмотря на большую емкость рабочей нагрузки
- **Эффективность**: Использует уменьшенный объем памяти благодаря NAS, позволяя использовать большие batch'и ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

## Обучение и пост-обработка

### Период обучения
- **Период обучения**: Ноябрь 2024 - Июль 2025
- **Дата отсечки данных**: 2023 (из ссылки на Llama 3.3)
- **Дистилляция знаний**: 40 миллиардов токенов из датасетов FineWeb, Buzz-V1.2 и Dolma ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

### Многофазная пост-обработка
- **Supervised fine-tuning** для математики, кода, науки и вызова инструментов
- **Обучение с подкреплением (Reinforcement Learning)** с несколькими этапами:
  - Оптимизация с предпочтениями с вознаграждением (RPO) для чата
  - Обучение с подкреплением с проверяемыми вознаграждениями (RLVR) для рассуждения
  - Итерационная оптимизация с прямым предпочтением (DPO) для вызова инструментов
- **Финальная точка проверки** объединена из нескольких точек проверки RL и DPO ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

## Производительность

### Метрики производительности
- **Тестирование на**: 1x NVIDIA B200 GPU
- **Результаты оценки** (при температуре 0.6, top_p=0.95, длина последовательности 64k):
  - MATH500: 94.4% pass@1
  - AIME 2024: 82.7% pass@1
  - GPQA: 70.5% pass@1
  - LiveCodeBench 24.07-25.01: 65.6% pass@1
  - MMLU Pro (CoT): 75.9% pass@1
  - Humanity's Last Exam (Только текст): 6.02% ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

## Уникальные возможности

- **Нейронный поиск архитектур (NAS)**: Предлагает компромисс между точностью и эффективностью с уменьшенным объемом памяти
- **Развертывание на одном GPU**: Помещается на GPU H200 несмотря на большую емкость рабочей нагрузки
- **Задачи агентов**: Оптимизирована для RAG (Расширенная генерация с извлечением) и вызова инструментов
- **Дистилляция по блокам**: Создает варианты с различными компромиссами между качеством и вычислительной сложностью
- **Высокая пропускная способность**: Оптимизирована для эффективности и экономии затрат ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

## Связь с другими темами

- [[llama_3_1.md]] - Базовая модель Llama 3.3, на которой основана эта модель
- [[../../reasoning.md]] - Общие аспекты рассуждений в ИИ
- [[../../llm/reasoning/logical_reasoning_in_llms.md]] - Логическое мышление в LLM
- [[../../llm/tools/toolllm.md]] - LLM, обученные работе с инструментами
- [[../../agents/advanced_tool_calling_and_planning.md]] - Продвинутый вызов инструментов и планирование для агентов
- [[nvidia/omnivinci.md]] - Другая модель от NVIDIA, демонстрирующая подходы NVIDIA к разработке LLM
- [[../techniques/neural_architecture_search_nas.md]] - Нейронный поиск архитектур, используемый для оптимизации модели

## Лицензия

- **Лицензия NVIDIA Open Model**
- Также регулируется Соглашением о лицензии сообщества Llama 3.3 ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4))

Модель представляет собой подход NVIDIA к созданию эффективных моделей рассуждения, которые балансируют между производительностью и вычислительными требованиями через новую методологию NAS ([Hugging Face Model Card](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5-NVFP4)).

![Архитектура NVIDIA Llama-3 Nemotron Super](../../../../images/img_1763100919_AgACAgIA.jpg)

**Описание:** Диаграмма архитектуры модели NVIDIA Llama-3 Nemotron Super 49B v1.5, показывающая ключевые особенности нейронного поиска архитектур (Neural Architecture Search), включая пропуск внимания и переменные FFN слои.