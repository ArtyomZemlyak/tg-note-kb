# nanochat: Образовательный проект Андрея Карпати по созданию LLM

## Краткое описание
nanochat - это полнотекстовая реализация LLM с функциональностью, подобной ChatGPT, в одном чистом и минимальном кодовом базисе. Проект разработан в качестве капстонного проекта для курса LLM101n от Eureka Labs и демонстрирует полный цикл разработки LLM: токенизация, предобучение, тонкая настройка, оценка, инференс и веб-сервер.

## Основная информация

### Цель проекта
- Простая, понятная реализация LLM, подобной ChatGPT
- Демонстрация полного пайплайна: от подготовки данных до веб-интерфейса
- Образовательный инструмент для изучения LLM с нуля
- Часть курса LLM101n, разрабатываемого Eureka Labs

### Функциональность
- Полнофункциональный чат с веб-интерфейсом, как ChatGPT
- Единый скрипт пайплайна обучения (speedrun.sh)
- Поддержка различных размеров моделей ($100, $300, $1000 уровни)
- Встроенные метрики оценки и отчеты
- Хакабельная и настраиваемая архитектура
- Поддержка различных конфигураций GPU (8XH100, 8XA100 или одиночный GPU)

### Быстрый старт
- Скрипт speedrun.sh обучает модель уровня $100 примерно за 4 часа
- Результируется в модель с 1.9 миллиардами параметров с 32 трансформерными слоями
- Стоимость обучения около $800 для полной модели (33 часа на 8XH100)
- Веб-интерфейс для общения с обученной моделью

### Технические особенности
- Использует датасет FineWeb-Edu для обучения
- Доступен для бюджетов менее $1000
- Читаемый и хакабельный код, а не сложный фреймворк
- Поддерживает разные конфигурации GPU, находится в разработке поддержка CPU/MPS

## Новые концепции и термины
- **FineWeb-Edu**: Высококачественный отфильтрованный датасет для обучения LLM на образовательном контенте
- **Speedrun обучение**: Быстрое обучение модели с минимальными затратами (около $100 за 4 часа)
- **Капстонный проект**: Завершающий проект курса, демонстрирующий полный цикл разработки

## Примеры применения
- Обучение LLM с нуля для студентов и энтузиастов
- Практическое изучение архитектуры трансформеров
- Эксперименты с обучением и тонкой настройкой LLM
- Демонстрация полного пайплайна разработки LLM

## Связи с другими темами
- [[ai/llm/llm101n_course.md]] - Курс, в котором используется nanochat как капстонный проект
- [[ai/llm/models/nanoGPT.md]] - Предыдущий образовательный проект Андрея Карпати по созданию GPT-моделей
- [[ai/llm/data_quality.md]] - Использование качественных датасетов для обучения LLM
- [[ai/llm/karpathy_critique_of_llms.md]] - Критика LLM от Андрея Карпати, дополненная образовательной инициативой

## Ссылки на источники
- https://github.com/karpathy/nanochat
- https://www.eurekacademy.co/