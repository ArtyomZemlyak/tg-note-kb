# On-Policy Distillation (Дистилляция по политике)

## Определение

On-Policy Distillation — это метод дистилляции знаний, при котором обучение модели-ученика происходит в процессе генерации примеров, которые затем проверяются моделью-учителем. Обучение происходит только в тех случаях, когда учитель не согласен с выводами ученика.

## Основные особенности

- **Активное участие учителя**: Примеры, сгенерированные учеником, проходят проверку учителем
- **Селективное обучение**: Модель-ученик обучается только в местах, где есть расхождение с учителем
- **Проблема словарей**: Классические методы дистилляции требуют одинаковые словари токенизатора у учителя и ученика
- **Решение exposure bias**: Модель видит одно и то же распределение как на обучении, так и на инференсе

## Отличие от традиционной дистилляции

В отличие от традиционной дистилляции знаний (как в оригинальной статье Хинтона), где используются логиты учителя напрямую, on-policy distillation:

- Преобразует задачу прямой дистилляции в задачу критика
- Использует динамическую проверку согласия между учителем и учеником
- Позволяет использовать модели с разными словарями токенизатора
- Решает проблему exposure bias за счет обучения на основе роллаутов

## Сравнение с другими методами

- **Speculative decoding**: Сходство есть, но on-policy distillation работает в "обратном" направлении
- **Reinforcement Learning**: Использует аналогичные концепции on-policy и off-policy алгоритмов
- **KL-дивергенция**: Можно использовать для измерения несогласованности между моделями
- **Off-policy дистилляция**: В off-policy роллауты не бесплатны, а в on-policy их можно предпосчитать

## Принцип работы

On-policy дистилляция работает следующим образом:

1. Модель-студент генерирует последовательность (роллаут)
2. Учитель оценивает каждый токен в этой последовательности
3. Накладывается штраф на ошибки, вычисленные через учителя
4. Это создает естественный curriculum (чем дальше, тем лучше качество генераций)
5. Полностью отсутствует exposure bias

## Преимущества

- **Естественный curriculum**: Качество генераций улучшается по мере обучения
- **Отсутствие exposure bias**: Модель видит одинаковое распределение при обучении и инференсе
- **Гибкость**: Может работать с моделями разных архитектур

## Применение

On-policy distillation особенно полезна:
- При обучении маленьких моделей с помощью больших учителей
- При работе с моделями, имеющими разные архитектуры и словари
- В сценариях, где важна точность конкретных выводов
- При дистилляции моделей в условиях, близких к реальным (The Countdown Game)

## Сравнение On-Policy и Off-Policy

Согласно исследованиям, качество on-policy дистилляции возрастает по сравнению с off-policy дистилляцией. На The Countdown Game при использовании полной on-policy дистилляции удалось достичь 92% от качества учителя. При lambda=0.5 восстанавливается 88% качества учителя, при lambda=0.25 — 86% качества, а при lambda=0.0 — 79% качества учителя.

## Связи с другими темами

- [[knowledge_distillation.md]] - основная концепция дистилляции знаний
- [[speculative_decoding.md]] - метод, с которым сравнивают on-policy distillation
- [[reinforcement_learning_in_llms.md]] - концепции on-policy и off-policy алгоритмов
- [[gold_method.md]] - обобщение on-policy дистилляции
- [[universal_logit_distillation.md]] - метод кросс-токенизаторной дистилляции
- [[distillation_challenges.md]] - проблемы традиционной дистилляции, которые решает on-policy подход
- [[rlhf.md]] - другой подход к обучению с использованием on-policy концепций
- [[gold_method.md]] - обобщение on-policy дистилляции
- [[universal_logit_distillation.md]] - метод кросс-токенизаторной дистилляции
- [[distillation_challenges.md]] - проблемы традиционной дистилляции

## Источники

1. [Hinton et al. - Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531) - оригинальная статья о дистилляции знаний
2. [Generalized Knowledge Distillation](https://arxiv.org/abs/) - статья о комбинации on-policy и off-policy методов
3. [Huggingface Blog Post on GOLD](https://huggingface.co/blog/gold) - объяснение контекста on-policy дистилляции и современных улучшений