# Оптимизация LLM

## Краткое описание

Этот раздел посвящен различным методам оптимизации больших языковых моделей (LLM), включая техники сжатия, квантования, прунинга и параметрически эффективного обучения. Эти методы позволяют улучшить производительность моделей, снизить вычислительные требования и ускорить инференс.

## Основные темы

- [[compress_to_impress_single_gradient_llm_adaptation.md]] - Метод адаптации LLM за один шаг градиентного спуска
- [[laser_layer_selective_rank_reduction.md]] - Оригинальный метод понижения ранга без обучения
- [[structured_pruning.md]] - Общий подход к структурированному прунингу в LLM