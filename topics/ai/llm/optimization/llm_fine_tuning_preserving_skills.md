# Сохранение навыков при дообучении LLM: лучшие практики предотвращения катастрофического забывания

## Описание

При дообучении (fine-tuning) больших языковых моделей (LLM) возникает критическая проблема - катастрофическое забывание, при котором модель теряет свои предыдущие навыки и знания при изучении новых задач. Этот файл описывает лучшие практики и методы, которые позволяют дообучать LLM, сохраняя их предыдущие способности и знания.

## Основная информация

Когда LLM дообучаются на новой задаче или в новой области, они могут потерять часть своих первоначальных возможностей. Это особенно проблематично, когда модель дообучается для специфических бизнес-задач, но должна по-прежнему сохранять общие языковые навыки. Катастрофическое забывание - это фундаментальная проблема в машинном обучении, когда нейронные сети резко забывают предыдущую информацию после изучения новой информации.

## Ключевые методы и практики

### 1. Параметрически эффективное дообучение (Parameter-Efficient Fine-Tuning, PEFT)

#### Low-Rank Adaptation (LoRA)
- Обновляет только небольшое подмножество параметров модели через низкоранговые адаптеры
- Позволяет сохранить основные параметры модели неизменными
- Обеспечивает сопоставимое качество с полным дообучением при значительно меньших вычислительных затратах
- [[../../lora_optimization.md|Подробнее о LoRA]]

#### Адаптеры (Adapters)
- Вставляются в промежуточные слои модели
- Обучает только параметры адаптеров, остальная часть модели заморожена
- Позволяет модели сохранять первоначальные навыки при адаптации к новым задачам

#### BitFit
- Обновляет только параметры смещения (bias)
- Значительно снижает количество обучаемых параметров
- Позволяет сохранить большинство оригинальных параметров неизменными

### 2. Регуляризационные методы

#### Упругая консолидация весов (Elastic Weight Consolidation, EWC)
- Ограничивает изменения весов, важных для предыдущих задач
- Добавляет регуляризационный член к функции потерь, штрафующий за изменение критических весов
- Предотвращает значительные изменения параметров, важных для прежних навыков
- [[../../../ai/regularization/elastic_weight_consolidation.md|Подробнее о EWC]]

#### Регуляризация через утечку градиентов (Gradient Episodic Memory/Experience Replay)
- Сохраняет градиенты от предыдущих задач
- Использует их для ограничения изменений в весах важных для прежних навыков

### 3. Методы воспроизведения опыта (Experience Replay Methods)

#### Хранение реальных примеров
- Сохранение небольшого подмножества оригинальных данных из предыдущих задач
- Периодическое использование этих примеров при обучении новым задачам
- Позволяет модели "напоминать" о предыдущих знаниях
- [[../../../ai/continual_learning/rehearsal/experience_replay.md|Подробнее о методах воспроизведения опыта]]

#### Псевдо-воспроизведение (Pseudo-rehearsal)
- Генерация примеров с помощью модели, обученной на предыдущих задачах
- Позволяет избежать хранения оригинальных данных при сохранении знаний

#### Генеративное воспроизведение (Generative Replay)
- Использование генеративных моделей для создания "псевдо-данных" для повторного обучения
- Позволяет модели вспоминать предыдущие задачи без хранения оригинальных данных

### 4. Техники настройки гиперпараметров

#### Малые темпы обучения (Learning Rates)
- Использование более низких темпов обучения при дообучении
- Предотвращает радикальные изменения в весах модели
- Позволяет сохранить предыдущие навыки при изучении новых задач

#### Постепенное снижение темпа обучения (Learning Rate Scheduling)
- Использование расписаний обучения, таких как линейное убывание или косинусное расписание
- Позволяет модели более осторожно адаптироваться к новым данным

#### Фаза разогрева (Warmup Phase)
- Постепенное увеличение темпа обучения в начале дообучения
- Помогает стабилизировать процесс обучения и сохранить существующие знания

### 5. Архитектурные методы

#### Замораживание слоев (Layer Freezing)
- Замораживание более ранних (обычно более общих) слоев при дообучении
- Позволяет сохранить общие языковые представления
- Обновление только поздних слоев, которые более специфичны для задачи

#### Прогрессивные нейронные сети (Progressive Neural Networks)
- Расширение архитектуры новыми ветвями для каждой задачи
- Предотвращение конфликта между знаниями разных задач
- Позволяет модели сохранять предыдущие навыки при изучении новых

#### Вложенные архитектуры (Nested Architectures)
- Использование систем непрерывной памяти (Continuum Memory System)
- Позволяет модели адаптироваться к новым задачам без потери знаний
- [[../../../ai/continual_learning/nested_learning.md|Подробнее о вложенном обучении]]

### 6. Альтернативные подходы

#### RAG (Retrieval-Augmented Generation)
- Вместо дообучения модели с использованием специфических данных, использование векторных баз данных для предоставления релевантной информации во время вывода
- Особенно рекомендуется, когда набор данных недостаточно велик для эффективного дообучения
- Позволяет сохранить оригинальную модель неизменной

#### Обучение с подкреплением с человеческой обратной связью (RLHF) и его альтернативы
- Использование методов выравнивания, таких как RLHF, DPO или RLAIF, для тонкой настройки поведения модели
- Позволяет улучшить соответствие человеческим предпочтениям без значительного влияния на базовые знания
- [[../../rlhf.md|Подробнее о RLHF]]

## Практические рекомендации

### Выбор подходящего метода

1. **Для ограниченных вычислительных ресурсов**: Используйте LoRA или другие методы PEFT
2. **Для критически важных приложений**: Рассмотрите комбинацию нескольких методов
3. **Для новых задач с небольшим количеством данных**: Используйте RAG вместо дообучения
4. **Для задач с последовательным обучением**: Применяйте методы воспроизведения опыта

### Мониторинг забывания

1. **Непрерывный мониторинг**: Отслеживайте ключевые метрики как для новых, так и для предыдущих задач
2. **Оценка с удержанием (Held-out evaluation)**: Регулярно тестируйте модель на датасетах предыдущих задач
3. **Раннее прекращение**: Останавливайте обучение, когда наблюдается значительное снижение производительности на старых задачах

## Новые концепции и термины

- **Catastrophic Forgetting (Катастрофическое забывание)**: Радикальная потеря предыдущих знаний при изучении новой информации в нейронных сетях.

- **Parameter-Efficient Fine-Tuning (PEFT)**: Методы дообучения, при которых обновляется только небольшая часть параметров, что экономит память и вычислительные ресурсы.

- **Knowledge Preservation**: Сохранение предыдущих навыков и знаний при дообучении модели.

- **Task Interference**: Конфликт между знаниями разных задач, приводящий к деградации производительности.

- **Continual Learning**: Подход, при котором модель обучается последовательно нескольким задачам, сохраняя знания о предыдущих задачах.

## Примеры применения

- **Дообучение для бизнес-приложений**: Сохранение общих языковых навыков при специализации на корпоративных задачах
- **Адаптация к домену**: Сохранение общей компетентности при специализации на определённой области (например, медицина, юриспруденция)
- **Многофункциональные агенты**: Обучение новых навыков при сохранении существующих функций
- **Обновления моделей**: Интеграция новых знаний без потери предыдущих способностей

## Связи с другими темами

- [[../../continual_learning/catastrophic_forgetting/catastrophic_forgetting.md]] - Катастрофическое забывание: фундаментальная проблема, которую решают эти методы
- [[../../continual_learning/nested_learning.md]] - Вложенное обучение: новая парадигма ИИ, решающая проблему непрерывного обучения
- [[../../lora_optimization.md]] - Low-Rank Adaptation: один из ключевых методов параметрически эффективного дообучения
- [[../../../ai/regularization/elastic_weight_consolidation.md]] - EWC: регуляризационный метод, предотвращающий забывание
- [[../../../ai/continual_learning/rehearsal/experience_replay.md]] - Методы воспроизведения опыта: подходы к сохранению знаний через повторное обучение
- [[../../rlhf.md]] - RLHF: метод выравнивания, также помогающий сохранить полезность модели
- [[techniques_for_small_models.md]] - Дополнительные техники эффективного обучения, применимые к проблеме забывания

## Источники

1. [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) - Оригинальная статья о методе Low-Rank Adaptation, позволяющем эффективно дообучать LLM без потери предыдущих навыков
2. [Overcoming Catastrophic Forgetting in Neural Networks](https://arxiv.org/abs/1612.00796) - Статья о методе Elastic Weight Consolidation и других подходах к предотвращению катастрофического забывания
3. [Parameter-Efficient Transfer Learning](https://arxiv.org/abs/2008.03156) - Обзор методов параметрически эффективного обучения, включая LoRA и адаптеры
4. [Machine Learning Mastery: 5 Problems Encountered Fine-Tuning LLMs with Solutions](https://machinelearningmastery.com/5-problems-encountered-fine-tuning-llms-with-solutions/) - Практическое руководство по проблемам дообучения LLM, включая катастрофическое забывание
5. [Hugging Face Discussion: How to Prevent Catastrophic Forgetting in Fine-tuned LLMs](https://discuss.huggingface.co/t/how-to-prevent-catastrophic-forgetting-in-fine-tuned-large-language-models/135153) - Практические советы от сообщества по предотвращению катастрофического забывания