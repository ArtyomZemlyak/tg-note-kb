# Логическое мышление в больших языковых моделях (LLM)

## Краткое описание

Этот файл описывает проблемы и подходы к логическому мышлению в больших языковых моделях (LLM). Несмотря на отличные навыки обработки текста, LLM часто испытывают трудности с логическим мышлением и последовательными логическими выводами. Статья охватывает два основных направления исследований: решение логических задач и обеспечение логической согласованности.

## Основная информация

### Проблема логического мышления

Основная проблема заключается в том, что LLM обучаются на текстах, написанных людьми, которые редко содержат примеры настоящего логического мышления, последовательных дедукций или формальных доказательств. Это создает фундаментальное ограничение, при котором модели могут генерировать грамматически правильный текст, но не справляются с логическими выводами.

LLaMA 13B, например, правильно отвечает только на 33.63% логических вопросов в датасете FOLIO, что практически равно случайному угадыванию (33.33%).

### Два основных направления исследований

1. **Решение логических задач** - способность LLM решать проблемы, требующие многоступенчатого логического мышления
2. **Логическая согласованность** - обеспечение того, чтобы LLM не производили противоречивые ответы

### Категории подходов

#### 1. Методы на основе решателей (Solver-Based Methods)

Эти методы переводят естественный язык в символическую форму (FOL, CSP, SAT) и используют внешние логические решатели, а затем переводят результаты обратно в естественный язык.

- **Faithful Chain-of-Thought (Faithful CoT)** - делает рассуждение модели прозрачным, показывая реальные промежуточные шаги, использованные для ответа, с использованием внешних решателей.
- **SatLM** - переводит текстовые задачи в общие логические формулы, затем решает их с помощью специализированных алгоритмов.
- **LINC** - переводит задачи на естественном языке в логические формулы и решает их с помощью специализированных алгоритмов.
- **LogicLM** - сразу преобразует задачи в несколько формальных систем одновременно (линейное программирование, логика первого порядка, задачи удовлетворения ограничений и логические проверки).
- **CLOVER** - сначала строит структуру логической зависимости в предложении, затем переводит его части поэтапно, чтобы сохранить смысл.

#### 2. Методы на основе промптов (Prompt-Based Methods)

- **Chain-of-Thoughts (CoT)** - поощряет модели к "мышлению вслух"
- **Tree-of-Thoughts (ToT)** - позволяет модели рассматривать несколько возможных цепочек рассуждений и выбрать наиболее убедительную, организуя рассуждение в виде древовидной структуры.
- **Graph-of-Thoughts (GoT)** - преобразует рассуждение в структуру графа, где разные части знаний соединяются через узлы и ребра.
- **Diagram-of-Thoughts (DoT)** - структурирует рассуждение как ориентированный ациклический граф (DAG), где узлы представляют утверждения, пояснения, проверки и даже критические комментарии.
- **Symbolic Chain-of-Thoughts (SymbCoT)** - сначала переводит задачи в логические выражения, затем шаг за шагом применяет правила вывода и в конечном итоге проверяет всю цепочку.
- **Logic-of-Thoughts (LoT)** - сначала использует алгоритмы Python, которые делают строгие логические выводы, затем подает результаты обратно модели в виде текста.
- **LLM-Driven Neuro-Symbolic Approach (LINA)** - использует гипотетико-дедуктивный метод, где гипотезы формируются первыми, а затем проверяются их последствия.
- [[../../../neuro_symbolic_systems.md]] - Более подробное описание нейросимволических систем и их роли в объединении нейронных и символических подходов к рассуждению

#### 3. Методы предобучения и дообучения (Pretraining and Fine-tuning Methods)

- **Deductive Iterative Logic Alignment (DiLA)** - модель сначала предлагает решения, затем итеративно уточняет их с учетом ограничений логики первого порядка. Решатель SAT выполняет проверку правильности.
- **Logic-Driven Contrastive Learning** - обучает модели лучше "понимать" логическую информацию, обучая их различать правильное мышление от неправильного.
- **Abstract Meaning Representation с логически-ориентированной аугментацией (AMR-LDA)** - работает в три этапа: 1) преобразование текста в структурированные графы семантических отношений, 2) выполнение логических преобразований над этим графом для создания новых вариантов рассуждения, 3) перевод графа обратно в текст.
- **Logical Inference Process Training (LOGIPT)** - встраивает процесс рассуждения в модель с использованием внешнего решателя Pyke, позволяя модели воспроизводить и объяснять шаги рассуждения.
- **Algorithmic Logic Training (ALT)** - создает специализированный синтетический корпус на основе логических принципов. Каждая задача сначала генерируется логическим алгоритмом и затем переводится на естественный язык.
- **Векторно-управляемое обучение рассуждению (Vector-Guided Reasoning Training)** - новый метод, разработанный российскими исследователями из T-Bank AI Research, при котором небольшие векторные подсказки усиливают логические шаги модели в нужном направлении без изменения основных параметров, позволяя достичь 100% качества полного дообучения при изменении всего 0.0016% параметров ([Векторно-управляемое обучение рассуждению](vector_guided_reasoning.md)).

## Новые концепции и термины

- **Логическое мышление** - способность LLM делать строгие логические выводы, а не просто генерировать правдоподобный текст
- **Цепочка рассуждений (Chain of Thought)** - подход к улучшению рассуждений в LLM, при котором модели поощряют "думать вслух"
- **Внешние решатели** - отдельные инструменты, которые выполняют строгую логическую проверку или вычисления
- **Формальная логика** - системы логики с четкими правилами вывода, такие как логика первого порядка
- **Логическая согласованность** - способность модели избегать противоречий в своих ответах

## Примеры применения

Подходы к логическому мышлению особенно эффективны для задач, которые требуют:
- Логического планирования
- Математических рассуждений
- Решения головоломок
- Последовательного принятия решений
- Проверки логических выводов из представленной информации
- Фактчекинга и логического анализа

## Основные ограничения

- Потеря семантической информации при символизации
- Распространение ошибок в многоступенчатых процессах
- Вычислительная сложность для сложных задач
- Галлюцинации и неправильные цепочки рассуждений
- Высокие требования к вычислительным ресурсам

## Связи с другими темами

- [[reasoning_patterns.md]] - Шаблоны рассуждения в LLM
- [[mit_symbolic_planning_approach.md]] - Альтернативный подход MIT к планированию через символьные цепочки
- [[../prompt_engineering/cot_variants.md]] - Варианты Chain of Thought
- [[logical_consistency.md]] - Типы логической согласованности
- [[reasoning_benchmarks.md]] - Бенчмарки для оценки рассуждений
- [[../../research_advances/reasoning_models/interruptible_lrms/index.md]] - Прерываемые модели рассуждения, которые исследуют устойчивость LLM в динамических условиях
- [[vector_guided_reasoning.md]] - Новый метод векторно-управляемого обучения рассуждению, разработанный российскими исследователями, позволяющий развивать способности к логическим рассуждениям с минимальными вычислительными затратами