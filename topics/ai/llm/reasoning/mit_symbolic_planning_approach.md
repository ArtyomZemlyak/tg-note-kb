# Подход MIT к обучению LLM планированию с помощью символьных цепочек

## Краткое описание

Новый подход от MIT к обучению языковых моделей рассуждению и планированию, который использует символьные цепочки переходов между состояниями вместо традиционного подхода "цепочка мыслей" (Chain of Thought). Этот метод позволяет моделям по-настоящему "мыслить" при решении задач, а не просто генерировать правдоподобные токены.

## Основная информация

### Проблема традиционного рассуждения в LLM

Традиционное рассуждение в LLM на самом деле не является настоящим рассуждением. То, что называется "рассуждением" или "цепочкой мыслей" (CoT), на деле оставляет модель в той же парадигме, где просто генерируется больше токенов. Это не настоящие рассуждения, а просто расширенная генерация текста.

### Решение от MIT: символьные рассуждения

MIT предложили подход, основанный на идее, что настоящее планирование требует умения переходить из состояния в состояние:

- Вместо простой генерации текста, модель должна уметь переходить из состояния А в состояние Б или В
- Некоторые переходы недопустимы (например, Г не может следовать из А)
- Последовательности типа A->Б могут не приводить к цели, и тогда нужно перейти в состояние В
- Многие задачи на "мышление" раскладываются в такие цепочки переходов состояний (головоломки, логические задачки, математика)

### Символьные цепочки вместо CoT

Символьные рассуждения отличаются от традиционного CoT тем, что:

- Вместо генерации "правдоподобного" CoT в виде обычных токенов, модель учится генерировать символьные цепочки
- Эти цепочки представляют реальные переходы между состояниями
- Это повышает надежность рассуждения и позволяет модели действительно "думать" как человек

### Обучение без разметки

Особенностью подхода является возможность обучения без разметки:

- Символьные цепочки можно проверять с помощью верификатора (как делали DeepSeek в DeepSeek-Prover-V2)
- Сначала модели показывают много цепочек
- Затем модель учится отличать правильные цепочки от неправильных и объяснять, что не так
- Затем применяется RL-подобный подход: модель генерирует CoT, его проверяет верификатор, получаем фидбэк и делаем шаг обучения

## Новые концепции и термины

- **Символьные рассуждения** - подход к рассуждению в LLM, при котором модель использует явные переходы между состояниями вместо генерации текста
- **Переходы между состояниями** - формализация процесса рассуждения как переходов из одного состояния задачи в другое
- **Символьные цепочки** - структурированные последовательности состояний, а не текстовые токены
- **Обучение с верификатором** - метод обучения, при котором отдельная модель проверяет корректность рассуждений
- **RL-подобное обучение** - применение методов обучения с подкреплением для улучшения рассуждений

## Примеры применения

Подход особенно эффективен для задач, которые требуют:

- Логического планирования
- Математических рассуждений
- Решения головоломок
- Последовательного принятия решений
- Задач, где важен путь к решению, а не только конечный ответ

## Результаты

- На задачах из тестов такой подход дает улучшение +30-60 процентных пунктов по сравнению с обычным рассуждением
- Значительные улучшения относительно базового подхода
- Правда, в статье рассматривается довольно узкий домен (использовались старые модели, для GPT-4 использовалась prompt-based настройка)
- Возникает вопрос, возможно ли применение подобного подхода на более высоком уровне

## Связи с другими темами

- [[../llm/prompt_engineering.md]] - Традиционные подходы к рассуждению (Chain of Thought) в LLM
- [[reasoning_patterns.md]] - Другие подходы к рассуждению в моделях
- [[latent_variables_reasoning.md]] - Альтернативный подход к рассуждению через латентные переменные
- [[../llm/prompt_engineering_advanced/cot_variants.md]] - Варианты Chain of Thought, включая синтез (CaT)
- [[pattern_learning/paro.md]] - Подход PARO к обучению с учителем и без него
- [[logical_reasoning_in_llms.md]] - Общее описание подходов к логическому мышлению в LLM
- [[logical_consistency.md]] - Типы логической согласованности, которые также рассматриваются в символьных подходах