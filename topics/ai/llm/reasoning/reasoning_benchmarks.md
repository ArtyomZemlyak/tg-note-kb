# Бенчмарки для оценки логического мышления в LLM

## Краткое описание

Этот файл описывает бенчмарки и датасеты, используемые для оценки способности больших языковых моделей (LLM) к логическому мышлению. Эти инструменты позволяют исследователям измерять, насколько хорошо модели справляются с задачами, требующими логических выводов и рассуждений.

## Основная информация

### Датасеты с открытым форматом ответов

#### FOLIO
Один из наиболее важных датасетов для оценки логического мышления. Содержит задачи на логический анализ и проверку фактов. Интересно, что LLaMA 13B правильно отвечает только на 33.63% вопросов из этого датасета, что лишь немного лучше случайного угадывания (33.33%) при трех вариантах ответа (истина, ложь, неизвестно).

#### Proofwriter
Датасет для проверки цепочек рассуждений и доказательств. Содержит задачи, требующие построения логических доказательств и проверки их корректности.

#### Ruletaker
Содержит логические правила и логические выводы. Используется для проверки способности моделей следовать логическим правилам и делать правильные выводы из них.

### Датасеты с множественным выбором

#### ReClor (Logical Reasoning)
Набор задач логического мышления, требующих выбора правильного ответа. Включает задачи, требующие понимания логических структур и связи между утверждениями.

#### LogiQA
Вопросы, проверяющие логическое понимание текста и аргументации. Оценивает способность модели анализировать логические аргументы и делать выводы.

#### AR-LSAT
Задачи, ориентированные на тренировку логических выводов и анализа аргументов. Основано на реальных экзаменационных задачах LSAT (Law School Admission Test).

## Новые концепции и термины

- **Бенчмарк** - стандартизированный набор задач для оценки производительности моделей
- **Датасет с открытым форматом** - набор данных, где ответы не ограничены вариантами выбора
- **Датасет с множественным выбором** - набор данных, где требуется выбрать правильный ответ из нескольких вариантов
- **FOLIO** - датасет для оценки логического мышления с задачами на проверку фактов и логические выводы
- **Proofwriter** - датасет для проверки способности к построению логических доказательств
- **Ruletaker** - датасет, тестирующий способности следовать логическим правилам
- **ReClor** - набор задач логического мышления с выбором ответа
- **LogiQA** - датасет для оценки логического понимания текста
- **AR-LSAT** - задачи на логический вывод и анализ аргументов
- **Формализации CSP** - задачи удовлетворения ограничений, используемые для тестирования логических способностей
- **Формализации SAT** - задачи выполнимости булевых формул, также используемые в тестировании

## Примеры применения

Бенчмарки для оценки рассуждений используются:
- При сравнении производительности различных LLM
- При оценке эффективности новых методов логического мышления
- При разработке и тестировании новых подходов к обучению с логическими рассуждениями
- При анализе прогресса в области логического мышления ИИ
- При адаптации моделей для специфических задач, требующих логики
- При тестировании новых методов параметрически эффективного обучения, таких как векторно-управляемое обучение рассуждению, которое показал высокую эффективность на шести бенчмарках по математическому рассуждению

## Критерии оценки

- **Процент правильных ответов** - основная метрика во многих датасетах
- **Сложность задач** - уровень сложности влияет на интерпретацию результатов
- **Тип логики** - различные датасеты оценивают разные аспекты логического мышления
- **Размер выборки** - количество примеров в датасете влияет на надежность оценки

## Связи с другими темами

- [[logical_reasoning_in_llms.md]] - Общие подходы к логическому мышлению в LLM
- [[logical_consistency.md]] - Типы логической согласованности
- [[reasoning_patterns.md]] - Шаблоны рассуждения в LLM
- [[vector_guided_reasoning.md]] - Пример метода, который использовал бенчмарки для оценки эффективности подхода к обучению логическим рассуждениям
- [[data_quality_impact_assessment.md]] - Исследование, использовавшее ARC бенчмарк для оценки снижения способностей к рассуждению при обучении на низкокачественных данных