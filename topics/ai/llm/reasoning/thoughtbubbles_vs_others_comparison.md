# Сравнение подходов к рассуждению в LLM: Chain-of-Thought, Free Transformer и Thoughtbubbles

## Обзор подходов

### Chain-of-Thought (CoT)
**Принцип работы**: Поощряет модели к генерации явных шагов рассужлений в виде текста перед выдачей окончательного ответа.

**Характеристики**:
- Явные рассуждения в виде генерируемого текста
- Последовательный процесс рассуждений
- Требует инструкций для активации
- Работает через промптинг и обучение с подсказками

**Преимущества**:
- Интерпретируемость процесса рассуждений
- Простота реализации поверх существующих моделей
- Эффективность на математических и логических задачах

**Ограничения**:
- Фиксированный вычислительный бюджет
- Последовательная природа ограничивает параллелизм
- Не может использоваться во время общего предобучения

### Free Transformer
**Принцип работы**: Переформулировка трансформера как условного вариационного автокодировщика (CVAE), где генерация обусловлена случайными латентными переменными.

**Характеристики**:
- Использование латентных переменных для кодирования высокоуровневой информации
- Неявное планирование в латентном пространстве
- Обучение без специальных инструкций для рассуждений

**Преимущества**:
- Более устойчивые и эффективные рассуждения
- Компактное векторное представление логической структуры
- Улучшенная согласованность рассуждений

**Ограничения**:
- Сложность в реализации и обучении
- Требует изменений в архитектуре модели

### Thoughtbubbles
**Принцип работы**: Новая архитектура трансформера, которая динамически распределяет параллельные вычисления в латентном пространстве, позволяя «разветвлять» или удалять residual streams.

**Характеристики**:
- Параллельные рассуждения в латентном пространстве
- Адаптивное распределение вычислительного бюджета
- Обучение в полностью необучаемом режиме
- Динамическое разветвление и слияние потоков

**Преимущества**:
- Максимальная эффективность вычислений
- Естественная параллелизация рассуждений
- Улучшенные результаты по сравнению с базовыми моделями

**Ограничения**:
- Сложная реализация и потенциальные проблемы с градиентами
- Требуется специализированное оборудование для оптимизации скорости

## Сравнительная таблица

| Критерий | Chain-of-Thought | Free Transformer | Thoughtbubbles |
|----------|------------------|-------------------|----------------|
| Форма рассуждений | Явная (текст) | Неявная (латентные переменные) | Неявная (латентное пространство) |
| Параллелизм | Нет (последовательно) | Частичный (скрытая структура) | Да (динамические разветвления) |
| Надзор при обучении | Требуется (CoT-обучающие данные) | Минимальный | Только языковое моделирование |
| Эффективность вычислений | Стандартная | Повышенная | Максимальная |
| Интеграция в архитектуру | Через промпты | Архитектурное изменение | Архитектурное изменение |
| Интерпретируемость | Высокая (текс) | Средняя (латентные переменные) | Низкая (внутренние потоки) |
| Эффективность масштабирования | Умеренная | Высокая | Очень высокая |
| Адаптация вычислительного бюджета | Нет | Частичная | Полная (на уровне токенов) |

## Переход от явных к неявным рассуждениям

Всё три подхода представляют эволюцию от явных внешних рассуждений (CoT) к внутренним неявным процессам (Free Transformer и Thoughtbubbles):

1. **Chain-of-Thought**: Рассуждения как внешняя последовательность токенов
2. **Free Transformer**: Рассуждения как латентная структура
3. **Thoughtbubbles**: Рассуждения как динамические параллельные процессы в латентном пространстве

## Связь с другими темами

- [[chain_of_thought.md]] - традиционный подход к рассуждениям в LLM
- [[free_transformer.md]] - подход с использованием латентных переменных
- [[thoughtbubbles.md]] - современный подход с параллельными рассуждениями
- [[reasoning_patterns.md]] - обзор различных паттернов рассуждений
- [[latent_variables_reasoning.md]] - использование латентного пространства для рассуждений