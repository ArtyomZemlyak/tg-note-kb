# Методы генерации текста в LLM

## Общее описание

Методы генерации текста в больших языковых моделях (LLM) определяют, как модель создает выходной текст на основе входного контекста. Различные подходы имеют разные компромиссы между скоростью, качеством и вычислительной эффективностью.

## Классификация методов

### Авторегрессивные методы (Autoregressive Models)

- **Принцип работы**: Генерация текста по одному токену за раз, каждый токен зависит от всех предыдущих
- **Примеры**: GPT, LLaMA, OPT, BLOOM
- **Преимущества**: Высокое качество, согласованность, детерминированная генерация
- **Ограничения**: Последовательный процесс, медленная генерация, особенно для длинных последовательностей

### Невавторегрессивные методы (Non-autoregressive Models)

- **Принцип работы**: Генерация всей последовательности за один или несколько параллельных шагов
- **Примеры**: FastBERT, CMLM (Conditional Masked Language Model)
- **Преимущества**: Значительное ускорение за счет параллелизма
- **Ограничения**: Сложность обучения, потенциально меньшее качество, проблемы с согласованностью

### Гибридные методы

- **Принцип работы**: Комбинирование преимуществ авторегрессивных и невавторегрессивных подходов
- **Примеры**: 
  - [[speculative_decoding.md]] - Использование помощника для предсказания токенов, проверяемых основной моделью
  - [[planned_diffusion.md]] - Объединение AR-планирования с параллельной диффузионной генерацией
- **Преимущества**: Баланс между скоростью и качеством
- **Ограничения**: Сложность реализации, необходимость синхронизации между компонентами

### Диффузионные методы

- **Принцип работы**: Генерация текста через постепенный процесс денойзинга, начиная с случайного шума
- **Примеры**: Masked Diffusion, Discrete Diffusion
- **Преимущества**: Возможность параллельной генерации, контроль над процессом
- **Ограничения**: Необходимость нескольких итераций, сложность для дискретных данных

## Сравнение методов

| Метод | Скорость | Качество | Параллелизм | Сложность |
|-------|----------|----------|-------------|-----------|
| Авторегрессивный | Низкая | Высокое | Нет | Средняя |
| Невавторегрессивный | Высокая | Ниже | Да | Высокая |
| Гибридный | Средняя-Высокая | Высокое | Частичный | Высокая |
| Диффузионный | Средняя | Средняя-Высокое | Да | Высокая |

## Современные тенденции

- Развитие гибридных подходов для оптимизации компромисса скорость-качество
- Интеграция различных методов в единую архитектуру
- Оптимизация для специфических задач и аппаратных платформ
- Автоматический выбор метода генерации в зависимости от контекста

## Связи с другими темами

- [[planned_diffusion.md]] - Пример гибридного подхода, объединяющего AR и диффузионные методы
- [[diffusion_llm_architectures.md]] - Диффузионные архитектуры для генерации текста
- [[inference_optimization/index.md]] - Оптимизация инференса, включая методы генерации
- [[llm_architectures_comparison.md]] - Сравнение архитектур, включающее методы генерации