# Приращение класса (Class-Incremental Learning)

## Определение

Приращение класса (class-incremental learning) - это сценарий машинного обучения, при котором модель последовательно изучает новые классы, не имея доступа к данным предыдущих задач. Это особенно проблематично из-за катастрофического забывания, так как модель может утратить способность распознавать старые классы при изучении новых.

## Проблема

Основная проблема приращения класса заключается в катастрофическом забывании - тенденции искусственных нейронных сетей резко и радикально забывать предыдущую информацию после изучения новой информации. Это серьезная проблема для непрерывного обучения, когда модели должны изучать новые задачи или классы без потери знаний, полученных ранее.

## Подходы к решению

### Методы воспроизведения опыта (Experience Replay)
- **Суррогаты (Exemplars)**: относительно небольшое количество объектов "предыдущих" классов, которое сохраняется на память
- **Псевдо-воспроизведение (Pseudo-rehearsal)**: сеть обучается на сгенерированных внутренних представлениях предыдущих данных, а не на оригинальных данных
- **Генеративное воспроизведение (Generative replay)**: использование глубоких генеративных моделей для создания "псевдо-данных" для повторного обучения

### Архитектурные методы
- **Модульное расширение (Modular expansion)**: добавление новых компонентов архитектуры для новых задач
- **Memo (MEmory and MOdular expansion)**: комбинация сохраненных экземпляров и расширения архитектуры нейронной сети
- **Прогрессивные нейронные сети**: добавление новых столбцов для новых задач при сохранении старых знаний

### Регуляризационные методы
- **Упругая консолидация весов (Elastic Weight Consolidation, EWC)**: метод, который предполагает, что некоторые веса нейронной сети более важны для предыдущих задач, чем другие. Изменения важных весов ограничиваются во время обучения новым задачам
- **Ортогональность**: создание ортогональных (перпендикулярных) векторов для представления разных задач, что уменьшает интерференцию

## Сравнение с другими задачами ML

- **Традиционное обучение**: модель получает доступ ко всем классам сразу
- **Приращение задачи (Task-incremental learning)**: модель знает, к какой задаче относится каждый образец
- **Приращение домена (Domain-incremental learning)**: модель изучает один и тот же набор классов в разных доменах

## Примеры применения

- Непрерывное обучение роботов в новых условиях
- Обновление систем распознавания изображений с новыми категориями
- Адаптация языковых моделей к новым задачам без потери предыдущих знаний

## Связи с другими темами

- [[../catastrophic_forgetting/catastrophic_forgetting.md]] - Катастрофическое забывание: основная проблема приращения класса
- [[memo_2022.md]] - Memo: один из современных методов решения задачи
- [[../regularization/elastic_weight_consolidation.md]] - EWC: регуляризационный подход к решению катастрофического забывания
- [[../rehearsal/experience_replay.md]] - Методы воспроизведения опыта как альтернативный подход
- [[../plasticity/loss_of_plasticity.md]] - Потеря пластичности: проблема, проявляющаяся в приращении класса
- [[../plasticity/dormant_units.md]] - Спящие юниты: механизм потери пластичности
- [[../plasticity/continual_backpropagation.md]] - Continual Backpropagation: метод решения проблемы потери пластичности