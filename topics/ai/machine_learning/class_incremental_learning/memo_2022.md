# Memo [2022] - Инъекция пластичности с помощью расширения нейронных сетей

## Описание подхода

Memo (MEmory and MOdular expansion) - это метод решения проблемы катастрофического забывания в задаче приращения класса (class-incremental learning), предложенный в 2022 году. Подход использует комбинацию сохраненных экземпляров и хирургические манипуляции с архитектурой нейронной сети для инъекции пластичности.

## Проблема

В задаче приращения класса модель обучается новым классам постепенно, без доступа к данным предыдущих задач. При этом происходит катастрофическое забывание - знания о старых классах вытесняются знаниями о новых. 

## Решение DER

Прежде чем описывать Memo, следует понять предшествующую работу DER (Dark Experience Replay, 2021):
- Для каждой новой пачки классов создается новая нейросеть, которая превращает объект в эмбеддинг
- Все предыдущие нейросети сохраняются и замораживаются
- Конкатенация всех эмбеддинговых моделей подается в новый обучаемый линейный слой, который выдает финальные вероятности
- Эта архитектура обучаеся предсказывать правильный ответ на сохраненных экземплярах и на новых классах
- Проблема DER: создание новых моделей дорого по памяти

## Подход Memo

Авторы Memo задались вопросом: действительно ли все слои эмбеддинг-модели нужно создавать заново?

Проведя эксперименты, они подтвердили известное представление о том, что:
- Первые слои моделей учат более общие представления
- Специализация в конкретные классы начинается в конце модели

### Основная идея

Memo предполагает:
- Продолжать использовать одни и те же первые слои моделей
- Создавать новые куски только для последних слоев в эмбеддинг-модели
- Это позволяет сэкономить память по сравнению с DER

### Замораживание слоев

Вопрос о том, какие куски модели замораживать, зависит от начальных условий:
- Если модель была предобучена на большом количестве классов: первые слои нужно сразу заморозить
- Если предобучения не было: нужно продолжать их доучивать
- Замораживать старые последние слои нужно всегда

## Экспериментальные результаты

По замерам авторов и обзора, Memo обгоняла всех конкурентов в 2022-2023 годах при фиксированном бюджете памяти, хотя разница с DER была не очень большой. Это означает, что потенциал до сих пор не исчерпан.

## Сравнение с другими методами

Memo отличается от других подходов к решению катастрофического забывания тем, что:
- Использует расширение архитектуры нейронной сети (модульное расширение)
- Комбинирует подход с сохраненными экземплярами с хирургическими манипуляциями с моделью
- Более эффективно использует память по сравнению с полным созданием новых эмбеддинг-моделей

## Связи с другими темами

- [[../catastrophic_forgetting/catastrophic_forgetting.md]] - Катастрофическое забывание: проблема, которую решает Memo
- [[../class_incremental_learning/class_incremental_learning.md]] - Общая постановка задачи приращения класса
- [[../regularization/elastic_weight_consolidation.md]] - EWC: другой подход к решению катастрофического забывания
- [[../rehearsal/experience_replay.md]] - Методы воспроизведения опыта как альтернативный подход