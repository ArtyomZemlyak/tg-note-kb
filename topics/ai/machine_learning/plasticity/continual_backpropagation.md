# Continual Backpropagation

## Определение

Continual Backpropagation - это метод непрерывного обучения, предложенный для решения проблемы потери пластичности в глубоких нейронных сетях. Метод направлен на поддержание способности сети к обучению новой информации, предотвращая появление спящих юнитов.

## Принцип работы

### Функция полезности (Utility Function)
- Для каждого нейрона вычисляется его "вклад" в следующие слои
- Это сумма выходных весов, умноженная на выход нейрона
- Используется скользящее среднее для усреднения по времени

### Переинициализация юнитов
- На каждом шаге определяется доля юнитов с наименьшей полезностью
- Эти юниты переинициализируются: входные веса из шума, выходные веса в нули
- Переинициализированным юнитам предоставляется иммунитет на 100 шагов

### Параметры метода
- Доля пересоздаваемых юнитов мала - всего 10^-5 от всех юнитов за шаг
- Малая доля позволяет эффективно поддерживать пластичность без значительных издержек

## Преимущества

- Полностью решает проблему потери пластичности на задаче class-incremental CIFAR-100
- Поддерживает долю спящих юнитов близкой к нулю
- Требует минимальных вычислительных ресурсов благодаря низкой доле переинициализации

## Ограничения

- Метод может казаться "бесплатным обедом", но на самом деле потребляет часть ресурсов, которые ранее простаивали
- На более сложных задачах эффективность может снижаться, и большая часть ресурсов может выбрасываться в мусор

## Сравнение с другими методами

- В отличие от "Shrink and Perturb", который использует L2-регуляризацию и зашумление, Continual Backpropagation применяет более точечный подход
- Более эффективен при борьбе со спящими юнитами, чем общие методы регуляризации

## Связи с другими темами

- [[loss_of_plasticity.md]] - Потеря пластичности: проблема, которую решает метод
- [[dormant_units.md]] - Спящие юниты: объект воздействия метода
- [[../class_incremental_learning/class_incremental_learning.md]] - Сценарий применения метода