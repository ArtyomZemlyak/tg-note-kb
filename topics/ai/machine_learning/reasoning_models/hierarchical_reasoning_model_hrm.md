# Иерархическая Модель Рассуждения (Hierarchical Reasoning Model, HRM)

## Описание

Иерархическая Модель Рассуждения (HRM) - это архитектура нейронной сети, предложенная в 2025 году, которая пытается имитировать способность человеческого мозга оперировать на разных временных масштабах. Модель состоит из двух компонентов: "медленной" и "быстрой" сети, которые должны работать с разной частотой и отвечать за различные уровни планирования и обработки.

## Архитектура

### Двухуровневая структура
- **Быстрая сеть**: Применяется чаще, обрабатывает детали
- **Медленная сеть**: Применяется реже, отвечает за "глобальное" планирование

### Скрытые состояния
- HRM использует два скрытых состояния, которые обновляются двумя разными трансформерами
- "Быстрая сеть" берет быстрое состояние, медленное состояние и эмбеддинги входа для обновления быстрого состояния
- Раз в T шагов "медленная сеть" обновляет медленное состояние, используя оба состояния

### Процесс выполнения
- "Forward pass" состоит из N * T шагов
- После N * T шагов модель преобразует медленное состояние в выходное предсказание
- Также включает обучаемый модуль, основанный на Q-learning, который может преждевременно остановить выполнение, если решение найдено быстрее

## Метод градиентной аппроксимации

### Проблема
Авторы утверждают, что прямая передача градиентов через всю схему требует много памяти и вычислительных ресурсов.

### Решение
- Вместо полной передачи градиентов предложена 1-step градиентная аппроксимация
- Градиенты текут только во время последнего шага, а все предыдущие состояния рассматриваются как константы
- Авторы утверждают, что это позволяет сэкономить память и время без потери качества

## Критика и ограничения

### Проблема с экспериментальными параметрами
- **Ключевая проблема**: Во всех экспериментах использовалось N=2, T=2
- Это означает, что одна итерация HRM включает всего 6 вызовов трансформера (4 вызова модели в цикле + 2 дополнительных)
- Вся сложная "иерархическая" схема на практике почти не используется

### Сравнение с базовыми моделями
- Анализы показали, что регулярный трансформер, применяемый такое же количество раз, дает почти такой же результат
- Улучшение производительности достигается за счет многократного применения модели, а не за счет иерархической структуры
- "Мишура" с иерархичностью не дает значительного практического преимущества

### Недостатки метода аппроксимации
- Схема 1-step градиентной аппроксимации вызывает сомнения в корректности обучения
- Отсутствует объективный анализ влияния разных значений N и T на результат
- Вместо анализа эффективности схемы авторы представили подгон под анализ работы мозга мыши

## Практическая значимость

### Преимущества
- Концептуальная модель для многоуровневого рассуждения
- Попытка решения задач иерархического планирования в ИИ

### Недостатки
- Ограниченная практическая польза при реализации
- Отсутствие доказательств преимущества иерархической структуры над простым повторением
- Недостаточный анализ параметров и эффективности метода

## Связи с другими темами

- [[../llm/llm_memory_overview.md]] - Сравнение архитектур с памятью
- [[../plasticity/continual_backpropagation.md]] - Альтернативные методы передачи градиентов
- [[../../nlp/models/speech_recognition.md]] - Применение трансформеров в различных задачах
- [[../../agents/planact_approach.md]] - Подходы к планированию в ИИ-агентах