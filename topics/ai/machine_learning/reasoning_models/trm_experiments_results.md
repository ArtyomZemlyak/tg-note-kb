# Эксперименты и результаты TRM

## Общая информация

Эксперименты для TRM проводились на тех же задачах, что и для HRM:
- ARC-AGI-1 и ARC-AGI-2
- Sudoku-Extreme
- Maze-Hard

## Подробные результаты

### Sudoku-Extreme
- Обучение: 1000 примеров
- Тестирование: 423,000 примеров
- Результаты:
  - Версия с attention: 74.7%
  - Версия с MLP: 87.4%
  - Для сравнения, HRM: 55%

### Maze-Hard
- Обучение: 1000 примеров
- Тестирование: 1000 примеров
- Результаты:
  - Версия с attention: 85.3%
  - Версия с MLP: 0% (почему-то нулевой результат)
  - Для сравнения, HRM: 74.5%

### ARC-AGI-1 (2025)
- Использовался датасет ConceptARC для аугментации
- Результаты:
  - Версия с attention: 44.6%
  - Версия с MLP: 29.6%
  - Для сравнения, HRM: 40.3%

### ARC-AGI-2 (2025)
- Использовался датасет ConceptARC для аугментации
- Результаты:
  - Версия с attention: 7.8%
  - Версия с MLP: 2.4%
  - Для сравнения, HRM: 5.0%

## Практические наблюдения

### Зависимость от архитектуры
- Для судоку лучше работает версия с MLP (87.4%)
- Для других задач (требующих большего контекста) лучше работает версия с attention (85.3% для лабиринтов, 44.6% для ARC-AGI-1)
- Это объясняется тем, что MLP лучше справляется с локальными зависимостями (как в судоку), а attention - с глобальным контекстом (как в логических головоломках)

### Размеры моделей
- Версия TRM с attention: 7M параметров
- Версия TRM с MLP: 5M параметров для Sudoku и 19M для остальных задач
- HRM всегда была 27M параметров

### Временные затраты
- TRM требует больше времени выполнения из-за рекурсии, несмотря на меньший размер
- Возможно, лучшие результаты обусловлены не только архитектурой, но и большим количеством FLOPS за счёт рекурсии

## Проверка ARC-AGI
Результаты для TRM на ARC-AGI были проверены командой ARC-AGI:
- ARC-AGI-1: 40%, $1.76/task
- ARC-AGI-2: 6.2%, $2.10/task

Разброс между статьей и измерениями ARC меньше, чем был у HRM, что указывает на более стабильные результаты.

## Эксперименты, которые не сработали

### Модификации архитектуры
- **Замена SwiGLU MLP на SwiGLU MoE** - общая обобщающая способность ухудшилась, возможно, на большем количестве данных результат был бы лучше
- **Ограниченное распространение градиентов** - например, только через последние 4 шага - никак не помогло, только усложнило
- **Удаление ACT** - всё ухудшило
- **Общие веса для эмбеддингов входа и выхода** - всё ухудшили
- **Замена рекурсии на fixed-point iteration из TorchDEQ** - замедлило и ухудшило, подтверждая, что сходимость к неподвижной точке не важна

### Изменение количества слоев
- **Добавление слоёв** - приводит к переобучению несмотря на увеличенную эффективную глубину
- **Уменьшение до 2 слоев** - оказалось оптимальным решением, дав улучшение на Sudoku-Extreme с 79.5% до 87.4%

## Вычислительные требования

- Время обучения: от <24 часов до примерно 3 дней максимум на 4×H100
- Требования к GPU: от 1 L40S до 4 H-100 в зависимости от задачи
- TRM требует больше времени выполнения из-за рекурсии, но меньше параметров

## Сравнение с другими работами

TRM демонстрирует архитектурную изобретательность в противовес постоянному масштабированию моделей, что является интересным направлением исследований. Результаты показывают, что эффективная архитектура может превзойти более крупные модели, что ставит под сомнение подход "больше значит лучше".

## Связанные темы
- [[tiny_recursive_model_trm.md]] - Основная информация о TRM
- [[trm_vs_hrm_comparison.md]] - Сравнение с HRM
- [[trm_architecture.md]] - Архитектура TRM
- [[less_is_more_philosophy.md]] - Философия "меньше значит больше" в архитектурах ИИ
- [[../../ai_contests/arc_prize/arc_prize_overview.md]] - Соревнование ARC-AGI, где тестировалась TRM