# Обучение с малым количеством примеров (Few-Shot Learning)

## Краткое описание

Обучение с малым количеством примеров (Few-Shot Learning) - это подход в машинном обучении, при котором модели обучаются на очень ограниченном количестве примеров для каждой задачи. Это контрастирует с традиционным машинным обучением, которое требует большого количества данных для каждой задачи. Few-shot learning тесно связан с мета-обучением, так как часто использует идеи "обучения обучению" для быстрой адаптации к новым задачам.

## Основная информация

Few-shot learning решает задачу, аналогичную той, с которой сталкиваются люди: способность быстро изучать новые понятия с минимальным количеством примеров. В few-shot learning модель обучается на наборе задач во время мета-обучения и затем тестируется на новых задачах с небольшим количеством поддержки (support examples).

## Терминология

- **N-way**: Классификация между N различными классами
- **K-shot**: Использование K примеров для каждого класса
- **Query**: Примеры, которые нужно классифицировать на основе K-shot обучающих примеров
- **Episode**: Один цикл обучения на одной задаче few-shot

## Основные подходы

### 1. Метрика-ориентированные методы

#### Matching Networks
- Используют задаче-специфичные веса для каждого тестового примера
- Применяют отношение внимания между обучающими и тестовыми примерами
- Комбинируют информацию от обучающих примеров через взвешенную сумму их меток

#### Prototypical Networks
- Для каждого класса вычисляют прототип как среднее векторов обучающих примеров
- Классифицируют тестовые примеры по ближайшему прототипу
- Используют метрику Евклидова расстояния в пространстве признаков

#### Relation Networks
- Обучают метрику, которая может определять отношения между парой изображений
- Используют сиамскую архитектуру для извлечения признаков
- Сравнивают тестовые примеры с обучающими примерами через обученную функцию отношения

### 2. Оптимизация-ориентированные методы

#### Model-Agnostic Meta-Learning (MAML)
- Обучает инициализацию модели, которая может быстро адаптироваться к новым задачам
- Использует градиентную оптимизацию для быстрой адаптации
- Применим к различным архитектурам (классификация, регрессия, RL)

#### Meta-Learning with Latent Embedding Optimization (LEO)
- Вводит вариационный подход к обучению инициализации
- Работает в пространстве низкой размерности для лучшей обобщающей способности
- Использует автокодировщик для обучения представлений параметров

### 3. Память-ориентированные методы

#### Memory-Augmented Neural Networks (MANN)
- Используют внешнюю память для хранения и извлечения информации
- Обучают, когда и как читать/писать в память
- Применимы к задачам с изменяющимся количеством обучающих примеров

## Применения в различных доменах

### Компьютерное зрение
- Классификация изображений с малым количеством примеров
- Обнаружение объектов на новых классах
- Сегментация изображений

### Обработка естественного языка
- Классификация текстов с ограниченными примерами
- Генерация текста на новых задачах
- Анализ тональности

### Обучение с подкреплением
- Быстрая адаптация агентов к новым средам
- Few-Shot RL задачи
- Перенос знаний между задачами

## Отношение к мета-обучению

Few-shot learning и мета-обучение тесно связаны:
- Few-shot learning часто использует мета-обучение для получения обобщаемых знаний
- Мета-обучение предоставляет рамки для few-shot задач
- Оба подхода фокусируются на быстрой адаптации к новым задачам

## Преимущества

- **Эффективность данных**: Может обучаться на очень ограниченных данных
- **Обобщение**: Хорошая способность к переносу знаний
- **Быстрая адаптация**: Быстрая настройка под новые задачи
- **Биологическая правдоподобность**: Более похожа на человеческое обучение

## Ограничения

- **Сложность обучения**: Требуется сложный мета-обучающий процесс
- **Чувствительность к домену**: Работает лучше, когда обучающие и тестовые задачи связаны
- **Масштабируемость**: Сложность применения к сложным задачам
- **Вычислительные требования**: Высокие требования к вычислениям при мета-обучении

## Оценка производительности

- **Accuracy**: Стандартная метрика для задач классификации
- **N-way K-shot**: Стандартная схема тестирования (например, 5-way 1-shot)
- **Cross-domain evaluation**: Тестирование на задачах из других доменов

## Будущие направления

- **Zero-shot learning**: Возможность решения задач без обучающих примеров
- **Cross-modal few-shot learning**: Обучение с примерами из разных модальностей
- **Causal few-shot learning**: Включение причинно-следственных связей для лучшей обобщаемости
- **Continual few-shot learning**: Комбинация few-shot и непрерывного обучения

## Связи с другими темами

- [[meta_learning.md]] - Основная концепция мета-обучения, на которой основан few-shot learning
- [[learning_to_learn.md]] - Общая концепция "обучения обучению"
- [[meta_rl.md]] - Применение few-shot learning к обучению с подкреплением
- [[continual_learning/index.md]] - Связь с непрерывным обучением
- [[transfer_learning.md]] - Отношение к переносу знаний между задачами
- [[automl.md]] - Автоматическая настройка моделей для few-shot задач
- [[domain_adversarial_training.md]] - Альтернативный подход к адаптации моделей к новым доменам через доменно-инвариантные признаки

## Ссылки на источники

- Lake, B. M., et al. (2015). Human-level concept learning through probabilistic program induction
- Vinyals, O., et al. (2016). Matching Networks for One Shot Learning
- Snell, J., et al. (2017). Prototypical Networks for Few-shot Learning
- Finn, C., et al. (2017). Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks