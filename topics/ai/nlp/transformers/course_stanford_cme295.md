# Курс Stanford CME 295 - Трансформеры и Большие Языковые Модели (Transformers & Large Language Models)

## Общее описание

CME 295 - это курс в Стэнфорде, посвящённый миру трансформеров и больших языковых моделей (LLM). Курс охватывает эволюцию методов обработки естественного языка (NLP), основные компоненты архитектуры трансформеров, а также их связь с LLM и методы повышения производительности моделей для реальных приложений.

## Темы курса

Курс охватывает следующие ключевые темы:

1. **Эволюция методов NLP** - переход от традиционных подходов к современным трансформерам
2. **Архитектура трансформеров** - основные компоненты и принципы работы
3. **Связь с LLM** - как трансформеры связаны с большими языковыми моделями
4. **Повышение производительности** - методы улучшения работы моделей для реальных приложений

## Требования

- Знание математического анализа
- Знание линейной алгебры
- Базовые понятия машинного обучения

## Практическая ценность

Через сочетание теории и практических рекомендаций, курс оснащает слушателей знаниями, необходимыми для эффективного использования LLM. Курс идеально подходит для тех, кто обладает базовыми знаниями в области исчисления, линейной алгебры и основ машинного обучения.

## Ссылки

- [Официальный сайт курса](https://cme295.stanford.edu)
- [Программа курса (syllabus)](https://cme295.stanford.edu/syllabus/)

## Связи с другими темами

- [[transformer_architecture.md]] - подробное описание архитектуры трансформеров
- [[evolution_of_nlp_methods.md]] - эволюция методов NLP
- [[transformers_and_llms.md]] - связь трансформеров с LLM
- [[../../llm/llm_memory_systems/llm_memory_overview.md]] - архитектура трансформеров в контексте систем памяти LLM
- [[../../machine_learning/machine_learning.md]] - основы машинного обучения, на которых строятся трансформеры