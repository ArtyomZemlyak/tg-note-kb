# MemWalker: Обход лабиринта памяти для работы с длинными контекстами

## Описание

MemWalker - это метод, разработанный для преодоления ограничений контекста в трансформерах при обработке длинных входных последовательностей. Метод был предложен в статье "Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading" (Howard Chen, Ramakanth Pasunuru, Jason Weston, Asli Celikyilmaz, 2023).

## Проблема

Трансформеры имеют ограничения по длине контекста, что не позволяет им эффективно обрабатывать длинные тексты. Существующие подходы включают:
- Увеличение размера контекстного окна
- Модификации механизма внимания (разреженное, линейное внимание)
- Введение рекуррентности
- Retrieval-augmented модели
- Агентные подходы с итеративным промптингом

## Решение: Двухэтапный процесс

### Этап 1: Построение дерева памяти

- Длинная входная последовательность разбивается на фрагменты, помещающиеся в контекст модели
- Каждый фрагмент суммаризируется в текст (саммари)
- Несколько саммари объединяются в саммари следующего уровня
- Создается иерархическая древесная структура
- Дерево строится независимо от запроса, может быть вычислено заранее

Для генерации саммари используются два типа промптов:
- Для листьев (фрагменты текста)
- Для узлов (объединение нескольких саммари)

### Этап 2: Навигация по дереву

- При получении запроса, MemWalker проходит по дереву в поисках релевантной информации
- Начинает с корня дерева
- Использует два типа промптов:
  - **Leaf prompt**: Для обработки листьев дерева (фрагментов текста)
  - **Triage prompt**: Для принятия решений на узлах (какой из дочерних узлов наиболее релевантен)
- В каждом узле LLM получает саммари из всех дочерних узлов и решает, в каком фрагменте наиболее вероятно содержится ответ на вопрос
- Используется Chain-of-Thought (CoT) рассуждение: "Сначала приведите рассуждения для сравнения саммари, прежде чем принимать решение"
- По мере навигации поддерживается рабочая память, которая добавляется в промпт для листьев
- Когда накапливается достаточно информации, генерируется ответ

## Особенности реализации

- Ответы генерируются в определенном формате
- Если LLM не может сгенерировать ответ в нужном формате, запрашивается перегенерация
- Если не удается три раза подряд, навигация прерывается с "no answer"
- Требуется отслеживание посещенных узлов, чтобы избежать зацикливания
- Если дошли до листа дерева, модель либо принимает его и отвечает, либо откатывается к родительскому узлу

## Эксперименты и результаты

- Проверка точности (accuracy) на трех датасетах: QuALITY, SummScreenFD, GovReport из бенчмарка SCROLLS
- QuALITY - датасет для ответов на вопросы с множественным выбором по длинным текстам из Project Gutenberg
- Описаны ограничения: логика оркестровки процесса описана плохо, много неявных допущений, работа не воспроизводима в чистом виде

## Сравнение с другими подходами

MemWalker отличается от других методов тем, что:
- Использует иерархическую структуру дерева для представления информации
- Применяет интерактивное чтение с активным поиском по дереву
- Использует LLM для принятия решений о навигации на каждом уровне

## Связи с другими темами

- [[sparse_attention.md]] - Разреженное внимание как альтернативный подход к решению проблемы длинных контекстов
- [[linear_attention.md]] - Линейное внимание как метод уменьшения вычислительной сложности
- [[retrieval_augmented_generation.md]] - Retrieval-augmented модели как альтернативный подход
- [[hierarchical_reasoning_model_hrm.md]] - Иерархические подходы к рассуждению
- [[llm_memory_overview.md]] - Обзор систем памяти в LLM
- [[mamba_architecture.md]] - Альтернативный подход к обработке длинных последовательностей с линейной сложностью
- [[specialized_attention_mechanisms.md]] - Обзор различных механизмов внимания для эффективной обработки длинных контекстов
- [[llm_long_term_memory.md]] - Системы долгосрочной памяти для LLM
- [[star_attention_mechanism.md]] - Механизм разреженного внимания для эффективного инференса с длинными контекстами