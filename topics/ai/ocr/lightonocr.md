# LightOnOCR-1B

## Описание

LightOnOCR-1B - компактная, полностью дифференцируемая визуально-языковая модель (VLM) для оптического распознавания символов (OCR) и понимания документов. Модель сочетает в себе высокопроизводительный энкодер Vision Transformer с легковесным текстовым декодером, дистиллированным из высококачественных открытых VLM. Модель оптимизирована для задач парсинга документов, обеспечивая точное извлечение текста с сохранением компоновки из высокоразрешающих страниц.

## Технические характеристики

- **Архитектура**: Vision Transformer энкодер с легковесным текстовым декодером
- **Подход**: Полностью дифференцируемый конвейер (End-to-end, fully differentiable), без внешнего OCR-конвейера
- **Формат файлов**: Safetensors
- **Языки**: Поддержка 9 языков
- **Варианты моделей**:
  - LightOnOCR-1B-1025 (Полная многоязычная модель)
  - LightOnOCR-1B-32k (32k токенов, оптимизирована для европейских языков)
  - LightOnOCR-1B-16k (Наиболее компактный вариант)
  - LightOnOCR-0.9B-32k-1025 (Модель 0.9B с 32k словарем)
- **Обучение**: Обучение на разнообразном крупномасштабном корпусе PDF, включая научные статьи, книги, квитанции, счета, таблицы, формы и рукописный текст на нескольких языках
- **Базовая модель**: Использует архитектуру mistral3
- **Фреймворк**: Поддержка vLLM для инференса

## Производительность

### Качество (Olmo-Bench):
- Превосходит DeepSeekOCR
- Сопоставима с dots.ocr (при этом модель в 3 раза меньше по весу)
- +16 очков к Qwen3-VL-2B-Instruct
- Показывает передовые результаты на своем уровне веса при этом в несколько раз быстрее и дешевле, чем более крупные VLM общего назначения

### Скоростные характеристики:
- Обрабатывает 5.71 страницы в секунду на одном GPU H100
- Примерно 493 000 страниц в день
- В 6.49 раза быстрее, чем dots.ocr
- В 2.67 раза быстрее, чем PaddleOCR-VL-0.9B
- В 1.73 раза быстрее, чем DeepSeekOCR

### Стоимость:
- Менее $0.01 за 1000 страниц по текущим ценам на облачные вычисления

## Процесс обучения

### Датасет:
- **Размер**: 17.6 миллионов страниц и 45.5 миллиардов токенов
- **Источник**: Крупномасштабный корпус PDF, обработанный в родном разрешении
- **Курирование**: Дистилляция знаний с использованием Qwen2-VL-72B-Instruct в качестве учительской модели
- **Формат**: Markdown с LaTeX-нотацией (предпочтительнее HTML для эффективности токенов)
- **Контроль качества**: Комплексный нормализационный конвейер для замкнутых циклов, дедупликации, фильтрации галлюцинаций

### Подход к обучению:
- Дистилляция знаний из более крупных визуально-языковых моделей
- Обучение в один этап (двухэтапный подход оказался ненужным)
- Полное сквозное обучение без замораживания компонентов
- Без специальной дообучки под бенчмарки

### Исследование качества аннотаций:
- Более крупные учителя (72B) значительно превосходят меньших (7B)
- Улучшение на 11.8 пунктов при использовании 72B против 7B учительской модели
- Прирост производительности особенно заметен на сложных макетах (многостолбцовые, математическое содержание, таблицы)

## Применение

### Основные приложения:
- Понимание документов и OCR
- Извлечение информации
- Решения RAG (Retrieval-Augmented Generation)
- Обработка сложных макетов (таблицы, формы, уравнения, научная нотация)
- Многостолбцовые документы с мелким текстом
- Страницы с математическими формулами и старые сканированные документы

### Целевые сценарии:
- Обработка документов в большом объеме
- Стоимостно-эффективные OCR-приложения
- Специализированные области документооборота
- Приложения, требующие быстрого инференса
- Полностраничная транскрипция (включая заголовки и колонтитулы)

### Возможности дообучения:
- Простая адаптация к специфическим доменам, макетам или языкам
- Продемонстрированное улучшение на +9.0% в целом по OlmOCR-mix после одной эпохи дообучения
- Значительное улучшение заголовков и колонтитулов (с 40.0% до 91.3%)

## Ключевые преимущества

- Полностью сквозная обучаемость (в отличие от сложных многоступенчатых конвейеров)
- Стоимостная эффективность и энергоэффективность
- Простое тонкое настраивание для новых доменов/языков
- Превосходное соотношение производительности к размеру
- Открытый исходный код и коммерчески применим
- Высокая пропускная способность с интеграцией vLLM
- Обработка таблиц, форм, уравнений и сложных макетов
- Высокая точность при сравнительно малом размере модели

## Сравнение с другими моделями

- **LightOnOCR-1B** был дистиллирован из **Qwen2-VL-72B-Instruct**, что делает его примером эффективной трансфера знаний от более крупной модели
- По сравнению с DeepSeek OCR: лучше по качеству, быстрее и дешевле
- Более компактный, чем Qwen3-VL-2B-Instruct, но с сопоставимой производительностью
- Превосходит другие специализированные OCR-модели по соотношению цена/качество

## Связи с другими темами

- [[object_detection_yolo_ocr.md]] - Общие сведения об OCR и его применении в системах компьютерного зрения
- [[deepseek_ocr.md]] - Другая современная модель OCR с высокой эффективностью обработки документов
- [[ai/llm/models/qwen/qwen-vl-series.md]] - Модель Qwen2-VL-72B-Instruct, использованная в качестве учителя при обучении LightOnOCR-1B
- [[ai/llm/models/qwen/vlm_models.md]] - Визуально-языковые модели, на основе которых создана LightOnOCR-1B
- [[docling.md]] - Библиотека обработки документов от IBM, альтернативное решение для обработки документов с похожими возможностями
- [[multimodal/ibm_granite_docling_258m.md]] - Мультимодельная модель IBM для преобразования документов, конкурентное решение для документооборота