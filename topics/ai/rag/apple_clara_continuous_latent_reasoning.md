# Apple CLaRa: Continuous Latent Reasoning в RAG-системах

## Обзор

CLaRa (Continuous Latent Reasoning) - это новая модель, разработанная Apple для RAG (Retrieval-Augmented Generation) с интегрированным сжатием документов. Основной особенностью CLaRa является то, что вместо помещения длинных документов в контекст, модель сжимает их в 16-128 раз и генерирует ответы напрямую из сжатого представления.

## Архитектура

CLaRa использует **трехэтапный подход к обучению** с непрерывным латентным рассуждением:

### Этап 1: Предобучение сжатия (Compression Pretraining)
- Использует фреймворк SCP (Salient Compressor Pretraining)
- Обучает сжиматель с использованием QA-пар и парафразов
- Сохраняет ключевые семантики через QA- и парафраз-ориентированное обучение
- Поддерживает степени сжатия от 1x до 256x

### Этап 2: Инструкционное тюнингование сжатия (Compression Instruction Tuning)
- Тонко настраивает сжиматель для задач инструкций по QA
- Использует текстовый QA-вывод для обеспечения того, чтобы сжатые представления содержали достаточную семантику

### Этап 3: Сквозная настройка (End-to-End Fine-tuning)
- Совместно обучает реранжировщик и генератор через единую функцию потерь моделирования языка
- Объединяет извлечение и генерацию в общем непрерывном пространстве с использованием дифференцируемого оценщика top-k
- Построена на основе фреймворка OpenRLHF

## Отличия от традиционных RAG-подходов

### Проблемы, которые решает CLaRa
- **Длинные контексты**: Традиционные RAG-модели сталкиваются с длинными контекстами, что увеличивает вычислительные издержки
- **Отдельная оптимизация извлечения-генерации**: Традиционные подходы имеют раздельную оптимизацию для извлечения и генерации
- **Избыточное кодирование**: Фреймворки с мягким сжатием требуют двойного кодирования, несмотря на то, что сжатые векторы поддаются извлечению
- **Смещение к поверхностным паттернам**: Целевые функции, основанные на реконструкции, смещают сжиматели в сторону поверхностных паттернов, а не семантического сохранения

### Решения CLaRa
- **Единое непрерывное пространство**: Использует дифференцируемую оценку top-k для объединения извлечения и генерации
- **Совместная оптимизация**: Сквозное обучение оптимизирует как извлечение, так и генерацию одновременно
- **Семантическое сохранение**: Помощь QA- и парафраз-ориентированного обучения сохраняет семантическую информацию, а не только поверхностные паттерны
- **Отсутствие избыточного кодирования**: Сжатые векторы сохраняют извлекаемость без двойного кодирования

## Механизм сжатия

- **Степени сжатия**: Достигает значительных степеней сжатия 32x-64x, при этом сохраняя необходимую информацию
- **Фреймворк SCP (Salient Compressor Pretraining)**: Использует QA-пары и парафразы для сохранения семантического содержания
- **MSE + QA Loss**: Комбинирует функцию потерь MSE для соответствия с исходными представлениями и QA-потерю для семантического сохранения
- **Непрерывное латентное пространство**: Поддерживает сжатую информацию в непрерывном пространстве, которое поддерживает как извлечение, так и генерацию

## Реализация и использование

### Доступные модели
- **CLaRa-7B-Instruct**: Инструкционно-настроенная унифицированная RAG-модель на базе Mistral-7B-Instruct-v0.2
- **Степени сжатия**: Поддерживает встроенное семантическое сжатие документов 16× и 128×

### Пример использования
```python
from transformers import AutoModel

unirag = AutoModel.from_pretrained(
    "/mnt/ceph_rbd/model/CLaRa-7B-Instruct/compression-16",
    trust_remote_code=True
).to("cuda")

documents = [
    [
        "Weldenia is a monotypic genus of flowering plant in the family Commelinaceae...",
        "Hagsatera is a genus of flowering plants from the orchid family...",
        "Alsobia is a genus of flowering plants in the family Gesneriaceae..."
    ]
]

questions = [
    "Which genus of plant grows originally in Mexico and Guatemala, Phylica or Weldenia?"
]

# Инструкционно-настроенное использование
out = unirag.generate_from_text(
    questions=questions,
    documents=documents,
    max_new_tokens=64
)

print("Сгенерированный ответ:", out)
```

### Ключевые детали реализации
1. **Способность к сжатию**: Модель включает встроенное семантическое сжатие документов на двух уровнях (16× и 128×)
2. **Интеграция RAG**: Унифицированная модель, объединяющая извлечение и генерацию с непрерывным латентным рассуждением
3. **Инструкционное тюнингование**: Специально обучена для выполнения инструкций и задач QA
4. **Загрузка модели**: Требует `trust_remote_code=True` при загрузке
5. **Метод**: Использует метод `generate_from_text()`, который принимает как вопросы, так и документы в качестве входных данных

## Производительность

### Результаты сжатия (Mistral-7B, нормальные настройки):
- **Конкурентоспособные результаты**: CLaRa (CR=4) достигает 39.86% средней производительности на 4 наборах данных (NQ, HotpotQA, MuSiQue, 2WikiMultiHopQA)
- **Превосходит базовые линии**: Превышает PISCO на +1.13% в нормальных настройках и +5.35% в oracle настройках в среднем
- **Лучше, чем LLMLingua-2**: Превосходит на +5.37% средний прирост в нормальных настройках
- **Сопоставимо с текстовыми базовыми линиями**: Достигает +2.36% среднего прироста на Mistral-7B

### Ключевые метрики производительности:
- **Эффективное сжатие**: 32x-64x сжатие при сохранении точности
- **Производительность на наборах данных**: Оценена на NQ, HotpotQA, MuSiQue и 2WikiMultiHopQA
- **Oracle vs Normal**: Протестирована как в oracle настройке (золотой документ включен), так и в нормальной настройке (топ-5 извлечённых документов)

## Поддерживаемые наборы данных
- HotpotQA: Ответы на вопросы с несколькими шагами (multi-hop)
- MuSiQue: Ответы на вопросы с несколькими шагами с разнообразным рассуждением
- 2WikiMultiHopQA: Ответы на вопросы с несколькими шагами по Википедии
- Natural Questions: Ответы на вопросы в открытом домене

## Связи с другими темами
- [[../llm/reasoning/latent_variables_reasoning.md]] - Использование латентных переменных для внутреннего формирования рассуждений, альтернатива явной цепочке рассуждений
- [[document_compression_techniques.md]] - Другие методы сжатия документов в RAG-системах
- [[../optimization/compress_to_impress_single_gradient_llm_adaptation.md]] - Метод Compress to Impress, связанный с градиентами сингулярных значений
- [[retrieval_strategies.md]] - Стратегии извлечения информации в RAG-системах

## Источники
1. [Apple CLaRa GitHub Repository](https://github.com/apple/ml-clara) - Официальный репозиторий с исходным кодом и технической документацией
2. [Apple CLaRa Hugging Face Model](https://huggingface.co/apple/CLaRa-7B-Instruct) - Модельный карточка с примерами использования
3. [CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning](https://arxiv.org/abs/2511.18659) - Оригинальная научная статья, описывающая архитектуру CLaRa
4. [Unifying Retrieval and Generation, Reasoning-Driven Cold Start](https://recsys.substack.com/p/unifying-retrieval-and-generation) - Обзорная статья о CLaRa