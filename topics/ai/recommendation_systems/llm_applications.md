# Применение LLM в рекомендательных системах

## Введение

Большие языковые модели (LLM) революционизировали подход к построению рекомендательных систем. В отличие от традиционных методов, основанных на факторизационных машинах, нейронных сетях и коллаборативной фильтрации, LLM могут использовать богатое семантическое понимание текста, контекста и сложных зависимостей между пользователями и предметами.

## Основные применения LLM в рекомендациях

### 1. Генерация кандидатов

LLM могут использоваться для:
- Прямого предсказания релевантных айтемов на основе истории пользователя
- Генерации новых кандидатов с учетом контекста
- Создания персонализированных рекомендаций на основе текстовых описаний

### 2. Ранжирование

LLM могут:
- Оценивать релевантность айтемов на основе сложных признаков
- Проводить многоуровневое ранжирование с учетом контекста, настроения и цели пользователя
- Учитывать сложные объяснения и обоснования для рекомендаций

### 3. Объяснение рекомендаций

LLM могут:
- Генерировать понятные объяснения для пользователей
- Объяснять логику выбора рекомендаций
- Обеспечивать прозрачность и доверие к системе

### 4. Диалоговые рекомендательные системы

LLM позволяют:
- Вести диалог с пользователем для уточнения предпочтений
- Уточнять запросы и персонализировать рекомендации в реальном времени
- Обрабатывать естественный язык и сложные запросы

## Преимущества LLM в рекомендательных системах

1. **Семантическое понимание**: LLM способны понимать смысл текста и контента
2. **Перенос знаний**: Возможность использовать знания, полученные на других задачах
3. **Объяснимость**: Возможность генерировать понятные объяснения
4. **Гибкость**: Возможность адаптации к новым доменам с минимальными изменениями
5. **Мультимодальность**: Возможность работы с разными типами данных

## Ограничения и вызовы

1. **Вычислительная сложность**: LLM требуют значительных вычислительных ресурсов
2. **Задержки**: Высокая латентность при генерации рекомендаций
3. **Расширение словаря**: Необходимость адаптации словаря LLM к предметной области
4. **Финтюнинг**: Требуется тщательная настройка под конкретные задачи
5. **Качество данных**: Зависимость от качества текстовых описаний

## Практические примеры

### OneRec-Think (Kuaishou)
- Использует Qwen-8B для генерации объяснений
- Фокусируется на логическом выводе (ризонинге)
- Генерирует траектории поведения пользователя
- Внедрение модели в оффлайне из-за вычислительной сложности ризонинга
- Рассуждающая модель в оффлайне генерирует несколько возможных траекторий (reasoning path) пользователя
- Для каждой траектории генерируется несколько возможных префиксов из 2-х SIDs
- Финальный сет всех возможных префиксов затем используется рантаймовой OneRec моделью для генерации итоговых рекомендаций

### PLUM (Google/YouTube)
- Использует Gemini-1.5-MoE-900M
- Обучается напрямую предсказывать будущие айтемы
- Учитывает рантаймовый контекст в промте
- Модель внедрена и в оффлайне, и в рантайме
- Количество dense параметров в трансформере у PLUM в 100 раз больше, чем у продового трансформера YouTube над пользовательской историей

### REGEN (Google)
- Диалоговые рекомендательные системы с генеративными нарративами
- Включает в себя две архитектуры: FLARE и LUMEN
- FLARE - гибридная система, сочетающая коллаборативную фильтрацию и языковые модели
- LUMEN - единая модель на основе LLM, способная к end-to-end обучению
- Использует семантические ID (SIDs) и генерирует контекстуальные нарративы о рекомендуемых товарах
- Включает в себя механизм понимания отзывов пользователей на естественном языке

## Архитектурные особенности LLM-рекомендательных систем

### Использование предобученных LLM

Обе компании (Google и Kuaishou) начинают с предобученных LLM:
- Google использует Gemini-1.5-MoE-900M
- Kuaishou использует Qwen-8B

### Семантические ID айтемов (SIDs)

Обе компании используют семантические ID как главное представление айтемов для модели:
- SIDs строятся на основе мульти-модальных контентных эмбеддингов айтемов
- Также используется коллаборативный сигнал из сервиса
- В обоих случаях рассматриваются видео-платформы

### Алайнмент семантических ID и языковых токенов

- Словарь LLM расширяется, чтобы включать каталог семантических ID айтемов
- Модель дообучается на задаче Next Token Prediction на текстах, описывающих:
  - Поведение действий пользователей
  - Сам каталог сервиса
- "Поведенческие" тексты интегрируют SIDs в текстовое описание действий пользователя
- Пример: "Пользователь <с такими фичами> лайкнул видео <SID-1><SID-2><SID-3> с заголовком <заголовок> и видео … с заголовком …"
- Также включается задача предсказания текстового описания айтема на основе его SIDs

### Обучение предсказанию рекомендуемых айтемов

- Модель обучают предсказывать семантические ID айтема, который стоит порекомендовать пользователю на основе истории его действий
- Это полностью заменяет современные рекомендательные трансформеры над пользовательскими историями
- Инференс аналогичен TIGER - последовательная генерация SIDs, beam search

### Отличия в подходах

#### Kuaishou (OneRec-Think)
- Весь файнтюн посвящает ризонингу (логическому выводу)
- Модель учат формулировать обоснование, почему пользователь после заданной истории взаимодействовал с конкретным айтемом
- Генерация обоснований нужна для улучшения качества самих рекомендаций, по аналогии с рассуждающими LLM

#### Google (PLUM)
- На этапе файнтюна учит именно предсказание будущих айтемов для пользователя
- Учитывает рантаймовый контекст в промте