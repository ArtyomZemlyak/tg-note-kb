# Генеративные модели поиска (Generative Retrieval Models) в рекомендательных системах

## Описание

Генеративные модели поиска - это подкатегория рекомендательных систем, в которой модели используют генеративные подходы для поиска и ранжирования кандидатов. В отличие от традиционных моделей, которые используют контрастивное обучение для сопоставления пользовательских и айтемных эмбеддингов, генеративные модели поиска обучаются предсказывать релевантные айтемы напрямую, часто с использованием авторегрессионных методов.

## Отличия от традиционных подходов

### Тренировка

- **Традиционные модели**: Обучаются с использованием контрастивных функций потерь (например, InfoNCE), где модель учится различать положительные и негативные примеры
- **Генеративные модели**: Обучаются с использованием авторегрессионных или последовательных подходов, где модель предсказывает следующий элемент в последовательности

### Инференс

- **Традиционные модели**: Вычисляют сходство между эмбеддингами пользователей и айтемов для поиска релевантных кандидатов
- **Генеративные модели**: Могут генерировать кандидатов напрямую или использовать генеративные подходы для поиска

## Ключевые архитектуры

### TBGRecall (Alibaba)

- Использует next-session prediction подход
- "Генеративность" относится к способу обучения, а не инференса
- Использует контекстные токены для интеграции информации о текущем запросе
- Применяет HSTU-блоки и session-wise ROPE для моделирования сессий
- Использует инкрементальное обучение для поддержания актуальности

### TIGER и PLUM (Google/YouTube)

- Используют подход "токенизации айтемов" для интеграции айтемов в LLM
- Применяют RQ-VAE для создания семантических идентификаторов (SIDs)
- Включают коллаборативный сигнал в процесс токенизации
- Используют next token prediction для генерации рекомендаций
- В PLUM: Mixture-of-Experts архитектура с ~900 млн активных параметров
- Позволяют эффективно масштабировать рекомендательные системы с использованием предобученных LLM

## Преимущества генеративных моделей поиска

1. **Гибкость**: Возможность интеграции сложной контекстной информации
2. **Моделирование сложных зависимостей**: Лучшее понимание сложных паттернов взаимодействия
3. **Адаптивность**: Более эффективное обучение на сложных сценариях взаимодействия сессий
4. **Контекстуальность**: Лучшая интеграция контекстной информации в процесс поиска

## Вызовы и ограничения

1. **Сложность обучения**: Авторегрессионные подходы могут быть вычислительно сложнее
2. **Инференс-время**: Некоторые генеративные подходы требуют больше времени для инференса
3. **Оценка**: Традиционные метрики могут быть не полностью применимы

## Сравнение с LLM-базированными подходами

| Аспект | Генеративные модели поиска | LLM-базированные модели |
|--------|----------------------------|--------------------------|
| Источник знаний | Только данные рекомендаций | Предобученные знания + данные рекомендаций |
| Сложность инференса | Средняя | Высокая |
| Объяснимость | Ограниченная | Высокая |
| Адаптация к домену | Прямая | Через промты или файнтюнинг |

## Связи с другими темами

- [[tbgrecall.md]] - TBGRecall: ключевой пример генеративной модели поиска для e-commerce
- [[session_based_recommendations.md]] - Сессионные рекомендательные системы: контекст применения
- [[sw_rope.md]] - Session-wise ROPE: техника, используемая в генеративных моделях
- [[optimization/incremental_learning.md]] - Инкрементальное обучение: для поддержки актуальности моделей
- [[candidate_generation.md]] - Генерация кандидатов: основной этап применения
- [[llm_based/main.md]] - LLM-базированные рекомендательные системы: альтернативный подход
- [[advantage_weighted_sft.md]] - Advantage-Weighted Supervised Fine-Tuning: метод дообучения генеративных рекомендательных моделей, альтернатива RLHF