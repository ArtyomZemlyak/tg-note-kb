# Анализ текущих подходов к персонализированным LLM

## Введение

Данное исследование анализирует современные подходы к интеграции персонализированной информации пользователей в архитектуры LLM для создания рекомендательных систем. Рассматриваются существующие архитектуры на основе анализа базы знаний.

## Ключевые подходы

### 1. OneRec-Think (Kuaishou)

**Архитектура:**
- Использует Qwen-8B как базовую LLM
- Вводит концепцию семантических ID (SIDs) для представления айтемов
- Интеграция SIDs в текстовое описание поведения пользователей
- Двухступенчатый процесс: претрейн и файнтюн

**Преимущества:**
- Эффективная интеграция пользовательской истории в текстовый формат
- Возможность ризонинга (логического вывода) для объяснения рекомендаций
- Доказанная применимость в реальной системе

**Ограничения:**
- Высокая вычислительная сложность ризонинга
- Внедрение только в оффлайн-режиме из-за сложности
- Ориентирована на видео-платформу, требует адаптации для других доменов

### 2. REGEN (Google)

**Архитектура:**
- Включает FLARE (гибридная система) и LUMEN (единая LLM-модель)
- Возможность вести диалог с пользователем
- Понимание отзывов на естественном языке
- Генерация контекстуальных нарративов

**Преимущества:**
- Естественное взаимодействие через диалог
- Объяснение причин рекомендаций
- Учет пользовательской критики в реальном времени

**Ограничения:**
- Сложность в оценке качества диалога
- Требует больших вычислительных ресурсов
- Потенциально сложная интеграция с несколькими сервисами

### 3. Модели с Mixture of Experts (MoE)

**Архитектура:**
- Разреженные сети с несколькими специализированными экспертом
- Маршрутизация входных данных к наиболее подходящим экспертам
- Примеры: Switch Transformers, Mixtral 8x7B

**Преимущества:**
- Высокая вычислительная эффективность (только часть параметров активируется)
- Масштабируемость до триллионов параметров
- Возможность специализации для разных пользователей/сценариев

**Ограничения:**
- Сложные методы маршрутизации
- Требования к памяти (все эксперты должны быть загружены)
- Проблемы с тонкой настройкой

## Общие паттерны

### Представление пользовательской информации
- Использование эмбеддингов для представления профилей пользователей
- Семантические ID для представления айтемов
- Сериализация истории взаимодействий в текстовый формат

### Интеграция с LLM
- Включение персональных данных как префикса/контекста
- Использование RAG (Retrieval-Augmented Generation) для доступа к профилю
- Файнтюнинг моделей на задачах с учетом персонализации

### Диалог и взаимодействие
- Возможность обновления предпочтений в реальном времени
- Объяснение причин рекомендаций
- Адаптивное поведение на основе пользовательской обратной связи

## Проблемы текущих подходов

1. **Интеграция данных из нескольких сервисов** - текущие архитектуры обычно ориентированы на один домен
2. **Скалярность персонализации** - отсутствие подходов, адаптирующихся к индивидуальным пользователям
3. **Защита приватности** - недостаточная интеграция методов дифференциальной приватности
4. **Вычислительная эффективность** - высокие требования к ресурсам для ризонинга и диалога
5. **Масштабируемость** - трудности с обслуживанием миллионов пользователей

## Выводы

Для создания новой архитектуры LLM, интегрирующей персонализированную информацию пользователей Самоката, Мегамаркета и Купера, необходимо объединить лучшие практики из существующих подходов:

- Использовать MoE для специализации под разные домены и пользователей
- Внедрить систему SIDs для унификации представления айтемов из разных сервисов
- Интегрировать диалоговые возможности REGEN для естественного взаимодействия
- Обеспечить вычислительную эффективность и защиту приватности