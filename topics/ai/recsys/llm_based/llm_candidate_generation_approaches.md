# LLM-базированные подходы к генерации кандидатов в рекомендательных системах

## Обзор

В последние годы наблюдается стремительное развитие подходов к использованию больших языковых моделей (LLM) для генерации кандидатов в рекомендательных системах. В этой статье рассматриваются два успешных промышленных внедрения: подход LinkedIn ("Large Scale Retrieval...") и подход Alibaba (RecGPT). Оба подхода используют текстовое представление айтемов вместо традиционных Semantic IDs, но имеют принципиальные архитектурные различия.

## Общие черты подходов

- Использование текстового представления айтемов вместо Semantic IDs
- Айтемы подаются в LLM в виде текстового описания фичей
- Пользовательская история представляется в виде текстового описания фичей и истории позитивных взаимодействий
- Оба подхода успешно внедрены в продакшн и показывают приросты в A/B тестировании
- Оба подхода сталкиваются с проблемой ограничения длины пользовательских историй, которые можно подать в LLM

## Подход LinkedIn: Large Scale Retrieval

### Основные особенности

- Замена классической двух-башенной архитектуры глубокого обучения на единую LLM
- Сохранение традиционной постановки задачи: обучение эмбеддингов пользователей и айтемов с приближением по коллаборативному сигналу через contrastive loss
- Использование файнтюна предобученной LLM (например, LLaMA-3 3B)
- Mean pooling для перехода от эмбеддингов токенов к финальным эмбеддингам пользователей и айтемов
- Использование косинусного расстояния для оценки близости айтема и пользователя
- Обучение на InfoNCE loss с использованием In-Batch негативов и Hard Negatives (impressions - айтемы, которые пользователь видел, но не взаимодействовал)
- Применение Matryoshka learning для сжатия размерности финальных эмбеддингов (например, с 3072 до 512)

### Преимущества

- Интеграция коллаборативных сигналов непосредственно в процесс генерации эмбеддингов
- Более прямое использование LLM в задаче рекомендаций
- Эмпирически показано, что текстовое представление айтемов является максимально нативным для LLM в определенных доменах (например, LinkedIn)

### Ограничения

- Ограничения по длине пользовательской истории из-за контекстной длины модели
- Возможна ограниченная эффективность в доменах, где текстовое представление не соответствует нативному языку айтемов

## Подход Alibaba: RecGPT

### Основные особенности

- Использование последовательности из нескольких LLM, каждая из которых дообучается на конкретную задачу
- Финальные рекомендации строятся не-LLM моделью
- Первый LLM майнит интересы пользователя из его истории действий (в виде текстовых описаний)
- Второй LLM предсказывает "теги" (текстовые описания следующих айтемов) на основе интересов и истории пользователя, без использования коллаборативных сигналов
- 3-башенная модель (Айтем-Юзер-Тег) с коллаборативными сигналами для финального построения рекомендаций
- Эмбеддинги юзера и предсказанного "тега" объединяются линейной комбинацией на этапе инференса

### Преимущества

- Лучшая масштабируемость за счет использования легкой DNN для финального результата
- Возможность обработки более длинных историй пользователей благодаря компрессии интересов
- Баланс между качеством и производительностью
- Интерпретируемость процесса построения рекомендаций
- Возможность генерации объяснений к рекомендациям

### Ограничения

- Ограниченное использование коллаборативных сигналов в процессе генерации тегов
- Суточные задержки в обновлении интересов пользователя
- Отказ от полностью end2end архитектуры

## Сравнение подходов

| Критерий | LinkedIn Large Scale Retrieval | Alibaba RecGPT |
|----------|-------------------------------|----------------|
| Архитектура | Единая LLM | Последовательность LLM + не-LLM модель |
| Роль LLM | Прямая генерация эмбеддингов | Подготовка промежуточных представлений |
| Использование коллаборативных сигналов | Напрямую в LLM | В основном в не-LLM модели |
| Сложность инференса | Выше из-за запуска LLM | Ниже за счет легкой DNN |
| Интерпретируемость | Ограниченная | Высокая благодаря промежуточным этапам |
| Обработка длинных историй | Ограничения контекста | Лучше благодаря сжатию интересов |

## Заключение

Оба подхода демонстрируют успешное применение LLM в задаче генерации кандидатов в промышленных рекомендательных системах, но предлагают разные компромиссы между эффективностью, интерпретируемостью и вычислительной сложностью. LinkedIn подходит к задаче как к обобщению традиционной двух-башенной архитектуры с использованием LLM, в то время как Alibaba использует LLM в качестве компонента более сложной гибридной архитектуры.

## Связи с другими темами

- [[main.md]] - Основы LLM-рекомендаций
- [[linkedin_large_scale_retrieval.md]] - Подробное описание подхода LinkedIn
- [[recgpt/main.md]] - Подробное описание подхода Alibaba
- [[../../candidate_generation.md]] - Общая информация о генерации кандидатов
- [[../../traditional_approaches.md]] - Традиционные подходы к рекомендательным системам
- [[../overview.md]] - Общий обзор применения LLM в рекомендательных системах