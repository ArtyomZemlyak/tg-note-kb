# LLM-based рекомендательные системы

## Описание

LLM-based рекомендательные системы - это новое поколение рекомендательных систем, которые используют предобученные большие языковые модели (LLM) для генерации рекомендаций. Вместо традиционных подходов кандидат-генерации и ранжирования, эти системы используют LLM для прямого предсказания релевантных айтемов на основе истории взаимодействия пользователя.

## История развития

После успеха end-2-end генеративных моделей в области рекомендательных систем, следующей хайповой темой стала LLM-based кандидат-генерация. Недавно появились статьи от топовых игроков с успешными результатами A/B тестирования внедренных дообученных LLM:

- OneRec-Think (Kuaishou)
- PLUM (Google, внедрение в YouTube)
- OnePiece (Shopee) - контекстная инженерия и ризонинг в промышленных каскадных ранжирующих системах
- Large Scale Retrieval… (LinkedIn)
- RecGPT (Alibaba, технический отчет от июля)
- REGEN (Google) - новый подход к диалоговым рекомендательным системам с использованием генеративных нарративов

## Общие подходы

### 1. Использование предобученных LLM

Обе компании (Google и Kuaishou) начинают с предобученных LLM:
- Google использует Gemini-1.5-MoE-900M
- Kuaishou использует Qwen-8B

### 2. Семантические ID айтемов (SIDs)

Обе компании используют семантические ID как главное представление айтемов для модели:
- SIDs строятся на основе мульти-модальных контентных эмбеддингов айтемов
- Также используется коллаборативный сигнал из сервиса
- В обоих случаях рассматриваются видео-платформы

### 3. Алайнмент семантических ID и языковых токенов

- Словарь LLM расширяется, чтобы включать каталог семантических ID айтемов
- Модель дообучается на задаче Next Token Prediction на текстах, описывающих:
  - Поведение действий пользователей
  - Сам каталог сервиса
- "Поведенческие" тексты интегрируют SIDs в текстовое описание действий пользователя
- Пример: "Пользователь <с такими фичами> лайкнул видео <SID-1><SID-2><SID-3> с заголовком <заголовок> и видео … с заголовком …"
- Также включается задача предсказания текстового описания айтема на основе его SIDs

### 4. Обучение предсказанию рекомендуемых айтемов

- Модель обучают предсказывать семантические ID айтема, который стоит порекомендовать пользователю на основе истории его действий
- Это полностью заменяет современные рекомендательные трансформеры над пользовательскими историями
- Инференс аналогичен TIGER - последовательная генерация SIDs, beam search

## Отличия в подходах

### Kuaishou (OneRec-Think)

- Весь файнтюн посвящает ризонингу (логическому выводу)
- Модель учат формулировать обоснование, почему пользователь после заданной истории взаимодействовал с конкретным айтемом
- Генерация обоснований нужна для улучшения качества самих рекомендаций, по аналогии с рассуждающими LLM
- Внедрение модели в оффлайне из-за вычислительной сложности ризонинга
- Рассуждающая модель в оффлайне генерирует несколько возможных траекторий (reasoning path) пользователя
- Для каждой траектории генерируется несколько возможных префиксов из 2-х SIDs
- Финальный сет всех возможных префиксов затем используется рантаймовой OneRec моделью для генерации итоговых рекомендаций
- OneRec является end-2-end движком, стадии ранжирования дальше не следует, генерируются именно финальные рекомендации

### Google (PLUM)

- На этапе файнтюна учит именно предсказание будущих айтемов для пользователя
- Учитывает рантаймовый контекст в промте
- Модель внедрена и в оффлайне, и в рантайме

## Заметки

- Количество dense параметров в трансформере у PLUM в 100 раз больше, чем у продового трансформера YouTube над пользовательской историей
- Kuaishou на примере доказывает полезность модели в сценарии диалога с пользователем. Здесь уже намечается персонализированный ассистент по рекомендациям, но пока о внедрении речи нет
- Google (как и LinkedIn) подчёркивает, что подобные архитектуры можно использовать для различных даунстрим задач, не только для кандидато-генерации
- Более подробный разбор PLUM есть у Кирилла

## Связи с другими темами

- [[../llm/models/generative_models.md]] - Генеративные модели, на которых основаны LLM-based рекомендательные системы
- [[../dialogue_based/main.md]] - REGEN: диалоговые рекомендательные системы с генеративными нарративами
- [[ai/recsys/candidate_generation.md]] - Традиционные подходы кандидат-генерации, которые заменяются LLM-based системами
- [[ai/recsys/transformer_based_models.md]] - Трансформерные модели, которые LLM полностью заменяют
- [[onepiece_framework/main.md]] - OnePiece: фреймворк Shopee с контекстной инженерии и ризонингом в каскадных системах