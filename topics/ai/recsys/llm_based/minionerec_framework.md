# MiniOneRec: Открытый фреймворк для масштабирования генеративных рекомендаций

```metadata
category: artificial_intelligence
subcategory: recommendation_systems
tags: generative_recommendations, llm, semantic_ids, sids, rq_vae, onerec, tiger, plum, sft
```

## Описание

MiniOneRec - это открытый фреймворк для генеративных рекомендательных систем, разработанный на основе идей из серии технических отчетов OneRec от Kuaishou. Фреймворк представляет собой попытку "повторить OneRec" в академической среде и без доступа к приватным датасетам. Авторы MiniOneRec - исследователи из университетов Китая и Сингапура - берут ключевые идеи OneRec, переносят их в минимально жизнеспособный фреймворк и подтверждают, что они действительно работают на открытых данных.

## Контекст и проблема

Традиционные подходы в рекомендательных системах сталкиваются с рядом ограничений:
- **Проблема масштаба каталога**: Невозможно использовать традиционные ID айтемов в миллионы/сотни миллионов напрямую в LLM из-за огромных embedding-слоев
- **Отсутствие генеративных возможностей**: Трудности с прямым предсказанием айтемов как токенов
- **Проблема холодного старта**: Трудности с новыми айтемами без истории взаимодействий

MiniOneRec решает эти проблемы, используя подходы, доказавшие свою эффективность в OneRec, но адаптированные для работы с открытыми данными.

## Архитектура

### Семантические идентификаторы (Semantic IDs) и подготовка данных

Первое препятствие, которое сразу появляется в рекомендациях - огромный каталог документов. Нельзя просто взять LLM и обучить её поверх ID в десятки или сотни миллионов: embedding/de-embedding-слои и softmax станут непригодными. Поэтому MiniOneRec, как и OneRec, используют семантические ID из работы TIGER.

**Основная идея**: Каждый документ кодируется короткой последовательностью токенов вместо использования миллионы ID в словаре LLM. Это позволяет использовать архитектуры трансформеров с огромными каталогами айтемов.

**Процесс генерации SIDs в MiniOneRec**:
1. Из исходного текста (название + описание) получают эмбеддинг
2. Текст прогоняется через замороженную Qwen3-Embedding-4B
3. Hidden states последнего слоя усредняются (mean pooling) в один вектор
4. Этот вектор подается в **трехуровневую RQ-VAE-кластеризацию**
   - На каждом уровне вычитается ближайший из 256 центроид (получается semantic_id_0)
   - Формируется остаток, который проходит ту же процедуру кластеризации следующего уровня
   - В итоге документ получает **трехтокенную семантическую подпись**

Этот подход резко уменьшает словарь: вместо миллионов ID становится 3x256 дополнительных токенов к словарю LLM.

### Решение проблемы коллапса кластеров

Авторы также отмечают проблему коллапса кластеров (слишком много документов в одном кластере), поэтому в коде используют не случайную инициализацию, а **RQ k-means из оригинального OneRec**. Это:
- Увеличивает энтропию кластеров
- Улучшает токенизацию
- Предотвращает коллапс (слияние слишком большого количества документов в один кластер)

### SFT (Supervised Fine-Tuning) и перенос NLP в рекомендации

После токенизации авторы применяют SFT поверх предобученной LLM (берут Qwen). Это оправдано для академии, поскольку:
- Экономятся ресурсы
- Не нужно тренировать архитектуру с нуля
- Модель сразу имеет сильный старт с предобученными знаниями

**Инновация в области алайнмента между NLP и рекомендациями**:
Авторы подмешивают в обучение разные форматы примеров, чтобы перенести world knowledge модели на новые токены. Получается несколько типов задач:

- **История на естественном языке** → предсказать следующий айтем в виде семантических токенов
- **История в виде семантических токенов** → предсказать текстовое описание следующего айтема  
- **Просто перевод айтема между двумя представлениями** - из текста в семантические токены и наоборот

**Важно**: Этот шаг дает самый большой прирост качества. В аблейшенах видно, что это важнее, чем стартовать со случайных весов. Вместе с тем сама идея достаточно проста: смешивать рекомендации с задачами NLP, чтобы модель лучше экстраполировала знания. Это похоже на недавнюю работу от Google — PLUM, хотя авторы на неё не ссылаются (возможно, результаты получены параллельно).

Этот подход позволяет LLM-модели не только извлекать информацию из предобученных знаний, но и применять эти знания к новым токенам, представляющим айтемы рекомендательной системы.

## Отличия от OneRec

| Аспект | OneRec (Kuaishou) | MiniOneRec (Akademia) |
|--------|-------------------|------------------------|
| **Данные** | Приватные датасеты Kuaishou | Открытые датасеты |
| **Масштаб** | Промышленная система | Минимально жизнеспособный фреймворк |
| **Цель** | Промышленное внедрение | Подтверждение эффективности идей OneRec на открытых данных |
| **Инфраструктура** | Коммерческая инфраструктура | Академические ресурсы |

## Связь с TIGER/PLUM и другими подходами

MiniOneRec использует ключевые идеи из всей экосистемы генеративных рекомендаций:

### Сравнение с TIGER (Google)

| Аспект | TIGER | MiniOneRec |
|--------|-------|------------|
| **Эмбеддинги** | Только текстовые описания айтемов | Использует Qwen3-Embedding-4B |
| **Коллаборативный сигнал** | Не использовался напрямую в токенизации | Подтверждение эффективности подхода |
| **Охват** | Эксперименты на Amazon датасетах | Открытые датасеты, подтверждение концепции |

### Сравнение с PLUM (Google/YouTube)

MiniOneRec похож на PLUM в аспекте использования LLM-подходов в рекомендациях, но:
- PLUM: промышленное внедрение в YouTube с Gemini
- MiniOneRec: академическая проверка концепции на открытых данных
- В обоих случаях используется подход "переноса NLP в рекомендации"

### Сравнение с OneRec

| Аспект | OneRec | MiniOneRec |
|--------|--------|------------|
| **Исходная база** | Коммерческая система Kuaishou | Академический фреймворк |
| **Используемые идеи** | Все ключевые идеи OneRec | Ключевые идеи OneRec, адаптированные |
| **Подтверждение эффективности** | Коммерческий успех | Подтверждение на открытых данных |
| **Доступность** | Приватная система | Открытый фреймворк |

## Влияние и результаты

MiniOneRec подтверждает, что ключевые идеи OneRec действительно работают и могут быть адаптированы для открытых данных. Это:
- Проверка гипотезы о применимости LLM-подходов из NLP в рекомендациях
- Подтверждение эффективности SIDs на открытых данных
- Попытка академического "репликации" промышленных решений

![SID history and prediction process](../../../../media/img_1764923229_aqadrg5rg6b2kul_sid_history_sei_eestory.jpg)

**Изображение показывает:** Процесс использования SIDs (Semantic IDs) в генеративных рекомендательных системах - историю пользователя в виде SIDs и предсказание следующего айтема с использованием LLM с ограниченным beam search, а также полный процесс выравнивания SIDs.

Данная статья представляет первую часть анализа фреймворка MiniOneRec (Part 1/2), фокусируясь на основах архитектуры и подходе к обучению. В следующей части будут рассмотрены:

- RL-дообучение (Reinforcement Learning fine-tuning)
- Масштабирование
- Эмпирические результаты

Для продолжения изучения темы, см. [[./minionerec_part2_rl_finetuning.md]] - подробное описание RL-дообучения и эмпирических результатов MiniOneRec.

## Связи с другими темами

- [[./minionerec_novel_approaches.md]] - Уникальные аспекты и нововведения MiniOneRec, детализирующие ключевые различия и улучшения по сравнению с предшественниками; этот файл содержит информацию о RQ k-means и подходах к NLP-выравниванию
- [[./onerec_think/main.md]] - Оригинальная промышленная система OneRec от Kuaishou, на основе которой развивался MiniOneRec; MiniOneRec представляет собой академическую реализацию ключевых идей OneRec на открытых данных
- [[./tiger.md]] - Предшествующая работа TIGER (Google/YouTube), задавшая подход SIDs (семантических идентификаторов), который используется и в OneRec, и в MiniOneRec
- [[./plum/main.md]] - Промышленная реализация SIDs в YouTube, похожая по духу к подходу MiniOneRec; обе работы демонстрируют применение LLM-подходов в рекомендательных системах
- [[./concept/rq_vae.md]] - RQ-VAE (Residual Quantization Variational Autoencoder), используемый для генерации SIDs в MiniOneRec, также описывается в контексте TIGER и PLUM
- [[./concept/item_tokenization.md]] - Токенизация айтемов с использованием RQ-VAE, ключевой компонент как в MiniOneRec, так и в других генеративных рекомендательных системах
- [[ai/recsys/semantic_ids_in_recsys.md]] - Общая информация о семантических идентификаторах в рекомендательных системах, контекст, в котором развивается подход MiniOneRec
- [[ai/recsys/llm_based/llm4rec_survey_classification.md]] - Обзор LLM-based рекомендательных систем, в контексте которого MiniOneRec представляет собой один из подходов к генерации рекомендаций с использованием SIDs
- [[ai/recsys/llm_based/main.md]] - Общая информация о LLM-based рекомендательных системах, где MiniOneRec является примером практической реализации концепции

## Источники

1. [MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation] - Оригинальная научная работа, описывающая фреймворк MiniOneRec и его подход к генеративным рекомендациям на основе идей OneRec
2. [OneRec Technical Reports from Kuaishou] - Серия технических отчетов, на основе которых был разработан MiniOneRec
3. [TIGER: Transformers Index for Generative Recommendations] - Оригинальная работа о семантических ID в рекомендациях, на основе которой развивались подходы в OneRec и MiniOneRec
4. [PLUM: Adapting Pre-trained Language Models for Industrial-scale Generative Recommendations] - Работа Google о применении LLM-подходов в рекомендательных системах YouTube, похожая по духу к подходу MiniOneRec
5. [Илья Мурзин - Разбор MiniOneRec] - Анализ статьи MiniOneRec, подготовленный для RecSysChannel, описывающий ключевые аспекты фреймворка