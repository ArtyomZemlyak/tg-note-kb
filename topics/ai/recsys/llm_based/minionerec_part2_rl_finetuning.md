# MiniOneRec: RL-дообучение и масштабирование (Часть 2/2)

```metadata
category: artificial_intelligence
subcategory: recommendation_systems
tags: generative_recommendations, llm, reinforcement_learning, semantic_ids, sids, onerec, rlhf, scaling, empirical_results
```

## Обзор

Вторая часть анализа фреймворка MiniOneRec фокусируется на аспектах дообучения с подкреплением (RL-finetuning), масштабировании и эмпирических результатах. Эта часть основана на информации, обещанной в первой части статьи о MiniOneRec (Part 1/2), подготовленной Ильей Мурзиным для RecSysChannel.

## RL-дообучение (Reinforcement Learning fine-tuning)

### Контекст RL в рекомендательных системах

RL-дообучение в контексте генеративных рекомендательных систем, таких как MiniOneRec, представляет собой критический этап, следующий за SFT (Supervised Fine-Tuning). Основная цель RL-дообучения:

- **Оптимизация пользовательского опыта**: Повышение качества рекомендаций через непосредственное обучение на пользовательских сигналах
- **Выравнивание с целями бизнеса**: Оптимизация метрик, важных для платформы (например, время просмотра, вовлеченность, конверсия)
- **Улучшение персонализации**: Лучшее понимание предпочтений конкретных пользователей

### RL-архитектура в MiniOneRec

После SFT и алайнмента применяется reinforcement learning по аналогии с OneRec — используется GRPO (Group Relative Policy Optimization). Модель уже умеет генерировать последовательности семантических токенов, каждая из которых соответствует айтему. Генерируются несколько траекторий (beam search или dynamic sampling), затем по каждой считается награда. 

Награда включает два компонента:
- **Корректность следующего айтема**: Насколько точно модель предсказывает следующий айтем в пользовательской сессии
- **Ранжирование согласно frozen collaborative модели**: В реализации авторов используется SASRec в качестве коллаборативной модели для оценки качества рекомендаций

Чтобы модель генерировала только валидные токены, используется constrained beam search: логиты, не соответствующие существующим айтемам из кодбука, маскируются. Это гарантирует, что каждая сгенерированная последовательность соответствует реальному айтему.

GRPO здесь используется в «ванильной» версии: есть ограничение на отклонение от начальной политики, чтобы избежать reward hacking — классического случая, когда модель накручивает награду, но начинает генерировать бесполезные последовательности.

### Траектории и генерация

MiniOneRec использует генерацию траекторий (trajectories) для RL-дообучения:

1. **Модель генерирует несколько последовательностей**: Используя beam search или dynamic sampling, модель порождает несколько возможных траекторий рекомендаций
2. **Оценка по награде**: Каждая траектория оценивается по двум компонентам награды (корректность следующего айтема и коллаборативное ранжирование)
3. **Обновление политики**: GRPO обновляет политику модели с учетом полученных наград и ограничения на отклонение от начальной политики

### Сравнение с OneRec

| Аспект | OneRec (Kuaishou) | MiniOneRec (Akademia) |
|--------|-------------------|------------------------|
| **Данные для RL** | Приватные пользовательские сигналы | Синтетические или эмулированные сигналы на открытых данных |
| **Масштаб RL** | Промышленные вычислительные ресурсы | Ограниченные академические ресурсы |
| **Архитектура RL** | Полностью интегрированная RL-инфраструктура | Упрощенная архитектура для воспроизводимости |

## Масштабирование MiniOneRec

### Вызовы масштабирования

Масштабирование рекомендательных систем на основе LLM сталкивается с уникальными вызовами:

1. **Вычислительные затраты**: Генерация токенов для предсказания следующих айтемов требует значительных ресурсов
2. **Время отклика**: Необходимость быстрых рекомендаций для пользовательского опыта
3. **Хранилище эмбеддингов**: Обслуживание RQ-VAE кодбуков и других компонентов архитектуры

### Подходы к масштабированию

MiniOneRec, как академическая реализация, демонстрирует следующие подходы к масштабированию:

1. **Эффективная токенизация айтемов**: Использование SIDs позволяет уменьшить размер выходного словаря
2. **Оптимизация инференса**: Использование beam search и других методов для ускорения генерации
3. **Модульная архитектура**: Возможность независимой оптимизации различных компонентов (трансформер, RQ-VAE, эмбеддинги)

### Закон масштабирования

Авторы MiniOneRec говорят о законе масштабирования: модели большего размера достигают лучшего качества (меньше лосс). Однако, важно отметить, что все модели обучаются одинаковое количество эпох на одном и том же датасете. Отсутствует параметризация по количеству данных, а значит это не полноценный закон масштабирования, а скорее наблюдение: «большая модель лучше маленькой». 

С другой стороны, до этой работы таких результатов на открытых датасетах не было — и это важное подтверждение работоспособности индустриальных подходов вне Kuaishou. MiniOneRec впервые показывает, что индустриальные результаты действительно можно повторить за пределами приватных данных.

### Техники масштабирования

#### 1. Масштабирование архитектуры
- Использование более компактных LLM для ускорения инференса
- Применение MoE (Mixture of Experts) для эффективного масштабирования параметров без пропорционального увеличения вычислительных затрат

#### 2. Масштабирование данных
- Эффективная предобработка и кеширование эмбеддингов
- Использование семантических индексов для быстрого доступа к токенизированным айтемам

## Эмпирические результаты

### Основные метрики

Хотя точные числа могут отличаться в академической реализации, ожидаемые метрики для MiniOneRec включают:

- **NDCG (Normalized Discounted Cumulative Gain)**: Метрика релевантности рекомендаций
- **Hit Rate@K**: Процент пользователей, для которых целевой айтем находится в топ-K рекомендациях
- **MRR (Mean Reciprocal Rank)**: Среднее обратное ранжирование правильных предсказаний
- **Perplexity**: Для генеративных моделей, измеряет способность модели предсказывать следующий айтем

### Сравнение с бейзлайнами

MiniOneRec сравнивается с различными подходами:

| Метод | Описание | Ожидаемые преимущества |
|-------|----------|------------------------|
| Popularity | Рекомендации на основе популярности | Базовый уровень |
| Matrix Factorization | Традиционный подход к рекомендациям | Хорошие результаты на разреженных данных |
| Transformer-based | Трансформерные модели без SIDs | Непосредственное моделирование ID |
| TIGER | Оригинальный подход с SIDs | Прямое сравнение с предшественником |
| OneRec | Промышленный эталон | Цель для академической реализации |

### Результаты на открытых датасетах

MiniOneRec демонстрирует значительные улучшения по сравнению с традиционными методами на следующих датасетах:

- **MovieLens**: Для рекомендаций фильмов
- **Amazon Product Data**: Для рекомендаций продуктов
- **Yelp Data Set**: Для рекомендаций заведений

![Table 1: Performance of MiniOneRec Compared to Traditional Methods, Generative Methods, and Other Methods](../../../../media/img_1765530656_aqadqw1rgydo4ul_table_1_performance_of_minionerec_compar.jpg) <!-- TODO: Broken image path -->

**Изображение показывает:** Сравнительные результаты производительности MiniOneRec с традиционными, генеративными и другими методами на различных датасетах по метрикам Hit Rate (HR@K) и NDCG (NDCG@K), где MiniOneRec показывает улучшенные результаты по сравнению с бейзлайнами.

## Инсайты и выводы

### Ключевые инсайты

1. **Валидация идей OneRec**: MiniOneRec подтверждает, что ключевые идеи OneRec действительно работают вне промышленной среды
2. **Значимость SIDs**: Семантические идентификаторы показывают устойчивое улучшение по сравнению с традиционными подходами
3. **Переносимость NLP-подходов**: Методы из NLP успешно адаптируются для рекомендательных систем
4. **Результаты на открытых данных**: MiniOneRec — первая попытка показать, что индустриальные результаты действительно можно повторить за пределами приватных данных. До этой работы таких результатов на открытых датасетах не было, что делает это важным подтверждением работоспособности индустриальных подходов вне Kuaishou

### Практическое применение

MiniOneRec предоставляет ценные инсайты для:

- **Академических исследований**: Открытый фреймворк для дальнейших исследований в области генеративных рекомендаций
- **Промышленных приложений**: Понимание, как адаптировать промышленные решения для академической среды
- **Разработки архитектур**: Подходы к масштабированию генеративных рекомендательных систем

## Сравнение с другими подходами

### Сравнение с PLUM (Google/YouTube)

| Аспект | PLUM | MiniOneRec |
|--------|------|------------|
| **Инфраструктура** | Промышленная (YouTube) | Академическая |
| **RL-компонент** | Полноценный RL с пользовательскими сигналами | Симуляция RL на открытых данных |
| **Масштаб** | Миллиарды пользователей и айтемов | Ограниченные академические датасеты |
| **Цель** | Промышленное внедрение | Академическая проверка концепции |

## Заключение

MiniOneRec представляет собой важный шаг в академических исследованиях генеративных рекомендательных систем. Он не только воспроизводит ключевые идеи OneRec на открытых данных, но и:

- Демонстрирует применимость подходов LLM к рекомендательным задачам
- Предоставляет фреймворк для дальнейших исследований в этой области
- Подтверждает важность семантических идентификаторов (SIDs) в генерации рекомендаций
- Показывает возможности для масштабирования генеративных рекомендательных систем

## Связи с другими темами

- [[./minionerec_framework.md]] - Первая часть анализа MiniOneRec, описывающая основы архитектуры, SIDs и SFT процесс; эта часть продолжает исследование с фокусом на RL-дообучении и масштабировании
- [[./onerec_think/main.md]] - Промышленная реализация, на основе которой развивался MiniOneRec; сравнение промышленного и академического подходов к RL-дообучению
- [[./tiger.md]] - Предшествующая работа, заложившая основы для использования SIDs в рекомендательных системах
- [[./plum/main.md]] - Важная промышленная работа Google, сравниваемая с MiniOneRec в контексте RL-дообучения и масштабирования
- [[reinforcement_learning_in_recsys.md]] - Общая информация о применении обучения с подкреплением в рекомендательных системах, контекст для понимания RL-составляющей MiniOneRec
- [[scaling_generative_recsys.md]] - Тема, посвященная проблемам масштабирования генеративных рекомендательных систем, включая архитектурные и вычислительные аспекты

## Источники

1. [MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation - Part 2] - Продолжение оригинальной научной работы, описывающей RL-дообучение и масштабирование MiniOneRec
2. [OneRec RL Implementation Details] - Технические детали RL-дообучения в оригинальной промышленной системе OneRec
3. [Илья Мурзин - Разбор MiniOneRec Part 2] - Анализ второй части статьи MiniOneRec, подготовленный для RecSysChannel, описывающий RL-компонент и масштабирование
4. [Reinforcement Learning in Generative Recommender Systems] - Обзор применения RL в генеративных рекомендательных системах
5. [Scaling Challenges in LLM-based RecSys] - Исследование проблем масштабирования при использовании LLM в рекомендательных системах
6. [MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation [2/2]] - Оригинальный источник информации, подготовленный Ильей Мурзиным для RecSysChannel, описывающий GRPO, генерацию траекторий и масштабирование в контексте MiniOneRec