# Каскадное ранжирование и архитектура извлечения/ранжирования в OnePiece

## Описание

OnePiece реализует каскадную двухступенчатую архитектуру для рекомендательных систем, включающую этап извлечения (retrieval) и этап ранжирования (ranking). Это современный подход, широко используемый в промышленных рекомендательных системах.

## Этап извлечения (Retrieval)

### Входные данные
- История взаимодействий пользователя
- Описание контекста через пользовательские признаки

### Особенности
- Использование "якорей предпочтений" (preference anchors) - топы товаров по количеству покупок, добавлений в корзину или кликов
- Можно рассматривать как аналог RAG (Retrieval-Augmented Generation) для рекомендательных систем
- Формирует широкий набор кандидатов для следующего этапа

### Методы обучения
- **Функция потерь**: Binary-cross-entropy loss для предсказания кликов, добавлений в корзину и покупок
- **Обратное обучение**: Используется bidirectional contrastive learning (симметричный User to Item и Item to User) для улучшения соответствия между пользователями и товарами

## Этап ранжирования (Ranking)

### Входные данные
- То же, что и на этапе извлечения, плюс множество кандидатов
- Подход аналогичен target-aware трансформерам

### Особенности
- Более точная оценка релевантности кандидатов для конкретного пользователя
- Использует более сложные признаки и модели для принятия решений

### Методы обучения
- **Функция потерь**: Вместо bidirectional contrastive learning используется set contrastive learning на успешных случаях
- **Цель set contrastive learning**: Расширить границы положительных и отрицательных исходов, что улучшает дифференциацию между релевантными и нерелевантными кандидатами

## Архитектурные особенности

### Представление данных
- Товары описываются набором ID: название, магазин, категория
- Запросы представлены мешком слов
- Токены получаются с помощью MLP над конкатенацией эмбеддингов

### Оптимизация
- Чтобы избежать полного внимания между всеми кандидатами (что увеличивает вычислительную нагрузку и может вызвать артефакты зависимостей)
- Кандидаты делятся на случайные группы и подаются на вход по одной

### Базовая архитектура
- Основа: трансформерный энкодер
- Размеры модели: по косвенным признакам, модель не очень большая

## Обучение в продакшене

### Методология онлайн-обучения
- Воспроизводится ежедневное онлайн-дообучение, которое ждёт систему в проде
- Данные упорядочены между собой по дням, но внутри них семплы пошаффлены
- Результат за каждый день сохраняется и оценивается по итогам следующего
- Период данных для обучения составляет месяц

## Интеграция с другими компонентами

- Компоненты контекстной инженерии и ризонинга работают на обоих этапах системы
- Якоря предпочтений используются для улучшения извлечения
- Прогрессивное многозадачное обучение используется для улучшения обеих стадий

## Преимущества каскадного подхода

1. Баланс между покрытием и точностью
2. Вычислительная эффективность (первый этап отсеивает заведомо нерелевантные кандидаты)
3. Возможность использования разных моделей на разных этапах
4. Лучшая масштабируемость для промышленных систем

## Бизнес-результаты

- **GMV/UU**: +2% при внедрении нового фреймворка в основной сценарий персонализированного поиска
- **Доход от рекламы**: +2.90% при использовании улучшенного фреймворка

## Связи с другими темами

[[./context_engineering.md]] - Контекстная инженерия, улучшающая оба этапа
[[./reasoning_approach.md]] - Компонент ризонинга, работающий на обоих этапах
[[./progressive_training.md]] - Метод обучения, используемый для обеих стадий
[[../../../programming/software_architecture/infinigram_fm_index_search.md]] - Infini-gram: точный метод поиска n-грамм, может быть использован как альтернатива или дополнение к традиционным методам извлечения в RAG-системах
[[../../../programming/software_architecture/search_methods_comparison.md]] - Сравнение методов поиска: Infini-gram, BM25 и SPLADE