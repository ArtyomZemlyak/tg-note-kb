# Обзор применения LLM в рекомендательных системах

## Введение

Большие языковые модели (LLM) революционизировали подход к построению рекомендательных систем. В отличие от традиционных методов, основанных на факторизационных машинах, нейронных сетях и коллаборативной фильтрации, LLM могут использовать богатое семантическое понимание текста, контекста и сложных зависимостей между пользователями и предметами.

## Основные применения LLM в рекомендациях

### 1. Генерация кандидатов

LLM могут использоваться для:
- Прямого предсказания релевантных айтемов на основе истории пользователя
- Генерации новых кандидатов с учетом контекста
- Создания персонализированных рекомендаций на основе текстовых описаний

### 2. Ранжирование

LLM могут:
- Оценивать релевантность айтемов на основе сложных признаков
- Проводить многоуровневое ранжирование с учетом контекста, настроения и цели пользователя
- Учитывать сложные объяснения и обоснования для рекомендаций

### 3. Объяснение рекомендаций

LLM могут:
- Генерировать понятные объяснения для пользователей
- Объяснять логику выбора рекомендаций
- Обеспечивать прозрачность и доверие к системе

### 4. Диалоговые рекомендательные системы

LLM позволяют:
- Вести диалог с пользователем для уточнения предпочтений
- Уточнять запросы и персонализировать рекомендации в реальном времени
- Обрабатывать естественный язык и сложные запросы

## Архитектурная схема LLM рекомендательных моделей

```
                    ┌─────────────────────────────────────┐
                    │        Входные данные               │
                    │  (пользовательские признаки,      │
                    │   контекст, история взаимодействий) │
                    └─────────────┬───────────────────────┘
                                  │
                    ┌─────────────▼─────────────┐
                    │      Предобработка        │
                    │  (трансформация в текст,  │
                    │   семантические ID,       │
                    │   токенизация)           │
                    └─────────────┬─────────────┘
                                  │
                    ┌─────────────▼─────────────┐
                    │      LLM Модель           │
                    │                           │
        ┌─────────────►  ┌─────────────────┐    │
        │              │  │  Семантические  │    │
        │              │  │  Встраивания    │    │
        │              │  │  (Embeddings)   │    │
        │              │  └─────────────────┘    │
        │              │         │               │
        │              │  ┌─────────────────┐    │
        │              │  │   Многослойный  │    │
        │              │  │   Трансформер   │    │
        │              │  │   (Encoder-     │    │
        │              │  │   Decoder)      │    │
        │              │  └─────────────────┘    │
        │              │         │               │
        │              │  ┌─────────────────┐    │
        │              │  │    Обработка    │    │
        │              │  │    Внимания     │    │
        │              │  │   (Attention)   │    │
        │              │  └─────────────────┘    │
        │              └─────────┬───────────────┘
        │                        │
        │              ┌─────────▼─────────┐
        │              │   Выходной слой   │
        │              │   (Prediction)    │
        └──────────────►  ┌───────────────┐ │
                       │  │ Прогноз       │ │
                       │  │ рекомендаций  │ │
                       │  │ (SIDs, токены,│ │
                       │  │ категории и т.д.)│ │
                       │  └───────────────┘ │
                       └─────────────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │         Постобработка         │
                    │  (конвертация в рекомендации, │
                    │   фильтрация, переранжирование) │
                    └───────────────┬───────────────┘
                                    │
                    ┌───────────────▼───────────────┐
                    │        Рекомендации           │
                    │  (финальные айтемы для       │
                    │   показа пользователю)       │
                    └───────────────────────────────┘
```

Для более детального представления архитектуры также доступна [диаграмма в формате Mermaid](architecture_diagram.mmd).

### Детализация архитектуры

#### Входные данные (Input Features)
- **История взаимодействия пользователя**: Последовательность айтемов, с которыми пользователь взаимодействовал
- **Признаки пользователя**: Демографические данные, профиль, предпочтения
- **Признаки айтема**: Текстовое описание, категории, метаданные
- **Контекст**: Время, место, устройство, сессионные данные
- **Семантические ID (SIDs)**: Специальные токены, представляющие айтемы в пространстве LLM

#### Предобработка
- **Токенизация**: Преобразование текста и категориальных признаков в токены
- **Создание SIDs**: Генерация семантических ID для айтемов на основе мультимодальных эмбеддингов
- **Формирование промтов**: Структурирование входных данных в формат, понятный LLM

#### LLM Модель
- **Семантические встраивания**: Специальные встраивания для представления айтемов
- **Многослойный трансформер**: Основной архитектурный компонент, обрабатывающий последовательности
- **Механизм внимания**: Позволяет модели фокусироваться на наиболее релевантных частях истории пользователя
- **Выходной слой**: Генерирует вероятностное распределение для следующих айтемов

#### Выходные данные
- **Прогноз рекомендаций**: Семантические ID, токены или вероятности для потенциальных рекомендаций
- **Объяснения**: Текстовые объяснения, почему айтемы рекомендуются
- **Контекстуальная информация**: Дополнительная информация для последующей обработки

## Преимущества LLM в рекомендациях

1. **Семантическое понимание**: LLM способны понимать смысл текста и контента
2. **Перенос знаний**: Возможность использовать знания, полученные на других задачах
3. **Объяснимость**: Возможность генерировать понятные объяснения
4. **Гибкость**: Возможность адаптации к новым доменам с минимальными изменениями
5. **Мультимодальность**: Возможность работы с разными типами данных

## Вызовы и ограничения

1. **Вычислительная сложность**: LLM требуют значительных вычислительных ресурсов
2. **Задержки**: Высокая латентность при генерации рекомендаций
3. **Расширение словаря**: Необходимость адаптации словаря LLM к предметной области
4. **Финтюнинг**: Требуется тщательная настройка под конкретные задачи
5. **Качество данных**: Зависимость от качества текстовых описаний

## Практические примеры

### OneRec-Think (Kuaishou)
- Использует Qwen-8B для генерации объяснений
- Фокусируется на логическом выводе (ризонинге)
- Генерирует траектории поведения пользователя

### PLUM (Google/YouTube)
- Использует Gemini-1.5-MoE-900M
- Обучается напрямую предсказывать будущие айтемы
- Интегрирует рантаймовый контекст в промт

### REGEN (Google)
- Диалоговые рекомендательные системы с генеративными нарративами
- Использует генеративные модели для создания персонализированных историй

## Заключение

Применение LLM в рекомендательных системах открывает новые возможности для создания более персонализированных, объяснимых и контекстуальных рекомендаций. Архитектура LLM-рекомендательных моделей включает в себя комплексную обработку входных признаков, использование мощных трансформерных моделей и генерацию качественных рекомендаций с объяснениями. Несмотря на вызовы, связанные со сложностью и вычислительными затратами, LLM-рекомендательные системы демонстрируют значительный потенциал для будущего развития рекомендательных технологий.

## Ссылки на связанные темы

- [[main|Основы LLM-рекомендаций]]
- [[../candidate_generation|Генерация кандидатов]]
- [[../ranking|Ранжирование в рекомендательных системах]]
- [[../transformer_based_models|Трансформерные модели]]
- [[../dialogue_based/main|Диалоговые рекомендательные системы]]
- [[../../llm/models/generative_models|Генеративные модели]]