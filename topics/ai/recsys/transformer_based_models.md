# Трансформерные модели в системах рекомендаций

## Описание

Трансформерные модели в системах рекомендаций представляют собой современный подход к моделированию последовательностей взаимодействий пользователя с айтемами. Эти модели используют механизм внимания (attention) для захвата сложных зависимостей между элементами в истории взаимодействий пользователя.

## История и развитие

Трансформерные модели были адаптированы для задач рекомендаций после их успеха в задачах обработки естественного языка. Первой значимой работой в этой области стала SASRec (Self-Attentive Sequential Recommendation), которая применила архитектуру трансформера для моделирования последовательностей поведения пользователя.

## Основные архитектуры

### SASRec (Self-Attentive Sequential Recommendation)

- Использует механизм самовнимания (self-attention) для моделирования последовательных паттернов
- Каждый айтем в последовательности получает взвешенное представление на основе других айтемов
- Позволяет эффективно захватывать долгосрочные зависимости в поведении пользователя

### HSTU (Hierarchical Semantic Transformer for User Behavior Modeling)

- Расширенная архитектура трансформера с иерархическим подходом
- Моделирует как локальные, так и глобальные зависимости в поведении
- Использует семантическое понимание для улучшения представлений

## Преимущества трансформерных моделей

- **Захват сложных зависимостей**: Благодаря механизму внимания, модели могут захватывать сложные взаимосвязи между айтемами в последовательности
- **Гибкость**: Возможность моделирования различных типов зависимостей и контекста
- **Масштабируемость**: Могут обрабатывать длинные последовательности (с ограничениями)

## Проблемы и ограничения

- **Уникальные эмбеддинги для каждого айтема**: Трансформерные модели (включая SASRec) должны выучивать уникальный эмбеддинг для каждого айтема в каталоге
- **Проблема холодного старта**: Трудности с новыми айтемами, которые не были в обучающих данных
- **Неэффективность для длинного хвоста**: Редкие айтемы из "длинного хвоста" могут иметь слабые представления
- **Вычислительная сложность**: Квадратичная сложность механизма внимания по длине последовательности

## Решения проблем

### DenseRec

- Подход, объединяющий контентные и коллаборативные эмбеддинги
- Обучение модели вероятностному выбору типа эмбеддинга для каждого айтема
- Использование контентных эмбеддингов для холодных айтемов и коллаборативных для теплых
- Простая модификация только слоя эмбеддингов, позволяющая интеграцию в существующие архитектуры (например, SASRec)

## Сравнение с традиционными подходами

| Аспект | Трансформерные модели | Традиционные подходы |
|--------|------------------------|----------------------|
| Захват зависимостей | Комплексные зависимости через внимание | Простые зависимости или матричная факторизация |
| Обработка последовательностей | Эффективно моделируют последовательности | Ограниченная способность к моделированию последовательностей |
| Холодный старт | Проблематично без дополнительных методов | Некоторые методы (например, контент-базированные) лучше справляются |
| Масштабируемость по каталогу | Проблемы при добавлении новых айтемов | Более гибкие в отношении новых айтемов |

## Применение в современных системах

Трансформерные модели в системах рекомендаций находят применение в:

- Моделировании последовательного поведения пользователей
- Рекомендациях контента (музыка, видео, новости)
- Сессионных рекомендациях
- Персонализированной ленте новостей
- Рекомендациях с учетом контекста

## Связи с другими темами

- [[traditional_approaches.md]] - Традиционные подходы к рекомендательным системам: контекст для понимания эволююции
- [[candidate_generation.md]] - Генерация кандидатов: этап, где могут использоваться трансформерные модели
- [[ranking.md]] - Ранжирование: этап, который может использовать трансформерные представления
- [[denserec.md]] - DenseRec: современное решение проблем трансформерных моделей
- [[tbgrecall.md]] - TBGRecall: современная модель, использующая HSTU-блоки для моделирования сессионного поведения
- [[session_based_recommendations.md]] - Сессионные рекомендательные системы: контекст применения трансформерных моделей
- [[sw_rope.md]] - Session-wise ROPE: модификация позиционных вложений для сессионных моделей
- [[llm_based/main.md]] - LLM-базированные рекомендательные системы: следующая эволюция после трансформеров
- [[gem_model.md]] - GEM: современная гибридная архитектура трансформера от Meta с инновационным подходом к обработке последовательных и непоследовательных признаков