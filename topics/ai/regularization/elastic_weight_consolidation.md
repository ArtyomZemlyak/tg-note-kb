# Упругая консолидация весов (Elastic Weight Consolidation, EWC)

## Определение

Упругая консолидация весов (Elastic Weight Consolidation, EWC) - это метод машинного обучения, предназначенный для преодоления катастрофического забывания в нейронных сетях. Метод предполагает, что некоторые веса нейронной сети более важны для предыдущих задач, чем другие, и ограничивает изменения этих важных весов во время обучения новым задачам.

## Основная идея

EWC основан на идее, что при обучении новой задачи веса нейронной сети, которые критически важны для решения предыдущей задачи, не должны изменяться слишком сильно. Вместо этого, изменения в этих весах штрафуются с помощью добавления регуляризационного члена к функции потерь.

## Математическая формулировка

Функция потерь в EWC модифицируется следующим образом:
L(θ) = L_new(θ) + Σ F_i (θ_i - θ_i^*)^2

Где:
- L_new(θ) - обычная функция потерь для новой задачи
- F_i - важность i-го веса (определяется через диагональные элементы матрицы Фишера)
- θ_i^* - значение i-го веса до обучения новой задаче
- Σ F_i (θ_i - θ_i^*)^2 - регуляризационный член, предотвращающий изменение важных весов

## Преимущества

1. Позволяет модели обучаться новым задачам без забывания предыдущих
2. Не требует хранения примеров из предыдущих задач
3. Вычислительно эффективен по сравнению с методами воспроизведения опыта

## Ограничения

1. Требует информации о важности весов для предыдущей задачи
2. Может накапливать ошибки при последовательном обучении нескольких задач
3. Предполагает, что важные веса для одной задачи не станут важны для другой

## Сравнение с другими методами

- В отличие от методов воспроизведения опыта, EWC не требует хранения примеров из предыдущих задач
- По сравнению с архитектурными методами (например, Memo), EWC не изменяет структуру нейронной сети
- EWC работает на уровне весов, а не на уровне представлений или архитектуры

## Связи с другими темами

- [[../catastrophic_forgetting/catastrophic_forgetting.md]] - Катастрофическое забывание: проблему, которую решает EWC
- [[../class_incremental_learning/class_incremental_learning.md]] - Приращение класса: контекст применения метода
- [[../rehearsal/experience_replay.md]] - Альтернативный подход к решению катастрофического забывания
- [[../class_incremental_learning/memo_2022.md]] - Сравнение с другим методом решения проблемы
- [[../../llm/optimization/llm_fine_tuning_preserving_skills.md]] - Сохранение навыков при дообучении LLM: лучшие практики предотвращения катастрофического забывания