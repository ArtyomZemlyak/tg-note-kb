# Глубокий RL на стероидах: масштабирование агентов до 1000 слоёв

## Краткое описание

Статья "1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities" авторов Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach представляет прорыв в масштабировании глубоких сетей для обучения с подкреплением. Вместо традиционных 2-5 слоёв, авторы успешно масштабировали агентов до 1000+ слоёв, используя самообучение (Self-Supervised Learning) и конкретно Contrastive RL (CRL) в сочетании с современной архитектурной "начинкой": резидуальные связи, нормализация по слою и активации Swish.

## Основная информация

Долгое время считалось, что RL не выигрывает от увеличения глубины нейронных сетей. Стандартные алгоритмы вроде SAC и TD3 деградировали или выходили на плато при углублении. Эта работа разрушает эту догму, показывая, что с правильной целевой функцией (контрастное обучение вместо регрессии) и архитектурной гигиеной, глубокие RL-агенты могут масштабироваться и достигать впечатляющих результатов.

### Проклятие мелководья (Shallow Water Curse)

В традиционном обучении с подкреплением агенты часто ограничены MLP (многослойными перцептронами) всего с 2-5 слоями, несмотря на то что в компьютерном зрении и NLP используются сети с сотнями слоёв. Считалось, что редкие сигналы обратной связи (награды) недостаточны для обучения глубоких моделей с большой ёмкостью. Попытки просто увеличить глубину в стандартных методах Actor-Critic часто приводили к нестабильности или затуханию градиентов.

### Классификация вместо регрессии

Ключевая идея работы - замена стандартной регрессионной задачи (Temporal Difference, TD) на задачу классификации через контрастное обучение. Contrastive RL переформулирует задачу goal-conditioned RL как задачу обучения представлений (representation learning) через бинарную классификацию.

Математическое ядро - отношение плотностей, представляющее вероятность того, что будущее состояние (цель) g будет достигнуто из текущего состояния s и действия a. Система обучается с использованием лосса InfoNCE:

L = - E [ log ( exp(f(s_i, a_i, g_i)) / sum( exp(f(s_i, a_i, g_j)) ) ) ]

Где f() считает сходство (например, отрицательное L2 расстояние) между эмбеддингами. Этот классификационный сигнал более робастен и даёт более богатые градиенты, чем скалярная регрессия значений.

### Современные архитектурные элементы

В отличие от простых стеков линейных слоёв, архитектура использует последовательность Residual Blocks. Входное представление h_i трансформируется по правилу обновления: h_{i+1} = h_i + F_i(h_i), где функция F_i - строгая последовательность операций: Dense → LayerNorm → Swish Activation. Это критично: удаление Layer Normalization или Swish приводит к коллапсу масштабирования.

## Ключевые особенности

1. **Масштабирование глубины**: Успешное масштабирование от стандартных 4 слоёв до 1024 слоёв в сложных задачах навигации
2. **Self-Supervised Learning**: Использование контрастного обучения вместо традиционного обучения с подкреплением
3. **Архитектурные улучшения**: Совмещение резидуальных связей, нормализации по слою и активаций Swish
4. **InfoNCE Loss**: Использование контрастной функции потерь для обучения представлений
5. **Повышенная производительность**: Прирост в 20-50 раз по сравнению с традиционными методами

## Преимущества

- **Монотонный рост производительности с глубиной**: В отличие от традиционных RL-методов, где добавление слоёв не даёт результата, качество растёт с увеличением глубины
- **Улучшенное понимание топологии**: Глубокие сети учатся геодезическому расстоянию, а не евклидову, корректно определяя пути обхода препятствий
- **Эмерджентные навыки**: Появление сложных навыков локомоции без сложного инжиниринга наград
- **Стабильность**: Архитектура с резидуальными связями и нормализацией стабилизирует обучение

## Ограничения

- **Вычислительная стоимость**: Инференс 1000-слойной сети требует значительных вычислительных ресурсов и может быть неприемлемым для реальных робототехнических циклов управления на высоких частотах
- **Online зависимость**: Подход эффективен в онлайн-сеттинге self-supervised обучения, но даёт смешанные результаты в офлайн-RL
- **Сложность реализации**: Требует тщательной инженерии для сохранения стабильности при масштабировании

## Применения

- **Робототехника**: Сложное управление с длинным горизонтом, задачи локомоции
- **Навигация**: Задачи, требующие понимания топологии пространства
- **Управление манипуляторами**: Задачи с длинной последовательностью действий
- **Агенты с долгосрочными целями**: Задачи, требующие планирования и понимания структуры среды

## Теоретическая основа

Ключевое открытие - разделяющий эксперимент "Collector vs. Learner". При обучении на одном и том же буфере воспроизведения, глубокий ученик стабильно превосходит мелкого, доказывая, что даже при идентичных данных глубокая сеть извлекает лучшие политики. Визуально это проявляется как топологическое понимание: неглубокая сеть выучивает наивную евклидову метрику, тогда как глубокая сеть усваивает геодезическое расстояние, корректно определяя пути обхода препятствий.

## Связи с другими темами

- [[./deep_rl_algorithms.md]] - Сравнение с традиционными алгоритмами глубокого RL (SAC, TD3)
- [[../index.md]] - Введение в обучение с подкреплением
- [[../../self_supervised_learning.md]] - Общие понятия об обучении без учителя
- [[../../self_supervised_learning/lejepa.md]] - Современные подходы к self-supervised learning
- [[../../computer_vision/residual_networks.md|Residual Networks]] - Резидуальные сети, использованные в архитектуре
- [[../../nlp/transformers/transformer_architecture.md]] - Сравнение с подходами в трансформерах (LayerNorm, Residual Connections)
- [[../survey_rl_comprehensive.md]] - Обзор RL от алгоритмов к практическим вызовам

## Источники

1. [1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities](https://openreview.net/forum?id=s0JVsx3bx1) - Оригинальная статья Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach, описывающая масштабирование агентов до 1000+ слоёв с использованием Contrastive RL
2. [JaxGCRL Codebase](https://github.com/MichalBortkiewicz/JaxGCRL) - Кодовая база для высокопроизводительной параллельной симуляции на GPU, использованная в экспериментах
3. [NeurIPS 2025 Review](https://arxiviq.substack.com/p/neurips-2025-1000-layer-networks) - Обзор и анализ результатов статьи, опубликованный в контексте NeurIPS 2025
4. [Contrastive RL](https://arxiv.org/abs/2206.07568) - Оригинальная работа по Contrastive Reinforcement Learning, на которой основывается подход
5. [Soft Actor-Critic (SAC)](https://arxiv.org/abs/1801.01290) - Статья о SAC, с которым сравниваются результаты в работе