# Критические режимы сбоя LRM при прерывании

## Обзор

Исследование "Are Large Reasoning Models Interruptible?" выявило и охарактеризовало три новых критических режима сбоя, которые проявляются при динамических условиях работы с LRM, когда вмешательства происходят в середине процесса рассуждений.

## 1. Утечка рассуждений (Reasoning Leakage)

### Описание
Модели игнорируют сигналы о немедленной остановке и продолжают свою цепочку рассуждений внутри финального ответа, что увеличивает вычислительные затраты.

### Проявления
- Модели не прекращают думать при жёстких прерываниях
- "Протаскивают" последующие шаги рассуждений в секцию финального ответа
- Иногда в виде комментариев в коде
- Ответы могут быть до 10 раз длиннее по сравнению с полным непрерывным ответом

### Причины
- Сильное противоречие между заложенной в модель при предобучении целью генерировать связный, пошаговый текст и её способностью следовать явным командам вроде "остановись сейчас"
- Модели не обучены управлять процессом прерывания

## 2. Паника (Panic)

### Описание
При просьбе ускориться модели катастрофически прерывают процесс рассуждений вместо того, чтобы аккуратно его сжать.

### Проявления
- Полный отказ от мыслительного процесса при давлении времени
- Выдача поспешного и неверного ответа
- Падение точности до 30% в сценариях с прерываниями по времени

### Статистика
- Является причиной более 90% новых ошибок в сценарии с просьбой ускориться
- Модели не умеют аккуратно сжимать свои рассуждения

### Причины
- Отсутствие навыков адаптивного сжатия рассуждений
- Недостаточная подготовка к сценариям с ограничениями по времени

## 3. Самосомнение (Self-Doubt)

### Описание
Модели не могут довериться новой, валидной информации и учесть её, часто придерживаясь своего первоначального, уже неверного пути рассуждений.

### Проявления
- Неспособность учесть новую валидную информацию
- Постановка под сомнение новой информации
- Игнорирование важных обновлений
- Продолжение первоначальной, теперь ошибочной, линии рассуждений

### Статистика
- Является причиной примерно 80% ошибок в сценарии с динамическим контекстом
- Особенно сильно проявляется, когда обновления вводятся на поздних этапах рассуждений

### Причины
- Катастрофическое забывание в микроконтексте
- Модель с трудом обновляет свою "модель мира" задачи на лету
- Слишком большой вес придается первоначальному следу рассуждений

## Значение открытий

Эти результаты демонстрируют, что:
- Прерываемость и адаптивность не являются врождёнными свойствами текущих LRM
- Необходимо явно закладывать эти свойства при проектировании и оценке
- Текущая архитектура и обучение LRM не предусматривают гибкое управление состоянием рассуждений

## Возможные решения

1. **Обучение с curriculum learning с прерываниями**
2. **Применение обучения с подкреплением** для штрафования "паники" или поощрения плавной адаптации
3. **Разработка новых архитектур** со специальными механизмами для управления и обновления состояния рассуждений
4. **Промпт-инжиниринг** - использование "направляющих промптов" для уменьшения самосомнения

## Ссылки и развитие темы

- [[evaluation_framework_dynamic.md]] - Динамические фреймворки оценки
- [[frozen_world_assumption.md]] - Проблема допущения "замороженного мира"
- [[real_world_applications.md]] - Применение в реальных условиях