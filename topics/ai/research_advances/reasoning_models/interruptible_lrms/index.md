# Прерываемые модели рассуждения (Interruptible Large Reasoning Models, LRM)

## Описание

Прерываемые модели рассуждения - это направление исследований, посвященное способности Large Reasoning Models (LRM) работать в динамических условиях, где контекст задачи может изменяться или где требуется прерывание процесса рассуждения. Это кардинально отличается от традиционного подхода "замороженного мира", при котором задача фиксирована, а модель генерирует ответ без каких-либо прерываний.

## Контекст

Традиционная парадигма оценки LRM работает в рамках допущения "замороженного мира": модель получает фиксированную задачу, генерирует полный ответ, и среда остается неизменной на протяжении всего процесса. Такой подход подходит для коротких задач, но не работает для сложных, длительных рассуждений в таких областях, как ассистивное программирование, где модели могут "думать" минуты или часы, а контекст задачи — код, намерения пользователя или ограничения — может меняться.

## Основные проблемы

1. **Высокая точность в статических условиях**: Производительность LRM может падать до 60%, когда контекст меняется на поздних этапах рассуждений, что свидетельствует о переоценке реальной устойчивости моделей.

2. **Отсутствие врожденной прерываемости**: Прерываемость и адаптивность не являются врожденными свойствами текущих LRM и должны быть явно заложены при проектировании и оценке.

## Ключевые аспекты

- [[frozen_world_assumption.md]] - Проблема допущения "замороженного мира"
- [[failure_modes_lrm.md]] - Критические режимы сбоя в LRM
- [[evaluation_framework_dynamic.md]] - Динамические фреймворки оценки
- [[real_world_applications.md]] - Применение в реальных условиях

## Ссылки

- Оригинальная статья: "Are Large Reasoning Models Interruptible?" (Tsung-Han Wu и др., 2025)
- Код и фреймворк: https://github.com/dynamic-lm/interrupt-lrm
- Бенчмарк: https://huggingface.co/datasets/dynamic-lm/update-interrupt-benchmark