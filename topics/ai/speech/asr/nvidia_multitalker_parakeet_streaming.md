# NVIDIA Multitalker Parakeet Streaming 0.6B v1: Многоголосовая потоковая модель распознавания речи

## Описание

NVIDIA Multitalker Parakeet Streaming 0.6B v1 — это потоковая многоголосовая модель автоматического распознавания речи (ASR), основанная на архитектуре Parakeet. Модель разработана для распознавания речи в реальном времени в многопользовательских средах, позволяя транскрибировать речь нескольких дикторов одновременно без необходимости предварительной регистрации спикеров.

## Ключевые особенности

- **Самоадаптация к спикерам**: Динамически адаптируется к индивидуальным дикторам через предсказание активности речи (без необходимости предварительной регистрации)
- **Внедрение спикерных ядер**: Внедряет обучаемые спикерные ядра в слои энкодера Fast-Conformer
- **Многопоточная архитектура**: Развертывает один экземпляр модели для каждого диктора
- **Поддержка потоковой обработки**: Поддерживает обработку в реальном времени с настраиваемыми компромиссами между задержкой и точностью
- **Обработка полного перекрытия**: Может обрабатывать полностью перекрывающуюся речь нескольких дикторов

## Технические характеристики

- **Архитектура**: Основана на Fast-Conformer энкодере с NEST (NeMo Encoder for Speech Tasks)
- **Входные данные**: Аудио в формате моно с частотой 16 000 Гц
- **Выходные данные**: Маркированные транскрипции дикторов в формате SegLST
- **Зависимости**: Требует фреймворк NVIDIA NeMo
- **Размер модели**: 0.6 миллиарда параметров
- **Фреймворк**: PyTorch, NeMo

## Технические детали

Модель основана на архитектуре Parakeet и состоит из NeMo Encoder for Speech Tasks (NEST), который базируется на энкодере Fast-Conformer. Ключевая особенность заключается в том, что модель принимает выводы спикерной диаризации как внешнюю информацию. Модель использует потоковый диаризатор [[nvidia_diar_streaming_sortformer_4spk_v2_1.md|NVIDIA Diar Streaming Sortformer 4spk-v2.1]] для отслеживания активности дикторов.

Модель обучена на 21 датасете, включая реальные разговоры и симулированные аудио-смеси, что позволяет ей достичь передовых результатов как в автономных, так и в потоковых сценариях.

## Применение

Модель особенно эффективна в следующих сценариях:

- Конференции и собрания с несколькими участниками
- Реальные транскрипции разговоров
- Системы слежения за речью в многопользовательских средах
- Потоковое распознавание речи в реальном времени

## Преимущества

- **Отсутствие необходимости в обучении на конкретных спикерах**: Способна адаптироваться к новым дикторам на лету
- **Обработка перекрывающейся речи**: Эффективно обрабатывает случаи, когда несколько людей говорят одновременно
- **Низкая задержка**: Потоковая архитектура обеспечивает минимальную задержку при обработке
- **Масштабируемость**: Может обрабатывать произвольное количество дикторов в реальном времени

## Сравнение с другими моделями

В отличие от традиционных ASR-моделей, которые могут обрабатывать только одного диктора за раз, Multitalker Parakeet позволяет точно транскрибировать речь нескольких дикторов одновременно. Это делает его особенно полезным для приложений, где важно различать речь разных участников разговора.

## Связи с другими темами

- [[speech_recognition.md]] - Общие принципы распознавания речи
- [[omnilingual_asr.md]] - Многоязычные системы распознавания речи от Meta
- [[sortformer_speaker_diarization.md]] - Модель диаризации дикторов, используемая в паре с этой моделью
- [[fast_conformer_architecture.md]] - Архитектура, на которой основана модель
- [[nvidia_parakeet_architecture.md]] - Базовая архитектура Parakeet

## Источники

1. [NVIDIA Multitalker Parakeet Streaming 0.6B v1 на Hugging Face](https://huggingface.co/nvidia/multitalker-parakeet-streaming-0.6b-v1) - Основная страница модели с описанием
2. [NVIDIA Developer Blog: Identify Speakers in Meetings with Streaming Sortformer](https://developer.nvidia.com/blog/identify-speakers-in-meetings-calls-and-voice-apps-in-real-time-with-nvidia-streaming-sortformer/) - Информация о технологии диаризации дикторов
3. [NeMo GitHub Repository](https://github.com/NVIDIA-NeMo/NeMo) - Исходный код и документация фреймворка