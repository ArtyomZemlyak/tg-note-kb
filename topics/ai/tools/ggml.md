# GGML (General Graph-based Machine Learning)

## Описание

GGML (General Graph-based Machine Learning) - это фреймворк для машинного обучения с открытым исходным кодом, предназначенный для эффективного выполнения вычислений графов машинного обучения. GGML оптимизирован для высокой производительности и поддерживает вычисления на CPU с использованием SIMD-инструкций, а также поддерживает GPU-акселерацию. Библиотека широко используется для запуска больших языковых моделей на устройствах с ограниченными вычислительными ресурсами.

## Основные возможности

- **Эффективные вычисления**: Оптимизация для высокой производительности на CPU
- **Поддержка SIMD**: Использование SIMD-инструкций для ускорения вычислений
- **Квантования**: Поддержка различных методов квантования весов для уменьшения потребления памяти
- **Графовые операции**: Поддержка различных операций над графами моделей
- **Многопоточность**: Поддержка многопоточных вычислений

## Операции, поддерживаемые GGML

- **MUL_MAT** - матричное умножение
- **ROPE** - Rotary Positional Embedding (вращательные позиционные вложения)
- **RESHAPE** - преобразование формы тензоров
- **ADD** - поэлементное сложение
- ** другие операции внимания и активации

## Использование в LLM

- **Инференс моделей**: GGML широко используется для запуска больших языковых моделей на локальных устройствах
- **llama.cpp**: Популярная реализация инференса LLaMA моделей с использованием GGML
- **Отладка операций**: GGML предоставляет отладочную информацию о вычислительных операциях, что используется в инструментах визуализации

## Примеры использования

- [[../tools/alphaxiv_tensor_trace.md]] - использование GGML для парсинга отладочной информации о вычислительных операциях
- [[llama_cpp.md]] - реализация инференса LLaMA с использованием GGML

## Преимущества

- **Эффективность**: Высокая производительность на CPU с ограниченными ресурсами
- **Портативность**: Возможность запуска моделей на различных устройствах
- **Низкие требования к памяти**: Поддержка квантования для уменьшения потребления памяти
- **Открытый исходный код**: Доступен для модификации и адаптации

## Ресурсы

- GitHub: https://github.com/ggerganov/ggml
- llama.cpp: https://github.com/ggerganov/llama.cpp (использует GGML для инференса)

## Связи с другими темами

- [[../tools/alphaxiv_tensor_trace.md]] - использование GGML для визуализации операций трансформеров
- [[llama_cpp.md]] - применение GGML для инференса LLaMA моделей
- [[../../llm/models/llama_3_1.md]] - LLaMA 3.1 модель, используемая с GGML