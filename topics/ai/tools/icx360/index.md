# ICX360: Комплексный инструментарий для объяснения LLM в контексте (In-Context eXplainability 360)

## Описание

ICX360 (In-Context eXplainability 360) - это открытая библиотека Python, предназначенная для объяснения текста, генерируемого LLM, с акцентом на контекст, предоставленный пользователем (или общий промпт). Библиотека фокусируется на объяснениях в контексте, где объяснения привязаны к вводу - словам, предложениям или частям промпта, на основании которых LLM сгенерировала вывод.

В отличие от традиционных методов объяснения, которые анализируют модель в целом, ICX360 предоставляет объяснения в контексте, которые описывают, как определенные части входного контекста повлияли на конкретный выходной результат LLM. Это особенно полезно для понимания и анализа поведения модели в конкретных сценариях.

## Основные методы

### 1. Методы на основе возмущений (Perturbation-based Methods)

Методы на основе возмущений работают путем внесения изменений в входные данные и наблюдения за тем, как изменяется выход модели. Это позволяет идентифицировать, какие части входа наиболее критичны для генерации определенного ответа.

- **Замена**: Замена определенных токенов или фраз на альтернативные значения
- **Удаление**: Удаление частей входа, чтобы увидеть, как это влияет на выход
- **Искажение**: Внесение небольших изменений в представление входа

### 2. Контрастные объяснения (Contrastive Explanations)

Контрастные объяснения автоматически создают "отредактированные" промпты. Основная идея - найти "незначительно измененную" версию промпта, при которой модель дает заметно другой ответ по заданной метрике. Подход основан на методологии CELL (Contrastive Explanation for Large Language Models), который создает пертурбации входных промпт-ов, чтобы выявить, как изменения в промпте влияют на ответ модели.

Контрастные объяснения позволяют понять, почему модель дала определенный ответ, анализируя, как она отреагировала бы на небольшие изменения в промпте.

### 3. Механизм выделения токенов (Token Highlighter)

Механизм выделения токенов - унифицированный метод анализа токенов, которые могут привести к поведению jailbreak (обходу безопасности). Этот подход помогает идентифицировать потенциально опасные паттерны ввода, которые могут привести к нежелательному поведению модели.

## Особенности реализации

### Поддержка больших входов

ICX360 поддерживает большие входы на основе иерархических объяснений - от крупных частей входа (предложений) до слов и фраз (см. Приложение C.3 в оригинальной документации). Это позволяет анализировать длинные тексты и сложные промпты, которые типичны для реальных сценариев использования.

### Интеграция и документация

В комплекте с библиотекой поставляются:
- Методы и алгоритмы для объяснения
- Полная документация
- Тесты
- Ноутбуки для быстрого старта (Colab прямо из коробки)

## Установка и использование

```bash
uv pip install icx360
uv run python -m spacy download en_core_web_sm
uv run python -m spacy download en_core_web_trf
```

## Связь с другими технологиями

ICX360 связана с несколькими подходами в области интерпретируемости и объяснения поведения LLM:

- [[../../llm/mechanistic_interpretability.md]] - Обе области стремятся понять внутреннюю работу LLM, но ICX360 фокусируется на объяснениях в контексте для конкретных случаев вывода
- [[../../llm/reasoning/attribution_graphs_interpretability.md]] - Оба подхода анализируют влияние различных компонентов модели на конечный результат
- [[../../llm/activation_engineering.md]] - Техники, используемые для понимания и модификации активаций моделей

## Применение

ICX360 особенно полезна для:
1. Понимания поведения LLM в конкретных сценариях
2. Анализа безопасности и устойчивости к jailbreak-атакам
3. Отладки сложных генераций
4. Оценки качества и надежности LLM в различных условиях

## Источники

1. [ICX360: In-Context eXplainability 360 Toolkit](https://arxiv.org/abs/2511.10879) - Оригинальная статья о библиотеке, описывающая основные методы и архитектуру
2. [CELL your Model: Contrastive Explanation Methods for Large Language Models](https://arxiv.org/abs/2406.11785) - Основа для контрастных объяснений, реализованных в ICX360
3. [IBM ICX360 Documentation](https://ibm.github.io/ICX360/) - Официальная документация проекта