# LMMs Engine - Единый движок для обучения мультимодальных моделей

## Краткое описание

LMMs Engine - это простой, гибкий и мощный фреймворк от LMMs-Lab для обучения мультимодальных моделей, которые понимают текст, изображения, аудио и видео. Фреймворк разработан как легковесный, гибкий и подходящий для масштабного хакинга и экспериментов.

## Назначение

LMMs Engine предназначен для обучения и дообучки мультимодальных моделей (включая визуально-языковые, диффузионные, аудио-языковые и другие). Основная цель - обеспечить простую, унифицированную платформу для предобучения и тонкой настройки мультимодальных моделей на различных задачах.

## Архитектура

Архитектура построена на гибких паттернах проектирования:

- **Реестр компонентов (Component Registry)**: Использует паттерн фабрики для простого расширения
- **Обучение по принципу сборки (Builder Pattern)**: Обеспечивает гибкую компоновку конвейера обучения
- **Система реестра моделей**: Позволяет легко регистрировать пользовательские архитектуры моделей
- **Система реестра наборов данных**: Позволяет легко добавлять новые форматы данных
- **Модульная система процессоров**: Позволяет настраивать обработку данных

Ключевые компоненты:
1. **Модельная инициализация** - из предобученных моделей или конфигураций
2. **Создание набора данных** - с процессором и объединителем
3. **Система Monkey Patching** - применение оптимизаций ядра
4. **Настройка тренера** - FSDP2, DeepSpeed или пользовательские решения
5. **Выполнение обучения** - с контрольными точками и ведением журнала

## Поддерживаемые архитектуры

LMMs Engine поддерживает более 19 архитектур, охватывающих визуально-языковые, диффузионные и языковые модели:

### Мультимодальные модели:
- **Qwen2.5-VL** - передовая визуально-языковая модель
- **Qwen3-VL** - передовая визуально-языковая модель с обработкой изображений в native-разрешении и контекстом до 10 000+ токенов
- **Qwen2.5-Omni** - единая модель для текста, изображений и аудио
- **LLaVA-OneVision** - полностью открытая визуально-языковая модель
- **Bagel** - унифицированная мультимодальная модель для визуального понимания и генерации
- **Aero** - легковесная аудио-языковая модель

### Диффузионные и генеративные модели:
- **dLLM (Qwen3)** - диффузионная языковая модель с маскированным предсказанием
- **WanVideo (1.3B/14B)** - генерация Текст-в-Видео/Изображение-в-Видео/Видео-в-Видео
- **SiT (XL/2)** - масштабируемые интерполяционные трансформеры для генерации изображений с классифицированными условиями
- **RAE-SigLip** - автоэнкодер представлений с дискриминатором соперничества

### Языковые модели:
- **Серии Qwen2/2.5/3** - полная поддержка ядра Liger с объединенными операциями
- **Модели с линейным вниманием** - рекуррентная архитектура, оптимизированная для Muon
- **Пользовательские архитектуры** - расширяемые через декоратор @register_model()

## Возможности и особенности

### Оптимизации производительности:
- **FSDP2** - DTensor-базовое разделение параметров, градиентов и состояний оптимизатора для распределенного обучения
- **Ulysses Sequence Parallel** - разделяет размер последовательности по GPU для очень длинных контекстов
- **Flash Attention + Unpadding** - тайловое внимание с use_rmpad устраняет все вычисления заполнения
- **Native Sparse Attention (NSA)** - гибридный механизм внимания для эффективной обработки длинных контекстов
- **Ядро Liger** - объединенные ядра Triton (CrossEntropy, RMSNorm, RoPE, SwiGLU) обеспечивают 30% снижение потребления памяти
- **Оптимизатор Muon** - ортогонализация Ньютона-Шульца с Triton ядрами
- **Упаковка последовательностей** - упаковка по первому подходящему алгоритму достигает 35-40% MFU по сравнению с 20-25%

### Особенности:
- **Модульная архитектура**: Простое расширение через систему реестров
- **Поддержка различных тренеров**: hf_trainer, dllm_trainer, wan_trainer, rae_trainer, sit_trainer
- **Гибкие конфигурации**: YAML-файлы для настройки обучения
- **Поддержка распределенного обучения**: Поддержка FSDP2, DeepSpeed, Multi-dimensional Parallelism
- **Потоковая обработка данных**: IterableDataset для предобучения с триллионами токенов
- **Многоформатная поддержка данных**: JSONL/JSON/Arrow/CSV форматы

### Примеры использования:
- **Предобучение визуально-языковых моделей** - Qwen-VL, LLaVA на больших мультимодальных наборах данных
- **Понимание видео** - AERO на 3D видеоданных
- **Диффузионные модели** - DLLM, SiT, WanVideo для задач генерации
- **Обучение представлениям** - RAE для визуальных представлений
- **Предобучение языковых моделей** - DGN, Qwen с оптимизатором Muon
- **Тонкая настройка мультимодальных моделей** - эффективная SFT с упаковкой последовательностей

## Лицензия

Apache 2.0 - можно использовать даже в коммерческих проектах

## Связи с другими темами

- [[ai/llm/models/qwen/qwen-vl-series.md]] - Поддерживаемая серия Qwen-VL моделей
- [[ai/llm/models/qwen/qwen3-vl.md]] - Поддерживаемая Qwen3-VL модель
- [[ai/computer_vision/multimodal_models.md]] - Общие понятия о мультимодальных моделях
- [[ai/llm/models/multimodal/omnivinci.md]] - Другая мультимодальная модель