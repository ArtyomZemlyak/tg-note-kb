# Vision ARC (VARC): Новый подход к бенчмарку ARC

## Описание

Vision ARC (VARC) — это фреймворк, предложенный в статье "ARC Is a Vision Problem!" (Keya Hu, Ali Cy, Linlu Qiu и др., ноябрь 2025), который переосмысливает бенчмарк Abstraction and Reasoning Corpus (ARC) как задачу визуального восприятия и image-to-image трансляции, а не как задачу языкового моделирования или синтеза программ.

![Определение задачи ARC](../../media/img_1764033898_aqadoq9rg9mngul9_figure_3_the_arc_problem_definition.jpg)

**Описание:** На изображении показано определение задачи ARC, где для каждой задачи предоставляется несколько демонстрационных пар (x,y), на основе которых модель должна выполнить инференс для нового входа.

## Основная информация

VARC достигает впечатляющих результатов на бенчмарке ARC-1: 54.5% точности с одной моделью ViT-18M и 60.4% в ансамбле с U-Net. Это сопоставимо со средним человеческим уровнем и превосходит результаты крупных языковых моделей, таких как GPT-5, при значительно меньшем количестве параметров (всего 18 миллионов против сотен миллиардов). Это доказывает, что правильные inductive bias (например, 2D-локальность и масштабная инвариантность) могут быть более эффективными, чем простое наращивание масштаба.

## Ключевые новшества

### 1. Философия холста (Canvas Philosophy)

Вместо токенизации сеток ARC в 1D-последовательности, VARC проецирует 2D-сетки на фиксированное пиксельное пространство большего размера (например, 64×64). Это позволяет:
- Сохранить пространственную топологию и геометрию данных
- Использовать масштабную и сдвиговую инвариантность
- Обойти ограничения токенизации, которая разрушает пространственные отношения

### 2. Использование визуальных архитектур

VARC использует стандартные архитектуры компьютерного зрения:
- Vision Transformer (ViT) — для обработки визуальных патчей
- U-Net — для семантической сегментации задач

Эти архитектуры лучше захватывают пространственные прайоры, которые текстовым моделям эмулировать крайне сложно.

### 3. Test-Time Training (TTT)

Критически важный компонент — это обучение во время теста (Test-Time Training). Модель дообучается на демонстрационных парах перед предсказанием для конкретной задачи с использованием геометрических аугментаций (повороты, отражения, перестановки цветов).

### 4. Аугментации

VARC использует:
- **Scale Augmentation**: каждый логический пиксель реплицируется s×s раз
- **Translation Augmentation**: масштабированная сетка случайным образом размещается на фоне холста

## Технические детали

### Обработка задачи ARC в VARC

1. Входная сетка (например, 10×10) проходит через Scale Augmentation
2. Масштабированная сетка размещается случайным образом на фиксированном фоне холста (например, 64×64)
3. Модель обрабатывает изображение холста при условии обучаемого эмбеддинга задачи
4. Процесс рассматривается как задача семантической сегментации: сеть предсказывает категориальное распределение по 10 цветам ARC для каждого пикселя на холсте
5. На инференсе модель выдает карту вероятностей, которая затем дискретизируется обратно в формат сетки

![Архитектура VARC](../../media/img_1764033898_aqadow9rg9mngul_ficure_5_the_architecture_in.jpg)

**Описание:** На изображении показана архитектура VARC, демонстрирующая процесс преобразования задач ARC в формат визуального восприятия и основные компоненты системы визуального рассуждения.

### Формула TTT

Модель обновляет веса для минимизации попиксельного лосса кросс-энтропии на аугментированных демонстрационных парах:

L(θ) = E_{T,i} [D(y_i, f_θ(x_i | T))]

где D - функция потерь (например, кросс-энтропия), f_θ - модель с параметрами θ, x_i и y_i - i-я демонстрационная пара.

![Пример обработки задачи VARC](../../media/img_1764033898_aqadog9rg9mngul9_image_figure_4.jpg)

**Описание:** На изображении показан пример обработки задачи в VARC, демонстрируется процесс преобразования входных данных и получения результата.

## Применение и результаты

![Таблица сравнения систем](../../media/img_1764033898_aqadpg9rg9mngul9_table_3_system_level_comparisons_on_the.jpg)

**Описание:** На изображении представлена таблица с системным сравнением результатов VARC с другими подходами на бенчмарке ARC.

### Сравнение с другими методами
- VARC (ViT-18M): 54.5% точности на ARC-1
- VARC (ансамбль ViT+U-Net): 60.4% точности на ARC-1
- HRM (нейронная модель, обученная с нуля): 40.3%
- LLM (GPT-5 и др.): значительно ниже 60%

![Примеры невидимых задач](../../media/img_1764033898_aqadqw9rg9mngul9_ficure_2_examples_of_unseen_tasks.jpg)

**Описание:** На изображении представлены примеры невидимых задач из бенчмарка ARC, которые модель должна решить на основе демонстрационных пар.

### Сильные стороны
- Значительное улучшение по сравнению с предыдущими подходами, обученными с нуля
- Эффективность модели с небольшим количеством параметров
- Успешное применение визуальных прайоров к пространственным трансформациям (симметрия, гравитация, постоянство объектов)

### Ограничения
- Высокая вычислительная стоимость инференса из-за TTT (около 70 секунд на задачу на GPU)
- Неясна эффективность для задач, требующих абстрактного счёта или сложных логических условий без прямых визуальных аналогов

## Значение для ИИ

VARC демонстрирует, что:
- Задачи, которые считались сложными для ИИ, могут быть решены с помощью правильного выбора модальности
- Индуктивные смещения (inductive bias) могут быть более эффективны, чем масштабирование
- Визуальные модели могут превосходить языковые модели в задачах, требующих абстрактного мышления, если задача представлена в правильной модальности

## Связи с другими темами

- [[../ai/computer_vision/canvas_representation_for_reasoning.md]] - Концепция холста для визуального рассуждения
- [[../ai/computer_vision/test_time_training_in_vision_models.md]] - Применение TTT в визуальных моделях
- [[../ai/llm/architectures/test_time_training.md]] - Общая концепция обучения во время инференса
- [[../ai/nlp/transformers/transformer_architecture.md]] - Vision Transformer как развитие архитектуры трансформеров
- [[../ai/computer_vision/vision_transformer.md]] - Vision Transformer: применение архитектуры трансформеров к задачам компьютерного зрения
- [[../ai/research_advances/reasoning_models/hierarchical_reasoning_model_hrm.md]] - Сравнение с другими подходами к визуальному рассуждению
- [[../ai/research_advances/reasoning_models/trm_architecture.md]] - Другие архитектуры для рассуждения

## Источники

1. [ARC Is a Vision Problem!](https://arxiv.org/abs/2511.14761) - Оригинальная статья о VARC, Keya Hu, Ali Cy, Linlu Qiu и др., ноябрь 2025
2. [VARC GitHub Repository](https://github.com/lillian039/VARC) - Код реализации VARC
3. [ArXivIQ Review: ARC Is a Vision Problem](https://arxiviq.substack.com/p/arc-is-a-vision-problem) - Обзор статьи о VARC