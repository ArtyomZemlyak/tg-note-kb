# Основы статистики и теории вероятностей для ИИ и машинного обучения

## Описание

Этот файл описывает фундаментальные концепции статистики и теории вероятностей, которые лежат в основе искусственного интеллекта и машинного обучения. Эти математические инструменты необходимы для понимания алгоритмов машинного обучения, оценки их производительности и работы с неопределенностью в данных.

## Основные понятия теории вероятностей

### Вероятность и пространство событий

Вероятность - это числовая характеристика возможности наступления события. В контексте машинного обучения вероятность используется для квантификации неопределенности.

**Пространство событий (sample space)** - это множество всех возможных исходов случайного эксперимента. Обозначается обычно как Ω.

**Событие** - это подмножество пространства событий. Например, при броске кости событие "четное число" - это подмножество {2, 4, 6} из пространства событий {1, 2, 3, 4, 5, 6}.

### Условная вероятность и независимость

Условная вероятность P(A|B) - это вероятность события A при условии, что событие B произошло:

P(A|B) = P(A ∩ B) / P(B), если P(B) > 0

События A и B называются независимыми, если P(A ∩ B) = P(A)P(B), что эквивалентно P(A|B) = P(A) при P(B) > 0.

### Теорема Байеса

Теорема Байеса является фундаментальным результатом в теории вероятностей:

P(A|B) = P(B|A)P(A) / P(B)

Эта теорема лежит в основе байесовского подхода к машинному обучению, включая наивный байесовский классификатор, байесовскую оптимизацию гиперпараметров и байесовский вывод в нейронных сетях.

### Случайные величины и распределения

**Случайная величина** - это функция, которая присваивает вещественное число каждому исходу в пространстве событий.

**Дискретная случайная величина** принимает счетное количество значений. Примеры:
- Биномиальное распределение: B(n, p) - количество успехов в n независимых испытаниях с вероятностью успеха p
- Геометрическое распределение: вероятность первого успеха на k-ом испытании
- Пуассоновское распределение: P(λ) - моделирует редкие события

**Непрерывная случайная величина** может принимать любое значение в интервале. Примеры:
- Нормальное (гауссовское) распределение: N(μ, σ²) - наиболее важное распределение в статистике
- Равномерное распределение: U(a, b) - все значения в интервале [a, b] равновероятны
- Экспоненциальное распределение: моделирует время между событиями в пуассоновском процессе

## Основные понятия статистики

### Параметры и статистики

**Параметр** - это числовая характеристика генеральной совокупности (например, истинное среднее μ).

**Статистика** - это числовая характеристика выборки, используемая для оценки параметра (например, выборочное среднее x̄).

### Точечные и интервальные оценки

**Точечная оценка** дает одно число как оценку параметра.

**Интервальная оценка** дает диапазон значений, в котором, как ожидается, находится параметр с определенной вероятностью (доверительный интервал).

### Методы статистического вывода

**Оценка параметров** - процесс определения неизвестного значения параметра на основе выборочных данных.

**Проверка гипотез** - статистическая процедура для оценки достоверности утверждения о параметре генеральной совокупности.

## Применение в машинном обучении

### Вероятностные модели

Вероятность используется для построения моделей, которые могут выражать неопределенность:
- Наивный байесовский классификатор: P(класс|признаки) = P(признаки|класс) × P(класс) / P(признаки)
- Логистическая регрессия: моделирует P(успех|признаки) с использованием сигмоидальной функции
- Гауссовские процессы: вероятностная модель для регрессии и классификации

### Работа с неопределенностью

В машинном обучении важно уметь работать с неопределенностью в предсказаниях:
- **Epistemic неопределенность** (из-за недостатка знаний) - может быть уменьшена с увеличением данных
- **Aleatoric неопределенность** (внутренняя случайность) - неустранимая

### Оценка моделей

Теория вероятностей и статистика используются для оценки качества моделей:
- Функции потерь: лог-правдоподобие, кросс-энтропия
- Метрики: точность, полнота, F1-мера
- Проверка статистической значимости различий между моделями

## Связи с другими темами

- [[../ai/machine_learning.md]] - Статистика и вероятность как основа алгоритмов машинного обучения
- [[../math/linear_algebra.md]] - Совместное применение с линейной алгеброй в статистических методах
- [[../data_science/general/statistical_methods.md]] - Обобщенные статистические методы для анализа данных
- [[../ai/theory/probabilistic_graphical_models.md]] - Вероятностные графовые модели для представления сложных зависимостей

## Источники

1. [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) - классическая книга по статистическому обучению от Hastie, Tibshirani и Friedman
2. [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) - книга Бишопа по вероятностным методам в машинном обучении
3. [Statistical Inference](https://www.cengage.com/c/statistical-inference-2e-casella/id/9780534243128) - классический учебник по математической статистике
4. [Probability Theory: The Logic of Science](https://www.cambridge.org/core/books/probability-theory/B420C2E8193F16D7E08C9D96C32B3764) - книга Джейнса о вероятности как логике неопределенности